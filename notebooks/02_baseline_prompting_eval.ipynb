{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "962754b6",
   "metadata": {},
   "source": [
    "# Baseline Eval\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4a3467",
   "metadata": {},
   "source": [
    "## Summary\n",
    "- Purpose: establish the prompting-only baseline for NL->SQL (`k=0` and `k=3`).\n",
    "- Scope: runs on the fixed 200-item ClassicModels benchmark for paired comparisons.\n",
    "- Outputs: baseline run JSON files under `results/baseline/` for downstream analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f6773c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "set -e\n",
    "\n",
    "# shared colab setup script keeps package versions aligned across notebooks.\n",
    "if [ ! -f scripts/colab_setup.sh ] && [ -d /content ]; then\n",
    "  if [ ! -d /content/NLtoSQL ]; then\n",
    "    git clone https://github.com/MacKenzieOBrian/NLtoSQL.git /content/NLtoSQL\n",
    "  fi\n",
    "  cd /content/NLtoSQL\n",
    "fi\n",
    "\n",
    "bash scripts/colab_setup.sh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba5f922",
   "metadata": {},
   "source": [
    "## 0) Bootstrap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd30aacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# If this notebook is opened directly in Colab (not from a cloned repo), clone the repo first.\n",
    "if Path(\"data/classicmodels_test_200.json\").exists() is False and Path(\"/content\").exists():\n",
    "    repo_dir = Path(\"/content/NLtoSQL\")\n",
    "    if repo_dir.exists():\n",
    "        shutil.rmtree(repo_dir)\n",
    "    !git clone https://github.com/MacKenzieOBrian/NLtoSQL.git \"{repo_dir}\"\n",
    "    os.chdir(repo_dir)\n",
    "\n",
    "# Ensure repo root is on sys.path for `import nl2sql`\n",
    "sys.path.insert(0, os.getcwd())\n",
    "print(\"cwd:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a65e12",
   "metadata": {},
   "source": [
    "## 1) Install\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4a0263",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab  # noqa: F401\n",
    "    IN_COLAB = True\n",
    "except Exception:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    !pip -q install -r requirements.txt\n",
    "else:\n",
    "    print(\"Not in Colab; ensure requirements are installed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644e4296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colab-only: authenticate with GCP (safe to skip locally)\n",
    "try:\n",
    "    from google.colab import auth\n",
    "except ModuleNotFoundError:\n",
    "    auth = None\n",
    "\n",
    "if auth:\n",
    "    auth.authenticate_user()\n",
    "else:\n",
    "    print(\"Not running in Colab; ensure ADC or service account auth is configured.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a375d04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hugging Face auth (gated model)\n",
    "import os\n",
    "\n",
    "hf_token = os.getenv(\"HF_TOKEN\") or os.getenv(\"HUGGINGFACE_HUB_TOKEN\")\n",
    "if hf_token:\n",
    "    os.environ[\"HUGGINGFACE_HUB_TOKEN\"] = hf_token\n",
    "    print(\"Using HF token from env\")\n",
    "else:\n",
    "    try:\n",
    "        from huggingface_hub import notebook_login\n",
    "        notebook_login()\n",
    "    except Exception as e:\n",
    "        print(\"HF auth not configured:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8db21f",
   "metadata": {},
   "source": [
    "## 2) Data + DB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc093bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from getpass import getpass\n",
    "\n",
    "INSTANCE_CONNECTION_NAME = os.getenv(\"INSTANCE_CONNECTION_NAME\")\n",
    "DB_USER = os.getenv(\"DB_USER\")\n",
    "DB_PASS = os.getenv(\"DB_PASS\")\n",
    "DB_NAME = os.getenv(\"DB_NAME\", \"classicmodels\")\n",
    "\n",
    "if not INSTANCE_CONNECTION_NAME:\n",
    "    INSTANCE_CONNECTION_NAME = input(\"Enter INSTANCE_CONNECTION_NAME: \").strip()\n",
    "if not DB_USER:\n",
    "    DB_USER = input(\"Enter DB_USER: \").strip()\n",
    "if not DB_PASS:\n",
    "    DB_PASS = getpass(\"Enter DB_PASS: \")\n",
    "\n",
    "print(\"Using DB:\", DB_NAME)\n",
    "\n",
    "test_set = json.loads(open(\"data/classicmodels_test_200.json\", \"r\", encoding=\"utf-8\").read())\n",
    "print(\"Loaded test items:\", len(test_set))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1016babb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nl2sql.db import create_engine_with_connector\n",
    "\n",
    "engine, connector = create_engine_with_connector(\n",
    "    instance_connection_name=INSTANCE_CONNECTION_NAME,\n",
    "    user=DB_USER,\n",
    "    password=DB_PASS,\n",
    "    db_name=DB_NAME,\n",
    ")\n",
    "\n",
    "print(\"Engine ready\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b951b4",
   "metadata": {},
   "source": [
    "## 3) Load Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9070492",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "MODEL_ID = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "# this is the base model for baseline prompting runs.\n",
    "# keep this fixed when comparing prompt and k-shot settings.\n",
    "# provenance: model is fixed per sweep so deltas reflect prompt/shot changes, not model swaps.\n",
    "\n",
    "print(\"Loading tokenizer...\")\n",
    "tok = AutoTokenizer.from_pretrained(MODEL_ID, token=True)\n",
    "if tok.pad_token is None:\n",
    "    tok.pad_token = tok.eos_token\n",
    "\n",
    "# Try 4-bit loading (fallback to fp/bf16)\n",
    "# provenance: 4-bit nf4 path follows qlora-style inference to stay within colab memory.\n",
    "try:\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    )\n",
    "    print(\"Attempting 4-bit quantized load...\")\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_ID,\n",
    "        quantization_config=bnb_config,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        device_map=\"auto\",\n",
    "        token=True,\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(\"4-bit load failed, falling back. Error:\")\n",
    "    print(e)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_ID,\n",
    "        torch_dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float32,\n",
    "        device_map=\"auto\" if torch.cuda.is_available() else None,\n",
    "        token=True,\n",
    "    )\n",
    "\n",
    "# transformers generation docs: temperature/top_p are sampling controls.\n",
    "# deterministic eval policy: do_sample=false with neutral temperature/top_p.\n",
    "model.generation_config.do_sample = False\n",
    "model.generation_config.temperature = 1.0\n",
    "model.generation_config.top_p = 1.0\n",
    "model.generation_config.top_k = 50\n",
    "model.generation_config.num_beams = 1\n",
    "\n",
    "print(\"Model device:\", model.device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb7e719",
   "metadata": {},
   "source": [
    "## 4) Schema Context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274de10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nl2sql.schema import build_schema_summary\n",
    "\n",
    "SCHEMA_SUMMARY = build_schema_summary(engine, db_name=DB_NAME, max_cols_per_table=50)\n",
    "print(\"Schema summary built (chars):\", len(SCHEMA_SUMMARY))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382bccdf",
   "metadata": {},
   "source": [
    "## 5) Run Controls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89802cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Orchestration helpers for baseline sweep runs.\n",
    "# Core NL->SQL logic stays in nl2sql imports below.\n",
    "import re\n",
    "import subprocess\n",
    "import shutil\n",
    "from functools import lru_cache\n",
    "from datetime import datetime, timezone\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from nl2sql.eval import eval_run\n",
    "from nl2sql.db import create_engine_with_connector\n",
    "import nl2sql.prompting as prompting_mod\n",
    "\n",
    "DEFAULT_SYSTEM_INSTRUCTIONS = prompting_mod.SYSTEM_INSTRUCTIONS\n",
    "\n",
    "\n",
    "from nl2sql.experiment_helpers import (\n",
    "    exemplar_pool_for_strategy,\n",
    "    make_prompt_variants,\n",
    "    model_alias_from_id,\n",
    "    schema_variant_text,\n",
    ")\n",
    "\n",
    "# shared helpers keep baseline/qlora notebook behavior aligned.\n",
    "_model_alias_from_id = model_alias_from_id\n",
    "PROMPT_VARIANTS = make_prompt_variants(DEFAULT_SYSTEM_INSTRUCTIONS)\n",
    "\n",
    "# Capture git commit for run provenance (optional).\n",
    "try:\n",
    "    commit = subprocess.check_output([\"git\", \"rev-parse\", \"--short\", \"HEAD\"]).decode().strip()\n",
    "except Exception:\n",
    "    commit = \"unknown\"\n",
    "\n",
    "# Base metadata attached to each saved run JSON.\n",
    "run_metadata_base = {\n",
    "    \"commit\": commit,\n",
    "    \"model_id\": MODEL_ID,\n",
    "    \"model_alias\": _model_alias_from_id(MODEL_ID),\n",
    "    \"notebook\": \"02_baseline_prompting_eval.ipynb\",\n",
    "    \"method\": \"baseline\",\n",
    "}\n",
    "\n",
    "# Ensure output root exists before writing run artifacts.\n",
    "Path(\"results/baseline\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "# Main sweep runner: executes k/seed grid and writes JSON+CSV artifacts.\n",
    "def run_baseline_grid(\n",
    "    *,\n",
    "    k_values: list[int],\n",
    "    seeds: list[int],\n",
    "    run_tag: str,\n",
    "    prompt_variant: str,\n",
    "    schema_variant: str,\n",
    "    exemplar_strategy: str,\n",
    "    limit: int | None = None,\n",
    "    copy_canonical: bool = True,\n",
    "    model_alias: str | None = None,\n",
    "    enable_ts_for_k: set[int] | None = None,\n",
    "    ts_n: int = 10,\n",
    "    ts_prefix: str = \"classicmodels_ts\",\n",
    "    ts_max_rows: int = 500,\n",
    "):\n",
    "    # Basic reproducibility checks.\n",
    "    if not seeds:\n",
    "        raise ValueError(\"Provide at least one seed\")\n",
    "\n",
    "    if prompt_variant not in PROMPT_VARIANTS:\n",
    "        raise ValueError(f\"Unknown PROMPT_VARIANT: {prompt_variant}\")\n",
    "\n",
    "    # Run directory is timestamped for traceability and collision safety.\n",
    "    ts = datetime.now(timezone.utc).strftime(\"%Y%m%d_%H%M%SZ\")\n",
    "    run_dir = Path(\"results/baseline/runs\") / f\"{run_tag}_{ts}\"\n",
    "    run_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    schema_used = schema_variant_text(SCHEMA_SUMMARY, schema_variant)\n",
    "    exemplar_pool = exemplar_pool_for_strategy(test_set, exemplar_strategy)\n",
    "    resolved_model_alias = model_alias or run_metadata_base.get(\"model_alias\") or _model_alias_from_id(MODEL_ID)\n",
    "\n",
    "    ts_enabled_k = set(enable_ts_for_k or set())\n",
    "    ts_suite_db_names = (\n",
    "        [f\"{ts_prefix}_{i:02d}\" for i in range(1, ts_n + 1)]\n",
    "        if ts_enabled_k and ts_n > 0\n",
    "        else None\n",
    "    )\n",
    "\n",
    "    # Lazy connector cache for optional TS evaluation databases.\n",
    "    ts_connectors = {}\n",
    "\n",
    "    @lru_cache(maxsize=32)\n",
    "    def _make_engine_cached(db_name: str):\n",
    "        eng, conn = create_engine_with_connector(\n",
    "            instance_connection_name=INSTANCE_CONNECTION_NAME,\n",
    "            user=DB_USER,\n",
    "            password=DB_PASS,\n",
    "            db_name=db_name,\n",
    "        )\n",
    "        ts_connectors[db_name] = conn\n",
    "        return eng\n",
    "\n",
    "    def _make_engine_fn(db_name: str):\n",
    "        return _make_engine_cached(db_name)\n",
    "\n",
    "    rows = []\n",
    "    primary_seed = seeds[0]  # first seed is used for canonical copies\n",
    "\n",
    "    # Prompt override is temporary and restored in finally.\n",
    "    old_prompt = prompting_mod.SYSTEM_INSTRUCTIONS\n",
    "    prompting_mod.SYSTEM_INSTRUCTIONS = PROMPT_VARIANTS[prompt_variant]\n",
    "\n",
    "    try:\n",
    "        for k in k_values:\n",
    "            # Keep k=0 tied to primary seed for canonical zero-shot consistency.\n",
    "            seed_list = [primary_seed] if k == 0 else seeds\n",
    "            for seed in seed_list:\n",
    "                save_path = run_dir / f\"results_k{k}_seed{seed}.json\"\n",
    "\n",
    "                run_meta = dict(run_metadata_base)\n",
    "                run_meta.update({\n",
    "                    \"run_tag\": run_tag,\n",
    "                    \"k\": k,\n",
    "                    \"seed\": seed,\n",
    "                    \"prompt_variant\": prompt_variant,\n",
    "                    \"schema_variant\": schema_variant,\n",
    "                    \"exemplar_strategy\": exemplar_strategy,\n",
    "                    \"exemplar_pool_size\": len(exemplar_pool),\n",
    "                    \"model_alias\": resolved_model_alias,\n",
    "                    \"ts_enabled\": bool(k in ts_enabled_k),\n",
    "                    \"ts_for_k_values\": sorted(ts_enabled_k),\n",
    "                    \"ts_n\": ts_n if ts_suite_db_names else 0,\n",
    "                    \"eval_profile\": \"model_only_raw\",\n",
    "                })\n",
    "\n",
    "                items = eval_run(\n",
    "                    test_set=test_set,\n",
    "                    exemplar_pool=exemplar_pool,\n",
    "                    k=k,\n",
    "                    limit=limit,\n",
    "                    seed=seed,\n",
    "                    engine=engine,\n",
    "                    model=model,\n",
    "                    tokenizer=tok,\n",
    "                    schema_summary=schema_used,\n",
    "                    save_path=str(save_path),\n",
    "                    run_metadata=run_meta,\n",
    "                    ts_suite_db_names=ts_suite_db_names if k in ts_enabled_k else None,\n",
    "                    ts_make_engine_fn=_make_engine_fn if k in ts_enabled_k else None,\n",
    "                    ts_max_rows=ts_max_rows,\n",
    "                    avoid_exemplar_leakage=True,\n",
    "                )\n",
    "\n",
    "                # Aggregate per-run rates for quick table summaries.\n",
    "                n = len(items)\n",
    "                va = sum(int(x.va) for x in items) / max(n, 1)\n",
    "                em = sum(int(x.em) for x in items) / max(n, 1)\n",
    "                ex = sum(int(x.ex) for x in items) / max(n, 1)\n",
    "                ts_values = [int(x.ts) for x in items if getattr(x, \"ts\", None) is not None]\n",
    "                ts_rate = (sum(ts_values) / len(ts_values)) if ts_values else None\n",
    "\n",
    "                rows.append({\n",
    "                    \"run_tag\": run_tag,\n",
    "                    \"prompt_variant\": prompt_variant,\n",
    "                    \"schema_variant\": schema_variant,\n",
    "                    \"exemplar_strategy\": exemplar_strategy,\n",
    "                    \"exemplar_pool_size\": len(exemplar_pool),\n",
    "                    \"k\": k,\n",
    "                    \"seed\": seed,\n",
    "                    \"n\": n,\n",
    "                    \"va_rate\": va,\n",
    "                    \"em_rate\": em,\n",
    "                    \"ex_rate\": ex,\n",
    "                    \"ts_rate\": ts_rate,\n",
    "                    \"ts_n\": len(ts_values),\n",
    "                    \"json_path\": str(save_path),\n",
    "                })\n",
    "\n",
    "                if seed == primary_seed and k in {0, 3}:\n",
    "                    if copy_canonical:\n",
    "                        target = (\n",
    "                            Path(\"results/baseline/results_zero_shot_200.json\")\n",
    "                            if k == 0\n",
    "                            else Path(\"results/baseline/results_few_shot_k3_200.json\")\n",
    "                        )\n",
    "                        target.parent.mkdir(parents=True, exist_ok=True)\n",
    "                        shutil.copy2(save_path, target)\n",
    "                        print(f\"Updated canonical file: {target}\")\n",
    "\n",
    "    finally:\n",
    "        for conn in ts_connectors.values():\n",
    "            try:\n",
    "                conn.close()\n",
    "            except Exception:\n",
    "                pass\n",
    "        prompting_mod.SYSTEM_INSTRUCTIONS = old_prompt\n",
    "\n",
    "    # Save per-run table and per-k mean/std summary.\n",
    "    df = pd.DataFrame(rows).sort_values([\"k\", \"seed\"]).reset_index(drop=True)\n",
    "    df.to_csv(run_dir / \"grid_summary.csv\", index=False)\n",
    "\n",
    "    agg = (\n",
    "        df.groupby([\"prompt_variant\", \"schema_variant\", \"exemplar_strategy\", \"k\"], as_index=False)\n",
    "        .agg(\n",
    "            runs=(\"seed\", \"count\"),\n",
    "            va_mean=(\"va_rate\", \"mean\"),\n",
    "            va_std=(\"va_rate\", \"std\"),\n",
    "            em_mean=(\"em_rate\", \"mean\"),\n",
    "            em_std=(\"em_rate\", \"std\"),\n",
    "            ex_mean=(\"ex_rate\", \"mean\"),\n",
    "            ex_std=(\"ex_rate\", \"std\"),\n",
    "            ts_mean=(\"ts_rate\", \"mean\"),\n",
    "            ts_std=(\"ts_rate\", \"std\"),\n",
    "        )\n",
    "    )\n",
    "    agg.to_csv(run_dir / \"grid_summary_by_k.csv\", index=False)\n",
    "\n",
    "    print(\"Saved grid run to:\", run_dir)\n",
    "    return df, agg, run_dir\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cff0257",
   "metadata": {},
   "source": [
    "### 5A) Run Plan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693a3e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# Plan-driven baseline controls\n",
    "# ============================\n",
    "# Edit only this block for most experiments.\n",
    "# Keep one RUN_PLAN active per execution to isolate effects clearly.\n",
    "RUN_PLAN = \"quick\"  # quick | k5_core | seed_backfill | full_sweep | ts_k3 | custom\n",
    "# run_plan picks which predefined grid to execute.\n",
    "# use custom when you need one exact run.\n",
    "\n",
    "PROMPT_VARIANT = \"default\"\n",
    "SCHEMA_VARIANT = \"full\"\n",
    "EXEMPLAR_STRATEGY = \"all\"\n",
    "# these three toggles control ablation axes. keep them fixed for fair model comparison.\n",
    "# provenance: these axes map directly to methodology sections (prompt, schema context, exemplar pool).\n",
    "\n",
    "MODEL_ALIAS = _model_alias_from_id(MODEL_ID)\n",
    "COPY_CANONICAL = False\n",
    "\n",
    "# optional reliability extension path (keep false for primary hypothesis runs)\n",
    "USE_OPTIONAL_RELIABILITY = False\n",
    "GENERATION_CONSTRAINED = USE_OPTIONAL_RELIABILITY\n",
    "GENERATION_EXTRACT_SELECT = USE_OPTIONAL_RELIABILITY\n",
    "GENERATION_STOP_ON_SEMICOLON = USE_OPTIONAL_RELIABILITY\n",
    "APPLY_SQL_GUARDRAILS = USE_OPTIONAL_RELIABILITY\n",
    "APPLY_POSTPROCESS = USE_OPTIONAL_RELIABILITY\n",
    "\n",
    "TS_N = 10\n",
    "# provenance: ts_n=10 mirrors execution-consistency stress tests used in final reporting.\n",
    "TS_PREFIX = \"classicmodels_ts\"\n",
    "TS_MAX_ROWS = 500\n",
    "\n",
    "CUSTOM_PLAN = {\n",
    "    \"k_values\": [0, 3],\n",
    "    \"seeds\": [7],\n",
    "    \"run_tag\": \"baseline_custom\",\n",
    "    \"enable_ts\": False,\n",
    "}\n",
    "\n",
    "# Resolve plan -> concrete k/seed/run_tag values.\n",
    "if RUN_PLAN == \"quick\":\n",
    "    K_VALUES = [0, 3]\n",
    "    SEEDS = [7]\n",
    "    RUN_TAG = \"baseline_main\"\n",
    "    ENABLE_TS = False\n",
    "elif RUN_PLAN == \"k5_core\":\n",
    "    K_VALUES = [5]\n",
    "    SEEDS = [7]\n",
    "    RUN_TAG = \"baseline_k5_core\"\n",
    "    ENABLE_TS = False\n",
    "elif RUN_PLAN == \"seed_backfill\":\n",
    "    K_VALUES = [0, 3, 5]\n",
    "    SEEDS = [17, 27]\n",
    "    RUN_TAG = \"baseline_seed_backfill\"\n",
    "    ENABLE_TS = False\n",
    "elif RUN_PLAN == \"full_sweep\":\n",
    "    K_VALUES = [0, 3, 5]\n",
    "    SEEDS = [7, 17, 27]\n",
    "    RUN_TAG = \"baseline_e1_k_sweep\"\n",
    "    ENABLE_TS = False\n",
    "elif RUN_PLAN == \"ts_k3\":\n",
    "    K_VALUES = [3]\n",
    "    SEEDS = [7]\n",
    "    RUN_TAG = \"baseline_ts_k3\"\n",
    "    ENABLE_TS = True\n",
    "elif RUN_PLAN == \"custom\":\n",
    "    K_VALUES = list(CUSTOM_PLAN[\"k_values\"])\n",
    "    SEEDS = list(CUSTOM_PLAN[\"seeds\"])\n",
    "    RUN_TAG = str(CUSTOM_PLAN[\"run_tag\"])\n",
    "    ENABLE_TS = bool(CUSTOM_PLAN[\"enable_ts\"])\n",
    "else:\n",
    "    raise ValueError(f\"Unknown RUN_PLAN: {RUN_PLAN}\")\n",
    "\n",
    "# TS is typically enabled only for k=3 semantic robustness checks.\n",
    "TS_FOR_K_VALUES = [3]\n",
    "\n",
    "# Run card is a quick sanity check before launching a long run.\n",
    "print(\"Baseline run card:\")\n",
    "print({\n",
    "    \"run_plan\": RUN_PLAN,\n",
    "    \"run_tag\": RUN_TAG,\n",
    "    \"model_id\": MODEL_ID,\n",
    "    \"model_alias\": MODEL_ALIAS,\n",
    "    \"k_values\": K_VALUES,\n",
    "    \"seeds\": SEEDS,\n",
    "    \"prompt_variant\": PROMPT_VARIANT,\n",
    "    \"schema_variant\": SCHEMA_VARIANT,\n",
    "    \"exemplar_strategy\": EXEMPLAR_STRATEGY,\n",
    "    \"enable_ts\": ENABLE_TS,\n",
    "    \"optional_reliability\": USE_OPTIONAL_RELIABILITY,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12ffe16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute selected sweep.\n",
    "baseline_grid, baseline_by_k, baseline_run_dir = run_baseline_grid(\n",
    "    k_values=K_VALUES,\n",
    "    seeds=SEEDS,\n",
    "    run_tag=RUN_TAG,\n",
    "    prompt_variant=PROMPT_VARIANT,\n",
    "    schema_variant=SCHEMA_VARIANT,\n",
    "    exemplar_strategy=EXEMPLAR_STRATEGY,\n",
    "    limit=None,\n",
    "    copy_canonical=COPY_CANONICAL,\n",
    "    model_alias=MODEL_ALIAS,\n",
    "    enable_ts_for_k=set(TS_FOR_K_VALUES) if ENABLE_TS else None,\n",
    "    ts_n=TS_N,\n",
    "    ts_prefix=TS_PREFIX,\n",
    "    ts_max_rows=TS_MAX_ROWS,\n",
    "    generation_constrained=GENERATION_CONSTRAINED,\n",
    "    generation_extract_select=GENERATION_EXTRACT_SELECT,\n",
    "    generation_stop_on_semicolon=GENERATION_STOP_ON_SEMICOLON,\n",
    "    apply_sql_guardrails=APPLY_SQL_GUARDRAILS,\n",
    "    apply_postprocess=APPLY_POSTPROCESS,\n",
    ")\n",
    "\n",
    "print(\"\\nPer-run rows:\")\n",
    "display(baseline_grid)\n",
    "print(\"\\nPer-k summary (mean/std across seeds):\")\n",
    "display(baseline_by_k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e435ec69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Quick canonical summary (reads saved k=0 and k=3 JSON outputs)\n",
    "import json\n",
    "\n",
    "zero = json.loads(open(\"results/baseline/results_zero_shot_200.json\", \"r\", encoding=\"utf-8\").read())\n",
    "few  = json.loads(open(\"results/baseline/results_few_shot_k3_200.json\", \"r\", encoding=\"utf-8\").read())\n",
    "\n",
    "print(\"Zero-shot:\", \"VA\", round(zero[\"va_rate\"], 3), \"EM\", round(zero.get(\"em_rate\", 0.0), 3), \"EX\", round(zero[\"ex_rate\"], 3))\n",
    "print(\"Few-shot:\",  \"VA\", round(few[\"va_rate\"], 3),  \"EM\", round(few.get(\"em_rate\", 0.0), 3),  \"EX\", round(few[\"ex_rate\"], 3))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
