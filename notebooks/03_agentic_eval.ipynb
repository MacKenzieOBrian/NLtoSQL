{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Agentic Evaluation (ReAct-style)\n",
        "\n",
        "This notebook adds a minimal ReAct-style loop for NL→SQL. It reuses the same benchmark (`data/classicmodels_test_200.json`) and metrics (VA/EX/EM; TS planned) to measure gains over prompt-only and QLoRA runs.\n",
        "\n",
        "Plan (step-by-step):\n",
        "1) Environment + DB connection\n",
        "2) Load schema summary + test set\n",
        "3) Load model (base or QLoRA adapters)\n",
        "4) Define ReAct prompt + loop (Thought → Action → Observation → Refinement)\n",
        "5) Run evaluation (VA/EX/EM) and save to `results/agent/…`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 0) Optional: install deps (Colab)\n",
        "try:\n",
        "    import google.colab  # noqa: F401\n",
        "    IN_COLAB = True\n",
        "except Exception:\n",
        "    IN_COLAB = False\n",
        "\n",
        "if IN_COLAB:\n",
        "    !pip -q install -r requirements.txt\n",
        "    import torch, transformers, accelerate, peft\n",
        "    print('torch', torch.__version__, 'cuda', torch.cuda.is_available())\n",
        "else:\n",
        "    print('Not in Colab; ensure requirements are installed.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1) Environment + DB\n",
        "import os\n",
        "from getpass import getpass\n",
        "from pathlib import Path\n",
        "\n",
        "from google.cloud.sql.connector import Connector\n",
        "from sqlalchemy import create_engine\n",
        "from sqlalchemy.engine import Engine\n",
        "\n",
        "INSTANCE_CONNECTION_NAME = os.getenv(\"INSTANCE_CONNECTION_NAME\")\n",
        "DB_USER = os.getenv(\"DB_USER\")\n",
        "DB_PASS = os.getenv(\"DB_PASS\")\n",
        "DB_NAME = os.getenv(\"DB_NAME\") or \"classicmodels\"\n",
        "\n",
        "if not INSTANCE_CONNECTION_NAME:\n",
        "    INSTANCE_CONNECTION_NAME = input(\"Enter INSTANCE_CONNECTION_NAME: \").strip()\n",
        "if not DB_USER:\n",
        "    DB_USER = input(\"Enter DB_USER: \").strip()\n",
        "if not DB_PASS:\n",
        "    DB_PASS = getpass(\"Enter DB_PASS: \")\n",
        "\n",
        "connector = Connector()\n",
        "def getconn():\n",
        "    return connector.connect(\n",
        "        INSTANCE_CONNECTION_NAME,\n",
        "        \"pymysql\",\n",
        "        user=DB_USER,\n",
        "        password=DB_PASS,\n",
        "        db=DB_NAME,\n",
        "    )\n",
        "\n",
        "engine: Engine = create_engine(\n",
        "    \"mysql+pymysql://\",\n",
        "    creator=getconn,\n",
        "    future=True,\n",
        ")\n",
        "\n",
        "with engine.connect() as conn:\n",
        "    conn.execute(\"SELECT 1\")\n",
        "print(\"DB connection OK\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2) Load schema summary + test set\n",
        "import json\n",
        "from nl2sql.schema import build_schema_summary\n",
        "\n",
        "SCHEMA_SUMMARY = build_schema_summary(engine, db_name=DB_NAME)\n",
        "\n",
        "test_path = Path(\"data/classicmodels_test_200.json\")\n",
        "test_set = json.loads(test_path.read_text(encoding=\"utf-8\"))\n",
        "print(\"Test items:\", len(test_set))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3) Load model (base or QLoRA adapters)\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from peft import PeftModel\n",
        "\n",
        "MODEL_ID = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
        "ADAPTER_PATH = \"results/adapters/qlora_classicmodels\"  # set to None to use base model\n",
        "\n",
        "cc_major, cc_minor = torch.cuda.get_device_capability(0) if torch.cuda.is_available() else (0, 0)\n",
        "use_bf16 = cc_major >= 8\n",
        "compute_dtype = torch.bfloat16 if use_bf16 else torch.float16\n",
        "print(\"GPU:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\")\n",
        "print(\"Using bf16:\", use_bf16)\n",
        "\n",
        "tok = AutoTokenizer.from_pretrained(MODEL_ID, token=True)\n",
        "if tok.pad_token is None:\n",
        "    tok.pad_token = tok.eos_token\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=compute_dtype,\n",
        ")\n",
        "\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_ID,\n",
        "    quantization_config=bnb_config,\n",
        "    torch_dtype=compute_dtype,\n",
        "    device_map={\"\": 0} if torch.cuda.is_available() else None,\n",
        "    token=True,\n",
        ")\n",
        "base_model.generation_config.do_sample = False\n",
        "base_model.generation_config.temperature = 1.0\n",
        "base_model.generation_config.top_p = 1.0\n",
        "\n",
        "if ADAPTER_PATH:\n",
        "    model = PeftModel.from_pretrained(base_model, ADAPTER_PATH)\n",
        "    print(\"Loaded adapters from\", ADAPTER_PATH)\n",
        "else:\n",
        "    model = base_model\n",
        "    print(\"Using base model only\")\n",
        "\n",
        "model.eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4) ReAct helpers: prompt builder and loop\n",
        "import re\n",
        "from nl2sql.query_runner import QueryRunner\n",
        "\n",
        "runner = QueryRunner(engine)\n",
        "\n",
        "def build_react_prompt(nlq: str, schema_text: str, history: list, observation: str) -> str:\n",
        "    history_text = \"\\n\".join([\n",
        "        f\"Thought/Action: {h['ta']}\\nObservation: {h['obs']}\" for h in history\n",
        "    ])\n",
        "    return f\"\"\"\n",
        "You are an expert SQL agent. Follow the steps:\n",
        "1) Think briefly about the question.\n",
        "2) Propose a single SQL query.\n",
        "3) If previous Observation reports an ERROR, fix it.\n",
        "\n",
        "Schema:\n",
        "{schema_text}\n",
        "\n",
        "Question: {nlq}\n",
        "\n",
        "Previous trace:\n",
        "{history_text}\n",
        "Observation: {observation}\n",
        "\n",
        "Now reply with SQL only.\n",
        "\"\"\"\n",
        "\n",
        "def extract_sql(text: str) -> str:\n",
        "    # Simple heuristic: grab first SELECT ... ; span\n",
        "    m = re.search(r\"(SELECT[\\s\\S]+?);\", text, re.IGNORECASE)\n",
        "    return m.group(1) + \";\" if m else text.strip()\n",
        "\n",
        "def react_sql(nlq: str, schema_text: str, max_steps: int = 3):\n",
        "    history = []\n",
        "    observation = \"Start.\"\n",
        "    final_sql = None\n",
        "    for step in range(max_steps):\n",
        "        prompt = build_react_prompt(nlq, schema_text, history, observation)\n",
        "        inputs = tok(prompt, return_tensors=\"pt\").to(model.device)\n",
        "        with torch.no_grad():\n",
        "            out = model.generate(**inputs, max_new_tokens=256)\n",
        "        gen = tok.decode(out[0], skip_special_tokens=True)\n",
        "        sql = extract_sql(gen)\n",
        "        try:\n",
        "            # Execute to drive the loop; limit rows to force evaluation\n",
        "            runner.run(sql + \" LIMIT 1\" if \" limit \" not in sql.lower() else sql)\n",
        "            observation = \"SUCCESS\"\n",
        "            final_sql = sql\n",
        "            break\n",
        "        except Exception as e:\n",
        "            observation = f\"ERROR: {e}\"\n",
        "        history.append({\"ta\": gen, \"obs\": observation})\n",
        "    return final_sql or sql, history\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5) Evaluation loop (VA/EX/EM). TS is planned.\n",
        "from nl2sql.eval import execution_accuracy\n",
        "\n",
        "results = []\n",
        "for i, sample in enumerate(test_set, start=1):\n",
        "    nlq = sample[\"nlq\"]\n",
        "    gold_sql = sample[\"sql\"]\n",
        "    pred_sql, trace = react_sql(nlq, SCHEMA_SUMMARY, max_steps=3)\n",
        "    va = 0\n",
        "    em = int(pred_sql.strip().rstrip(\";\").lower() == gold_sql.strip().rstrip(\";\").lower())\n",
        "    ex = 0\n",
        "    try:\n",
        "        runner.run(pred_sql)\n",
        "        va = 1\n",
        "        ex = int(execution_accuracy(engine, pred_sql, gold_sql))\n",
        "    except Exception:\n",
        "        va = 0\n",
        "        ex = 0\n",
        "    results.append({\n",
        "        \"nlq\": nlq,\n",
        "        \"gold_sql\": gold_sql,\n",
        "        \"pred_sql\": pred_sql,\n",
        "        \"va\": va,\n",
        "        \"em\": em,\n",
        "        \"ex\": ex,\n",
        "        \"trace\": trace,\n",
        "    })\n",
        "    if i % 20 == 0:\n",
        "        print(f\"Processed {i}/{len(test_set)}\")\n",
        "\n",
        "va_rate = sum(r[\"va\"] for r in results) / len(results)\n",
        "ex_rate = sum(r[\"ex\"] for r in results) / len(results)\n",
        "em_rate = sum(r[\"em\"] for r in results) / len(results)\n",
        "print(\"VA:\", va_rate, \"EX:\", ex_rate, \"EM:\", em_rate)\n",
        "\n",
        "Path(\"results/agent\").mkdir(parents=True, exist_ok=True)\n",
        "save_path = Path(\"results/agent/results_react_200.json\")\n",
        "save_path.write_text(json.dumps({\n",
        "    \"va_rate\": va_rate,\n",
        "    \"ex_rate\": ex_rate,\n",
        "    \"em_rate\": em_rate,\n",
        "    \"items\": results,\n",
        "}, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
        "print(\"Saved to\", save_path)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
