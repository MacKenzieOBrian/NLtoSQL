{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Validate the QLoRA training set (ClassicModels)\n",
        "\n",
        "This notebook **does not generate** training data. Instead, it validates that an existing JSONL training set executes cleanly on the ClassicModels database and does **not** overlap the fixed 200-item benchmark test set.\n",
        "\n",
        "## Inputs\n",
        "- Benchmark test set (fixed): `data/classicmodels_test_200.json`\n",
        "- Training set (pre-generated): `data/train/classicmodels_train_200.jsonl`\n",
        "\n",
        "## Checks performed\n",
        "- **Train/test leakage**: rejects exact NLQ overlaps with the benchmark NLQs\n",
        "- **SELECT-only**: rejects non-SELECT statements\n",
        "- **Executability (VA)**: runs each SQL against the live DB to confirm it executes\n",
        "\n",
        "## Output\n",
        "- A small validation report printed in the notebook output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# If running in Colab: install dependencies\n",
        "try:\n",
        "    import google.colab  # noqa: F401\n",
        "    !pip -q install -r requirements.txt\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "import json\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "from sqlalchemy import text\n",
        "\n",
        "from nl2sql.db import create_engine_with_connector\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e7c75b7",
      "metadata": {},
      "source": [
        "## 1) Configure DB connection\n",
        "\n",
        "This uses the same environment variables as the other notebooks:\n",
        "\n",
        "- `INSTANCE_CONNECTION_NAME` (e.g. `project:region:instance`)\n",
        "- `DB_USER`\n",
        "- `DB_PASS`\n",
        "- `DB_NAME` (usually `classicmodels`)\n",
        "\n",
        "If they are not set, the notebook will prompt you.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acbb8b35",
      "metadata": {},
      "outputs": [],
      "source": [
        "from getpass import getpass\n",
        "\n",
        "INSTANCE_CONNECTION_NAME = os.getenv('INSTANCE_CONNECTION_NAME')\n",
        "DB_USER = os.getenv('DB_USER')\n",
        "DB_PASS = os.getenv('DB_PASS')\n",
        "DB_NAME = os.getenv('DB_NAME') or 'classicmodels'\n",
        "\n",
        "if not INSTANCE_CONNECTION_NAME:\n",
        "    INSTANCE_CONNECTION_NAME = input('Enter INSTANCE_CONNECTION_NAME: ').strip()\n",
        "if not DB_USER:\n",
        "    DB_USER = input('Enter DB_USER: ').strip()\n",
        "if not DB_PASS:\n",
        "    DB_PASS = getpass('Enter DB_PASS: ')\n",
        "\n",
        "engine, connector = create_engine_with_connector(\n",
        "    instance_connection_name=INSTANCE_CONNECTION_NAME,\n",
        "    user=DB_USER,\n",
        "    password=DB_PASS,\n",
        "    db_name=DB_NAME,\n",
        ")\n",
        "\n",
        "with engine.connect() as conn:\n",
        "    conn.execute(text('SELECT 1')).fetchone()\n",
        "print('DB connection OK')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Load benchmark + training set\n",
        "\n",
        "The benchmark is fixed at 200 items. The training set must be separate (no exact NLQ overlap).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_path = Path('data/classicmodels_test_200.json')\n",
        "train_path = Path('data/train/classicmodels_train_200.jsonl')\n",
        "\n",
        "test_items = json.loads(test_path.read_text(encoding='utf-8'))\n",
        "test_nlqs = {x['nlq'].strip() for x in test_items}\n",
        "\n",
        "train_records = []\n",
        "for line in train_path.read_text(encoding='utf-8').splitlines():\n",
        "    line = line.strip()\n",
        "    if not line:\n",
        "        continue\n",
        "    train_records.append(json.loads(line))\n",
        "\n",
        "print('Test items:', len(test_items))\n",
        "print('Train items:', len(train_records))\n",
        "\n",
        "# Basic shape checks\n",
        "for i, r in enumerate(train_records[:5]):\n",
        "    assert 'nlq' in r and 'sql' in r, f'Missing keys at row {i}: {r}'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Leakage + safety checks\n",
        "\n",
        "- **Leakage** is defined here as an *exact NLQ string match* between train and test.\n",
        "- **Safety** is defined as `SELECT`-only.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "overlap = []\n",
        "non_select = []\n",
        "deduped = []\n",
        "seen = set()\n",
        "\n",
        "for idx, r in enumerate(train_records):\n",
        "    nlq = str(r['nlq']).strip()\n",
        "    sql = str(r['sql']).strip()\n",
        "\n",
        "    if nlq in test_nlqs:\n",
        "        overlap.append((idx, nlq))\n",
        "        continue\n",
        "\n",
        "    if not sql.lower().lstrip().startswith('select'):\n",
        "        non_select.append((idx, nlq, sql[:120]))\n",
        "        continue\n",
        "\n",
        "    key = nlq\n",
        "    if key in seen:\n",
        "        continue\n",
        "    seen.add(key)\n",
        "    deduped.append({'nlq': nlq, 'sql': sql if sql.endswith(';') else sql + ';'})\n",
        "\n",
        "print('Exact NLQ overlaps with test:', len(overlap))\n",
        "print('Non-SELECT rows:', len(non_select))\n",
        "print('After NLQ-dedup:', len(deduped))\n",
        "\n",
        "if overlap[:5]:\n",
        "    print('First overlaps:')\n",
        "    for i, nlq in overlap[:5]:\n",
        "        print('  -', i, nlq)\n",
        "\n",
        "if non_select[:5]:\n",
        "    print('First non-SELECT rows:')\n",
        "    for i, nlq, sql_snip in non_select[:5]:\n",
        "        print('  -', i, nlq, '->', sql_snip)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Executability validation (VA)\n",
        "\n",
        "This runs each SQL query against the database. A query is considered executable if it runs without raising an exception.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "failed = []\n",
        "\n",
        "with engine.connect() as conn:\n",
        "    for idx, r in enumerate(deduped):\n",
        "        sql = r['sql']\n",
        "        try:\n",
        "            # Execute and fetch a tiny sample to force evaluation without pulling huge results.\n",
        "            res = conn.execute(text(sql))\n",
        "            res.fetchmany(1)\n",
        "        except Exception as e:\n",
        "            failed.append((idx, r['nlq'], sql, repr(e)))\n",
        "\n",
        "print('Executable (VA=True):', len(deduped) - len(failed), '/', len(deduped))\n",
        "print('Failed:', len(failed))\n",
        "\n",
        "if failed[:5]:\n",
        "    print('First failures:')\n",
        "    for i, nlq, sql, err in failed[:5]:\n",
        "        print('---')\n",
        "        print('row:', i)\n",
        "        print('nlq:', nlq)\n",
        "        print('sql:', sql)\n",
        "        print('err:', err)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Next step\n",
        "\n",
        "If failures are **0**, proceed to `notebooks/05_qlora_train_eval.ipynb` to fine-tune + evaluate.\n",
        "\n",
        "If there are failures, fix the problematic rows in `data/train/classicmodels_train_200.jsonl` and re-run this notebook.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
