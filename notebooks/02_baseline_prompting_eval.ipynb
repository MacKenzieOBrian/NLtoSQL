{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "962754b6",
   "metadata": {},
   "source": [
    "# Baseline NL→SQL Evaluation (Zero-shot vs Few-shot)\n",
    "\n",
    "This notebook is the baseline replication block for Ojuri et al. (2025): it measures prompting effects (`k=0` vs `k=3`) on the same 200-item ClassicModels test set using an open-source local stack.\n",
    "\n",
    "Primary role in dissertation:\n",
    "- establish non-fine-tuned reference metrics,\n",
    "- isolate prompting gains before QLoRA,\n",
    "- provide controlled inputs for later paired comparisons.\n",
    "\n",
    "This notebook runs the VA/EX baseline over `data/classicmodels_test_200.json` and saves outputs under `results/baseline/`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d66939",
   "metadata": {},
   "source": [
    "Run this setup in a fresh GPU runtime, then restart before continuing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f6773c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "set -e\n",
    "export PIP_DEFAULT_TIMEOUT=120\n",
    "\n",
    "# Clean conflicting preinstalls\n",
    "pip uninstall -y torch torchvision torchaudio bitsandbytes triton transformers accelerate peft trl datasets numpy pandas fsspec requests google-auth scipy scikit-learn || true\n",
    "\n",
    "# Base deps\n",
    "pip install -q --no-cache-dir --force-reinstall \\\n",
    "  numpy==1.26.4 pandas==2.2.1 scipy scikit-learn \\\n",
    "  fsspec==2024.5.0 requests==2.31.0 google-auth==2.43.0\n",
    "\n",
    "# Torch + CUDA 12.1\n",
    "pip install -q --no-cache-dir --force-reinstall \\\n",
    "  torch==2.3.1+cu121 torchvision==0.18.1+cu121 torchaudio==2.3.1+cu121 \\\n",
    "  --index-url https://download.pytorch.org/whl/cu121\n",
    "\n",
    "# bitsandbytes + triton + HF stack\n",
    "pip install -q --no-cache-dir --force-reinstall \\\n",
    "  bitsandbytes==0.43.3 triton==2.3.1 \\\n",
    "  transformers==4.44.2 accelerate==0.33.0 peft==0.17.0 trl==0.9.6 datasets==2.20.0\n",
    "\n",
    "echo \"Setup complete. Restart runtime once, then run the rest of the notebook top-to-bottom.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b335da04",
   "metadata": {},
   "source": [
    "After restart, continue with DB/auth, schema, model, and eval cells."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82818187",
   "metadata": {},
   "source": [
    "Prompt/eval: build prompts (system+schema+k exemplars), generate SQL, postprocess, and compute VA/EX/EM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba5f922",
   "metadata": {},
   "source": [
    "**Docs (schema prompts):** NL→SQL schema-grounded prompting survey https://arxiv.org/abs/2410.06011; Spider-style listings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd30aacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# If this notebook is opened directly in Colab (not from a cloned repo), clone the repo first.\n",
    "if Path(\"data/classicmodels_test_200.json\").exists() is False and Path(\"/content\").exists():\n",
    "    repo_dir = Path(\"/content/NLtoSQL\")\n",
    "    if repo_dir.exists():\n",
    "        shutil.rmtree(repo_dir)\n",
    "    !git clone https://github.com/MacKenzieOBrian/NLtoSQL.git \"{repo_dir}\"\n",
    "    os.chdir(repo_dir)\n",
    "\n",
    "# Ensure repo root is on sys.path for `import nl2sql`\n",
    "sys.path.insert(0, os.getcwd())\n",
    "print(\"cwd:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a65e12",
   "metadata": {},
   "source": [
    "## Install dependencies (Colab)\n",
    "\n",
    "This repo pins versions in `requirements.txt` to reduce Colab binary drift.\n",
    "After installation, restart the runtime (Runtime → Restart runtime), then run this notebook again from the top.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4a0263",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab  # noqa: F401\n",
    "    IN_COLAB = True\n",
    "except Exception:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    !pip -q install -r requirements.txt\n",
    "else:\n",
    "    print(\"Not in Colab; ensure requirements are installed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644e4296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colab-only: authenticate with GCP (safe to skip locally)\n",
    "try:\n",
    "    from google.colab import auth\n",
    "except ModuleNotFoundError:\n",
    "    auth = None\n",
    "\n",
    "if auth:\n",
    "    auth.authenticate_user()\n",
    "else:\n",
    "    print(\"Not running in Colab; ensure ADC or service account auth is configured.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a375d04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hugging Face auth (gated model)\n",
    "import os\n",
    "\n",
    "hf_token = os.getenv(\"HF_TOKEN\") or os.getenv(\"HUGGINGFACE_HUB_TOKEN\")\n",
    "if hf_token:\n",
    "    os.environ[\"HUGGINGFACE_HUB_TOKEN\"] = hf_token\n",
    "    print(\"Using HF token from env\")\n",
    "else:\n",
    "    try:\n",
    "        from huggingface_hub import notebook_login\n",
    "        notebook_login()\n",
    "    except Exception as e:\n",
    "        print(\"HF auth not configured:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8db21f",
   "metadata": {},
   "source": [
    "**Docs (auth/DB):** Cloud SQL connector pattern https://cloud.google.com/sql/docs/mysql/connect-run; SQLAlchemy creator hook https://docs.sqlalchemy.org/en/20/core/engines.html#custom-dbapi-connect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc093bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from getpass import getpass\n",
    "\n",
    "INSTANCE_CONNECTION_NAME = os.getenv(\"INSTANCE_CONNECTION_NAME\")\n",
    "DB_USER = os.getenv(\"DB_USER\")\n",
    "DB_PASS = os.getenv(\"DB_PASS\")\n",
    "DB_NAME = os.getenv(\"DB_NAME\", \"classicmodels\")\n",
    "\n",
    "if not INSTANCE_CONNECTION_NAME:\n",
    "    INSTANCE_CONNECTION_NAME = input(\"Enter INSTANCE_CONNECTION_NAME: \").strip()\n",
    "if not DB_USER:\n",
    "    DB_USER = input(\"Enter DB_USER: \").strip()\n",
    "if not DB_PASS:\n",
    "    DB_PASS = getpass(\"Enter DB_PASS: \")\n",
    "\n",
    "print(\"Using DB:\", DB_NAME)\n",
    "\n",
    "test_set = json.loads(open(\"data/classicmodels_test_200.json\", \"r\", encoding=\"utf-8\").read())\n",
    "print(\"Loaded test items:\", len(test_set))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa43392",
   "metadata": {},
   "source": [
    "**Docs (auth/DB):** Cloud SQL connector pattern https://cloud.google.com/sql/docs/mysql/connect-run; SQLAlchemy creator hook https://docs.sqlalchemy.org/en/20/core/engines.html#custom-dbapi-connect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1016babb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nl2sql.db import create_engine_with_connector\n",
    "\n",
    "engine, connector = create_engine_with_connector(\n",
    "    instance_connection_name=INSTANCE_CONNECTION_NAME,\n",
    "    user=DB_USER,\n",
    "    password=DB_PASS,\n",
    "    db_name=DB_NAME,\n",
    ")\n",
    "\n",
    "print(\"Engine ready\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b951b4",
   "metadata": {},
   "source": [
    "**Ref:** HF Transformers 4-bit load with BitsAndBytes (quantization docs: https://huggingface.co/docs/transformers/main_classes/quantization). Mirrors PEFT/QLoRA examples for gated Llama 3; keeps model within Colab GPU VRAM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de77bc5",
   "metadata": {},
   "source": [
    "**Docs (model load):** HF 4-bit NF4 quantization https://huggingface.co/docs/transformers/main_classes/quantization; PEFT/QLoRA https://huggingface.co/docs/peft/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9070492",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "MODEL_ID = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "\n",
    "print(\"Loading tokenizer...\")\n",
    "tok = AutoTokenizer.from_pretrained(MODEL_ID, token=True)\n",
    "if tok.pad_token is None:\n",
    "    tok.pad_token = tok.eos_token\n",
    "\n",
    "# Try 4-bit loading (fallback to fp/bf16)\n",
    "try:\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    )\n",
    "    print(\"Attempting 4-bit quantized load...\")\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_ID,\n",
    "        quantization_config=bnb_config,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        device_map=\"auto\",\n",
    "        token=True,\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(\"4-bit load failed, falling back. Error:\")\n",
    "    print(e)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_ID,\n",
    "        torch_dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float32,\n",
    "        device_map=\"auto\" if torch.cuda.is_available() else None,\n",
    "        token=True,\n",
    "    )\n",
    "\n",
    "model.generation_config.do_sample = False\n",
    "model.generation_config.num_beams = 1\n",
    "\n",
    "print(\"Model device:\", model.device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb7e719",
   "metadata": {},
   "source": [
    "**Ref:** Schema summary helper from this repo (`nl2sql.schema`) following schema-grounded NL→SQL prompting practice (see survey: https://arxiv.org/abs/2410.06011). Including table/column context reduces column/join errors in zero/few-shot prompts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e11cb75",
   "metadata": {},
   "source": [
    "**Docs (schema prompts):** NL→SQL schema-grounded prompting survey https://arxiv.org/abs/2410.06011; Spider-style listings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274de10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nl2sql.schema import build_schema_summary\n",
    "\n",
    "SCHEMA_SUMMARY = build_schema_summary(engine, db_name=DB_NAME, max_cols_per_table=50)\n",
    "print(\"Schema summary built (chars):\", len(SCHEMA_SUMMARY))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382bccdf",
   "metadata": {},
   "source": [
    "**Ref:** Repo evaluation harness (`nl2sql.eval`) implementing VA/EX/EM execution-based metrics (semantic accuracy per EMNLP'20 TS work: https://aclanthology.org/2020.emnlp-main.29/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed10dfaa",
   "metadata": {},
   "source": [
    "**Docs (prompt/eval):** ICL patterns https://arxiv.org/abs/2005.14165; execution-based metrics (VA/EX) https://aclanthology.org/2020.emnlp-main.29/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89802cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "from nl2sql.eval import eval_run\n",
    "\n",
    "try:\n",
    "    commit = subprocess.check_output([\"git\", \"rev-parse\", \"--short\", \"HEAD\"]).decode().strip()\n",
    "except Exception:\n",
    "    commit = \"unknown\"\n",
    "run_metadata = {\n",
    "    \"commit\": commit,\n",
    "    \"model_id\": MODEL_ID,\n",
    "    \"notebook\": \"02_baseline_prompting_eval.ipynb\",\n",
    "}\n",
    "\n",
    "Path(\"results/baseline\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Quick smoke test\n",
    "# _ = eval_run(test_set=test_set, k=0, limit=20, seed=7, engine=engine, model=model, tokenizer=tok, schema_summary=SCHEMA_SUMMARY,\n",
    "#              save_path=\"results/baseline/results_zero_shot_20.json\", run_metadata=run_metadata)\n",
    "\n",
    "# Full run (n=200)\n",
    "zero_200 = eval_run(\n",
    "    test_set=test_set,\n",
    "    exemplar_pool=test_set,\n",
    "    k=0,\n",
    "    limit=None,\n",
    "    seed=7,\n",
    "    engine=engine,\n",
    "    model=model,\n",
    "    tokenizer=tok,\n",
    "    schema_summary=SCHEMA_SUMMARY,\n",
    "    save_path=\"results/baseline/results_zero_shot_200.json\",\n",
    "    run_metadata=run_metadata,\n",
    "    avoid_exemplar_leakage=True,\n",
    ")\n",
    "\n",
    "few_200 = eval_run(\n",
    "    test_set=test_set,\n",
    "    exemplar_pool=test_set,\n",
    "    k=3,\n",
    "    limit=None,\n",
    "    seed=7,\n",
    "    engine=engine,\n",
    "    model=model,\n",
    "    tokenizer=tok,\n",
    "    schema_summary=SCHEMA_SUMMARY,\n",
    "    save_path=\"results/baseline/results_few_shot_k3_200.json\",\n",
    "    run_metadata=run_metadata,\n",
    "    avoid_exemplar_leakage=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e435ec69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick summary (reads the saved JSON outputs)\n",
    "import json\n",
    "\n",
    "zero = json.loads(open(\"results/baseline/results_zero_shot_200.json\", \"r\", encoding=\"utf-8\").read())\n",
    "few  = json.loads(open(\"results/baseline/results_few_shot_k3_200.json\", \"r\", encoding=\"utf-8\").read())\n",
    "\n",
    "print(\"Zero-shot:\", \"VA\", round(zero[\"va_rate\"], 3), \"EM\", round(zero.get(\"em_rate\", 0.0), 3), \"EX\", round(zero[\"ex_rate\"], 3))\n",
    "print(\"Few-shot:\",  \"VA\", round(few[\"va_rate\"], 3),  \"EM\", round(few.get(\"em_rate\", 0.0), 3),  \"EX\", round(few[\"ex_rate\"], 3))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
