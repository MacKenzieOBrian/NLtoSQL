# Reflection Logbook

This logbook records weekly activities, challenges, decisions, insights, and reflections during the NL→SQL dissertation project. The project reproduces the methodology of Ojuri et al. (2025) using open-source models, with emphasis on reproducibility, evaluation, and compute feasibility.

---

## Week of 2025-09-29 — Project Anchoring and Scope Formation

**Activities**
- Initial supervisor meeting
- Drafted outline
- Seed literature review on NL→SQL, ReAct, PEFT, and QLoRA

**Challenges**
- Scope initially too broad; risk of drifting into descriptive “LLM essay”

**Insights**
- NL→SQL is a structured generation task requiring execution-based evaluation (VA/EX/TS)

**Decisions**
- Define scope as reproduction of Ojuri et al. (2025) using open-source models

**Reflection**
This week shifted the project from diffuse ideas into a constrained research problem with feasibility and methodological grounding.

---

## Week of 2025-10-06 — Tooling and Method Discipline

**Activities**
- Expanded outline (~2000 words)
- Drafted ethics application
- Set up citation infrastructure (Zotero)

**Challenges**
- State of the art overly descriptive; lacked critique

**Decisions**
- Treat literature as comparisons of methods rather than catalog of capabilities

**Reflection**
The project began to adopt the language of methodology rather than literature summary, which is essential for dissertation rigor.

---

## Week of 2025-10-13 — Ethics and Academic Writing Tone

**Activities**
- Finalised ethics submission
- Added linking paragraphs between theory and implementation

**Challenges**
- Bridging conceptual writing with system design narrative

**Reflection**
Learned that NL→SQL literature must be contextualised by architectural implications (schema linking, execution feedback).

---

## Week of 2025-10-20 — Research Engineering Plan

**Activities**
- Produced timeline, SMART objectives, MoSCoW priorities
- Defined VA/EX/TS evaluation metrics
- Classified proprietary vs open-source feasibility
- Selected ClassicModels domain

**Insights**
- Reproducibility gap is itself a contribution

**Decisions**
- Baseline strategy: prompting → fine-tuning → agent loop

---

## Week of 2025-10-27 — Infrastructure Pivot

**Activities**
- Migrated storage layer from SQLite to Cloud SQL (MySQL)
- Added secure connector and SQLAlchemy integration
- Introduced `QueryRunner` abstraction

**Challenges**
- Hardcoded secrets pending proper configuration

**Reflection**
Execution feedback became technically possible; agent loops require an executable SQL environment.

---

## Week of 2025-11-03 — System Becomes Testable

**Activities**
- Schema introspection implementation
- QueryRunner smoke tests
- Minimal prompting + execution pipeline working

**Insights**
- VA cannot be computed without deterministic SQL execution layer

**Reflection**
System formed an evaluable pipeline even before model quality was good.

---

## Week of 2025-11-10 — Dataset Planning and Conceptual Shift

**Activities**
- Designed dataset schema (NL, SQL, schema)
- Reviewed ReAct + QLoRA papers

**Insights**
- Few-shot prompting is a hypothesis, not a solution

---

## Week of 2025-11-17 — QLoRA Feasibility Tests

**Activities**
- Implemented QLoRA scaffolding
- Generated ~100 prototype training examples

**Challenges**
- BitsAndBytes instability on Colab
- VRAM constraints during tokenization + batching

**Insights**
- NF4 quantization and LoRA adapters are necessary for 8B models on consumer GPUs

**Decisions**
- Fixed dataset format: `{schema, nl, sql}`

---

## Week of 2025-12-02 — System Consolidation

**Activities**
- Created final ~200-item training set
- Ensured evaluation test set is disjoint
- Restructured repo (ARCHITECTURE, CONFIG, DATA, NOTEBOOKS)

**Reflection**
System transitioned from exploratory notebooks into structured research instrument.

---

## Week of 2025-12-04 → 2025-12-12 — Reproducibility Hardening

**Activities**
- Validated gold SQL executes 200/200
- Pinned dependencies in `requirements.txt`
- Added deterministic decoding settings
- Logged schema + exemplar ordering
- Removed confirmatory bias during exemplar selection

**Insights**
- Determinism is necessary for fair baseline comparisons

**Reflection**
Reproducibility work is undervalued but crucial in ML systems research.

---

## Week of 2025-12-14 — Prompting Baseline Achieved

**Activities**
- Implemented zero-shot and few-shot prompting baselines
- Added SQL post-processing for column extraction

**Results**
- Zero-shot: VA=0.810 / EX=0.000
- Few-shot (k=3): VA=0.865 / EX=0.250

**Reflection**
Prompting alone achieved non-trivial execution accuracy; schema-awareness mattered significantly.

---

## Week of 2025-12-23 — Evaluation Rigour

**Activities**
- Refactored baselines into callable evaluation harness
- Introduced batch evaluation

**Insights**
- Surface exact match insufficient; TS required for semantic correctness

---

## January 2026 — First QLoRA Fine-Tuning Runs

**Activities**
- Fine-tuned QLoRA (r=16, 1 epoch, 4-bit)
- Loaded adapters and re-evaluated test set

**Results**
k=0 → VA 0.73 / EX 0.03
k=3 → VA 0.86 / EX 0.305


**Interpretation**
- Fine-tuning did not exceed exemplar-augmented prompting baseline yet
- Prompting contributed strongest performance gains

**Next Steps**
- Hyperparameter tuning
- Expand exemplar pool
- Implement TS evaluation
- Integrate agent loop

**Reflection**
Null results were scientifically informative; model adaptation is non-trivial under data constraints.

---

## January 2026 — Second QLoRA Run (improved VA, low EX)

**Activities**
- Re-ran QLoRA with higher LoRA capacity and longer training (3 epochs, r=32/α=64, warmup).
- Evaluated adapter-only on ClassicModels-200.

**Results**
- k=0 → VA 0.865 / EM 0.000 / EX 0.065 (saved to `results/qlora/results_zero_shot_200.json`).

**Interpretation**
- Executability improved sharply vs first run (VA 0.73→0.865), but semantic correctness remains low (EX 0.065).
- Indicates better syntactic grounding from training, but still insufficient result-set accuracy without exemplars or refinement.

**Next Steps**
- Consider more steps or slightly higher LR with warmup; evaluate k=3 with a clean exemplar pool; add TS/agentic refinement to target semantic accuracy.

**Reflection**
Gains in VA alone are not enough; future work must raise EX to surpass the few-shot baseline.
