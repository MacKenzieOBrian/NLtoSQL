# References (Named, Linked)

Primary-source papers (benchmark papers, methods papers, and official proceedings)
are prioritized for technical claims in this dissertation.

1. <a id="ref-li2023-bigbench"></a> J. Li et al., "Can LLM Already Serve as a Database Interface? A BIg Bench for Large-Scale Database Grounded Text-to-SQLs," arXiv:2305.03111, May 30, 2023. DOI: 10.48550/arXiv.2305.03111.
2. <a id="ref-zhai2025-excot"></a> B. Zhai, C. Xu, Y. He, and Z. Yao, "ExCoT: Optimizing Reasoning for Text-to-SQL with Execution Feedback," arXiv:2503.19988, Mar. 27, 2025. DOI: 10.48550/arXiv.2503.19988.
3. <a id="ref-mosbach2023-icl"></a> M. Mosbach, T. Pimentel, S. Ravfogel, D. Klakow, and Y. Elazar, "Few-shot Fine-tuning vs. In-context Learning: A Fair Comparison and Evaluation," arXiv:2305.16938, May 30, 2023. DOI: 10.48550/arXiv.2305.16938.
4. <a id="ref-modal2025-vram"></a> Modal, "How much VRAM do I need for LLM model fine-tuning?," accessed Oct. 24, 2025. URL: https://modal.com/blog/how-much-vram-need-fine-tuning
5. <a id="ref-mercity2025-qlora"></a> Mercity, "In-depth guide to fine-tuning LLMs with LoRA and QLoRA," accessed Oct. 24, 2025. URL: https://www.mercity.ai/blog-post/guide-to-fine-tuning-llms-with-lora-and-qlora
6. <a id="ref-brown2020-gpt3"></a> T. Brown et al., "Language Models are Few-Shot Learners," Advances in Neural Information Processing Systems, vol. 33, pp. 1877–1901, 2020.
7. <a id="ref-capraro2024-language-game"></a> V. Capraro, R. Di Paolo, M. Perc, and V. Pizziol, "Language-based game theory in the age of artificial intelligence," Journal of The Royal Society Interface, vol. 21, no. 212, p. 20230720, Mar. 2024. DOI: 10.1098/rsif.2023.0720.
8. <a id="ref-zhu2024-survey"></a> X. Zhu, Q. Li, L. Cui, and Y. Liu, "Large Language Model Enhanced Text-to-SQL Generation: A Survey," arXiv:2410.06011, Oct. 8, 2024. DOI: 10.48550/arXiv.2410.06011.
9. <a id="ref-hong2025-survey"></a> Z. Hong et al., "Next-Generation Database Interfaces: A Survey of LLM-based Text-to-SQL," arXiv:2406.08426, Sep. 16, 2025. DOI: 10.48550/arXiv.2406.08426.
10. <a id="ref-ojuri2025-agents"></a> S. Ojuri, T. A. Han, R. Chiong, and A. Di Stefano, "Optimizing text-to-SQL conversion techniques through the integration of intelligent agents and large language models," Information Processing & Management, vol. 62, no. 5, p. 104136, Sep. 2025. DOI: 10.1016/j.ipm.2025.104136.
11. <a id="ref-goswami2024-peft"></a> J. Goswami, K. K. Prajapati, A. Saha, and A. K. Saha, "Parameter-efficient fine-tuning large language model approach for hospital discharge paper summarization," Applied Soft Computing, vol. 157, p. 111531, May 2024. DOI: 10.1016/j.asoc.2024.111531.
12. <a id="ref-ding2023-peft"></a> N. Ding et al., "Parameter-efficient fine-tuning of large-scale pre-trained language models," Nature Machine Intelligence, vol. 5, no. 3, pp. 220–235, Mar. 2023. DOI: 10.1038/s42256-023-00626-4.
13. <a id="ref-scholak2021-picard"></a> T. Scholak, N. Schucher, and D. Bahdanau, "PICARD: Parsing Incrementally for Constrained Auto-Regressive Decoding from Language Models," arXiv:2109.05093, Sep. 10, 2021. DOI: 10.48550/arXiv.2109.05093.
14. <a id="ref-velasquez2023-prompteng"></a> J. D. Velásquez-Henao, C. J. Franco-Cardona, and L. Cadavid-Higuita, "Prompt Engineering: a methodology for optimizing interactions with AI-Language Models in the field of engineering," accessed Oct. 24, 2025. URL: http://www.scielo.org.co/scielo.php?pid=S0012-73532023000600009&script=sci_arttext
15. <a id="ref-velasquez2023-prompteng-dup"></a> J. D. Velásquez-Henao, C. J. Franco-Cardona, and L. Cadavid-Higuita, "Prompt Engineering: a methodology for optimizing interactions with AI-Language Models in the field of engineering," accessed Oct. 22, 2025. URL: http://www.scielo.org.co/scielo.php?pid=S0012-73532023000600009&script=sci_arttext
16. <a id="ref-yao2023-react"></a> S. Yao et al., "ReAct: Synergizing Reasoning and Acting in Language Models," arXiv:2210.03629, Mar. 10, 2023. DOI: 10.48550/arXiv.2210.03629.
17. <a id="ref-li2023-resdsql"></a> H. Li, J. Zhang, C. Li, and H. Chen, "RESDSQL: Decoupling Schema Linking and Skeleton Parsing for Text-to-SQL," Proceedings of the AAAI Conference on Artificial Intelligence, vol. 37, no. 11, pp. 13067–13075, Jun. 2023. DOI: 10.1609/aaai.v37i11.26535.
18. <a id="ref-zhong2020-ts"></a> R. Zhong, T. Yu, and D. Klein, "Semantic Evaluation for Text-to-SQL with Distilled Test Suites," Proceedings of EMNLP 2020, pp. 396–411, Nov. 2020. DOI: 10.18653/v1/2020.emnlp-main.29.
19. <a id="ref-yu2018-spider"></a> T. Yu et al., "Spider: A Large-Scale Human-Labeled Dataset for Complex and Cross-Domain Semantic Parsing and Text-to-SQL Task," Proceedings of EMNLP 2018, pp. 3911–3921, Oct. 2018. DOI: 10.18653/v1/D18-1425.
20. <a id="ref-gao2025-llm-sql"></a> D. Gao et al., "Text-to-SQL Empowered by Large Language Models: A Benchmark Evaluation," arXiv:2308.15363v4, accessed Nov. 13, 2025. URL: https://arxiv.org/abs/2308.15363v4
21. <a id="ref-xi2025-agents"></a> Z. Xi et al., "The rise and potential of large language model based agents: a survey," Science China Information Sciences, vol. 68, no. 2, pp. 1–44, Jan. 2025. DOI: 10.1007/s11432-024-4222-0.
22. <a id="ref-wang2020-ratsql"></a> B. Wang et al., "RAT-SQL: Relation-Aware Schema Encoding and Linking for Text-to-SQL Parsers," Proceedings of ACL 2020, Aug. 2020. DOI: 10.18653/v1/2020.acl-main.677.
23. <a id="ref-lin2020-bridge"></a> X. V. Lin et al., "Bridging Textual and Tabular Data for Cross-Domain Text-to-SQL Semantic Parsing," Findings of EMNLP 2020, Nov. 2020. DOI: 10.18653/v1/2020.findings-emnlp.438.
24. <a id="ref-guo2019-irnet"></a> J. Guo et al., "Towards Complex Text-to-SQL in Cross-Domain Database with Intermediate Representation," Proceedings of ACL 2019, Jul. 2019. DOI: 10.18653/v1/P19-1444.
25. <a id="ref-wang2018-eg-decoding"></a> C. Wang et al., "Robust Text-to-SQL Generation with Execution-Guided Decoding," arXiv preprint, Sep. 2018. URL: https://www.microsoft.com/en-us/research/publication/robust-text-to-sql-generation-with-execution-guided-decoding/
26. <a id="ref-pourreza2023-dinsql"></a> M. Pourreza and D. Rafiei, "DIN-SQL: Decomposed In-Context Learning of Text-to-SQL with Self-Correction," arXiv:2304.11015, Apr. 2023. DOI: 10.48550/arXiv.2304.11015.
27. <a id="ref-sun2023-sqlpalm"></a> R. Sun et al., "SQL-PaLM: Improved Large Language Model Adaptation for Text-to-SQL," arXiv:2306.00739, Jun. 2023. DOI: 10.48550/arXiv.2306.00739.
28. <a id="ref-hu2021-lora"></a> E. J. Hu, Y. Shen, P. Wallis, Z. Allen-Zhu, Y. Li, S. Wang, L. Wang, and W. Chen, "LoRA: Low-Rank Adaptation of Large Language Models," arXiv:2106.09685, Jun. 2021. DOI: 10.48550/arXiv.2106.09685.
29. <a id="ref-dettmers2023-qlora"></a> T. Dettmers, A. Pagnoni, A. Holtzman, and L. Zettlemoyer, "QLoRA: Efficient Finetuning of Quantized LLMs," arXiv:2305.14314, May 2023. DOI: 10.48550/arXiv.2305.14314.
30. <a id="ref-yu2019-sparc"></a> T. Yu et al., "SParC: Cross-Domain Semantic Parsing in Context," Proceedings of ACL 2019, pp. 4511-4523, Jul. 2019. DOI: 10.18653/v1/P19-1443.
31. <a id="ref-yu2019-cosql"></a> T. Yu et al., "CoSQL: A Conversational Text-to-SQL Challenge Towards Cross-Domain Natural Language Interfaces to Databases," Proceedings of EMNLP-IJCNLP 2019, pp. 1962-1979, Nov. 2019. DOI: 10.18653/v1/D19-1204.
32. <a id="ref-dror2018-significance"></a> R. Dror, G. Baumer, S. Shlomov, and R. Reichart, "The Hitchhiker's Guide to Testing Statistical Significance in Natural Language Processing," Proceedings of ACL 2018, pp. 1383-1392, Jul. 2018. DOI: 10.18653/v1/P18-1128.
33. <a id="ref-mcnemar1947"></a> Q. McNemar, "Note on the Sampling Error of the Difference Between Correlated Proportions or Percentages," Psychometrika, vol. 12, no. 2, pp. 153-157, Jun. 1947. DOI: 10.1007/BF02295996.
34. <a id="ref-wilson1927"></a> E. B. Wilson, "Probable Inference, the Law of Succession, and Statistical Inference," Journal of the American Statistical Association, vol. 22, no. 158, pp. 209-212, Jun. 1927. DOI: 10.1080/01621459.1927.10502953.
35. <a id="ref-wolf2020-transformers"></a> T. Wolf et al., "Transformers: State-of-the-Art Natural Language Processing," Proceedings of EMNLP 2020: System Demonstrations, pp. 38-45, Oct. 2020. DOI: 10.18653/v1/2020.emnlp-demos.6.
36. <a id="ref-dubey2024-llama3"></a> A. Dubey et al., "The Llama 3 Herd of Models," arXiv:2407.21783, Jul. 2024. DOI: 10.48550/arXiv.2407.21783.
