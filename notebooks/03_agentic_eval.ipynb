{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c7beb01",
   "metadata": {},
   "source": [
    "# ReAct Eval\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "- Purpose: evaluate the tool-driven ReAct pipeline with traceable reasoning steps.\n",
    "- Scope: supports both interactive single-question demos and full benchmark execution.\n",
    "- Outputs: agent run artifacts and failure profiles under `results/agent/`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3e5edc",
   "metadata": {},
   "source": [
    "## 0) Install\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76a2f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%%bash\n",
    "set -e\n",
    "export PIP_DEFAULT_TIMEOUT=120\n",
    "\n",
    "# Clean conflicting preinstalls\n",
    "pip uninstall -y torch torchvision torchaudio bitsandbytes triton transformers accelerate peft trl datasets numpy pandas fsspec requests google-auth || true\n",
    "\n",
    "# Base deps\n",
    "pip install -q --no-cache-dir --force-reinstall   numpy==1.26.4 pandas==2.2.1 fsspec==2024.5.0 requests==2.31.0 google-auth==2.43.0\n",
    "\n",
    "# Torch + CUDA 12.1\n",
    "pip install -q --no-cache-dir --force-reinstall   torch==2.3.1+cu121 torchvision==0.18.1+cu121 torchaudio==2.3.1+cu121   --index-url https://download.pytorch.org/whl/cu121\n",
    "\n",
    "# bitsandbytes + triton + HF stack\n",
    "pip install -q --no-cache-dir --force-reinstall   bitsandbytes==0.43.3 triton==2.3.1   transformers==4.44.2 accelerate==0.33.0 peft==0.17.0 trl==0.9.6 datasets==2.20.0\n",
    "\n",
    "echo \"Setup complete. Restart runtime once, then run the rest of the notebook top-to-bottom.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f60137",
   "metadata": {},
   "source": [
    "## 1) Sync Repo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42aa8947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0) Clone repo (Colab) + install deps\n",
    "import os\n",
    "try:\n",
    "    import google.colab  # noqa: F401\n",
    "    IN_COLAB = True\n",
    "except Exception:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    if not os.path.exists('/content/NLtoSQL'):\n",
    "        !git clone https://github.com/MacKenzieOBrian/NLtoSQL.git /content/NLtoSQL\n",
    "    %cd /content/NLtoSQL\n",
    "    !pip -q install -r requirements.txt\n",
    "    import torch, transformers, accelerate, peft\n",
    "    print('torch', torch.__version__, 'cuda', torch.cuda.is_available())\n",
    "else:\n",
    "    print('Not in Colab; using existing workspace')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9647ef39",
   "metadata": {},
   "source": [
    "## 2) Auth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310b11b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this only if you prefer gcloud-based ADC (no JSON key)\n",
    "try:\n",
    "    import google.colab  # noqa: F401\n",
    "    IN_COLAB = True\n",
    "except Exception:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    %pip install -q --upgrade google-auth google-auth-oauthlib\n",
    "    !gcloud auth application-default login\n",
    "else:\n",
    "    print(\"Not in Colab; skip gcloud auth.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ca499c",
   "metadata": {},
   "source": [
    "## 3) DB Engine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf829a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Environment + DB\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "from sqlalchemy import text\n",
    "\n",
    "from nl2sql.db import create_engine_with_connector, safe_connection\n",
    "\n",
    "# Expected env vars (set these in a Colab cell):\n",
    "# INSTANCE_CONNECTION_NAME, DB_USER, DB_PASS, DB_NAME\n",
    "INSTANCE_CONNECTION_NAME = os.getenv(\"INSTANCE_CONNECTION_NAME\")\n",
    "DB_USER = os.getenv(\"DB_USER\")\n",
    "DB_PASS = os.getenv(\"DB_PASS\")\n",
    "DB_NAME = os.getenv(\"DB_NAME\") or \"classicmodels\"\n",
    "\n",
    "if not INSTANCE_CONNECTION_NAME:\n",
    "    INSTANCE_CONNECTION_NAME = input(\"Enter INSTANCE_CONNECTION_NAME: \").strip()\n",
    "if not DB_USER:\n",
    "    DB_USER = input(\"Enter DB_USER: \").strip()\n",
    "if not DB_PASS:\n",
    "    DB_PASS = getpass(\"Enter DB_PASS: \")\n",
    "\n",
    "# Canonical engine builder (shared with scripts + other notebooks).\n",
    "# Uses Cloud SQL Connector under the hood and ADC for credentials.\n",
    "engine, connector = create_engine_with_connector(\n",
    "    instance_connection_name=INSTANCE_CONNECTION_NAME,\n",
    "    user=DB_USER,\n",
    "    password=DB_PASS,\n",
    "    db_name=DB_NAME,\n",
    ")\n",
    "\n",
    "with safe_connection(engine) as conn:\n",
    "    conn.execute(text(\"SELECT 1\"))\n",
    "print(\"DB connection OK\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7a447a",
   "metadata": {},
   "source": [
    "## 4) TS Engines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79134dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1b) Engine factory for TS (multiple DB names)\n",
    "\n",
    "import sqlalchemy\n",
    "from sqlalchemy.engine import Engine\n",
    "\n",
    "\n",
    "def make_engine(db_name: str) -> Engine:\n",
    "    \"\"\"Create a new engine bound to a specific TS replica DB name.\n",
    "\n",
    "    TS (test-suite accuracy) executes the same (gold, pred) SQL across multiple\n",
    "    replica databases (classicmodels_ts_XX). We keep separate engines so each\n",
    "    replica is evaluated independently.\n",
    "    \"\"\"\n",
    "\n",
    "    def getconn_for_db():\n",
    "        return connector.connect(\n",
    "            INSTANCE_CONNECTION_NAME,\n",
    "            \"pymysql\",\n",
    "            user=DB_USER,\n",
    "            password=DB_PASS,\n",
    "            db=db_name,\n",
    "        )\n",
    "\n",
    "    return sqlalchemy.create_engine(\"mysql+pymysql://\", creator=getconn_for_db, future=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29403cf",
   "metadata": {},
   "source": [
    "## 5) Schema + Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6bf8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Load schema summary + test set + QueryRunner\n",
    "import json\n",
    "from pathlib import Path\n",
    "from nl2sql.schema import build_schema_summary\n",
    "from nl2sql.query_runner import QueryRunner\n",
    "\n",
    "SCHEMA_SUMMARY = build_schema_summary(engine, db_name=DB_NAME)\n",
    "print(\"Schema contains offices.city:\", \"offices\" in SCHEMA_SUMMARY.lower() and \"city\" in SCHEMA_SUMMARY.lower())\n",
    "\n",
    "test_path = Path(\"data/classicmodels_test_200.json\")\n",
    "full_set = json.loads(test_path.read_text(encoding=\"utf-8\"))\n",
    "\n",
    "# Default target is full benchmark evaluation (200 items).\n",
    "test_set = full_set\n",
    "print(\"Loaded test items:\", len(test_set))\n",
    "\n",
    "# Runner is used for local VA checks in demo sanity cells.\n",
    "runner = QueryRunner(engine)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6137ff",
   "metadata": {},
   "source": [
    "## 6) Load Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda9fa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Load model (base or QLoRA adapters)\n",
    "import os\n",
    "from getpass import getpass\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from peft import PeftModel\n",
    "\n",
    "MODEL_ID = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "# this model + adapter pair defines the react agent backbone.\n",
    "ADAPTER_PATH = os.getenv(\"ADAPTER_PATH\") or \"results/adapters/qlora_classicmodels\"  # set to None to use base model\n",
    "# set ADAPTER_PATH to None when you want base-model react runs.\n",
    "\n",
    "# Experiment knobs (change one axis at a time for comparable claims):\n",
    "# - MODEL_ID: switch model family (Llama/Qwen/etc).\n",
    "# - ADAPTER_PATH: set to local QLoRA adapter dir for tuned runs; set to None for base-model runs.\n",
    "# Keep all later loop/TS settings unchanged when isolating model effects.\n",
    "\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\") or os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "if not HF_TOKEN:\n",
    "    HF_TOKEN = getpass(\"Enter HF_TOKEN (https://huggingface.co/settings/tokens): \").strip()\n",
    "\n",
    "cc_major, cc_minor = torch.cuda.get_device_capability(0) if torch.cuda.is_available() else (0, 0)\n",
    "use_bf16 = cc_major >= 8\n",
    "compute_dtype = torch.bfloat16 if use_bf16 else torch.float16\n",
    "print(\"GPU:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\")\n",
    "print(\"Using bf16:\", use_bf16)\n",
    "print(\"Adapter path:\", ADAPTER_PATH)\n",
    "\n",
    "# Tokenizer\n",
    "tok = AutoTokenizer.from_pretrained(MODEL_ID, token=HF_TOKEN)\n",
    "if tok.pad_token is None:\n",
    "    tok.pad_token = tok.eos_token\n",
    "\n",
    "# Quantized base model\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    ")\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    quantization_config=bnb_config,\n",
    "    torch_dtype=compute_dtype,\n",
    "    device_map={\"\": 0} if torch.cuda.is_available() else None,\n",
    "    token=HF_TOKEN,\n",
    ")\n",
    "base_model.generation_config.do_sample = False\n",
    "base_model.generation_config.temperature = 1.0\n",
    "base_model.generation_config.top_p = 1.0\n",
    "\n",
    "# Load adapters if present locally; otherwise use base model\n",
    "adapter_dir = Path(ADAPTER_PATH) if ADAPTER_PATH else None\n",
    "if adapter_dir and adapter_dir.exists():\n",
    "    model = PeftModel.from_pretrained(base_model, adapter_dir, token=HF_TOKEN)\n",
    "    print(\"Loaded adapters from\", adapter_dir)\n",
    "else:\n",
    "    print(\"Adapter path missing; using base model only. Set ADAPTER_PATH to your local adapter folder or upload it to Colab.\")\n",
    "    model = base_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f03e11e",
   "metadata": {},
   "source": [
    "## 7) Pipeline Config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8474e827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ReAct module imports, context binding, and config ---\n",
    "from nl2sql.agent_tools import AgentContext, set_agent_context\n",
    "from nl2sql.react_pipeline import ReactAblationConfig, run_react_pipeline, evaluate_react_ablation\n",
    "from nl2sql.prompts import REACT_SYSTEM_PROMPT\n",
    "\n",
    "# Bind shared runtime context once.\n",
    "set_agent_context(\n",
    "    AgentContext(\n",
    "        engine=engine,\n",
    "        db_name=DB_NAME,\n",
    "        model=model,\n",
    "        tok=tok,\n",
    "        runner=runner,\n",
    "        max_new_tokens=128,\n",
    "    )\n",
    ")\n",
    "\n",
    "# ReAct config knobs (edit for controlled ablations).\n",
    "# keep these flags stable when you are only changing model/adapters.\n",
    "REACT_CONFIG_NAME = \"react_core_notebook\"\n",
    "REACT_USE_SCHEMA_LINK = True\n",
    "REACT_USE_CONSTRAINT_POLICY = True\n",
    "REACT_USE_REPAIR_POLICY = True\n",
    "REACT_USE_INTENT_GATE = False\n",
    "REACT_MAX_REPAIRS = 1\n",
    "REACT_LINK_MAX_TABLES = 6\n",
    "REACT_MAX_STEPS = 8\n",
    "REACT_MAX_NEW_TOKENS = 256\n",
    "REACT_DO_SAMPLE = False\n",
    "REACT_TEMPERATURE = 0.2\n",
    "REACT_TOP_P = 0.9\n",
    "\n",
    "REACT_CONFIG = ReactAblationConfig(\n",
    "    name=REACT_CONFIG_NAME,\n",
    "    use_schema_link=REACT_USE_SCHEMA_LINK,\n",
    "    use_constraint_policy=REACT_USE_CONSTRAINT_POLICY,\n",
    "    use_repair_policy=REACT_USE_REPAIR_POLICY,\n",
    "    use_intent_gate=REACT_USE_INTENT_GATE,\n",
    "    max_repairs=REACT_MAX_REPAIRS,\n",
    "    link_max_tables=REACT_LINK_MAX_TABLES,\n",
    "    max_steps=REACT_MAX_STEPS,\n",
    "    max_new_tokens=REACT_MAX_NEW_TOKENS,\n",
    "    do_sample=REACT_DO_SAMPLE,\n",
    "    temperature=REACT_TEMPERATURE,\n",
    "    top_p=REACT_TOP_P,\n",
    ")\n",
    "\n",
    "\n",
    "def summarize_trace_brief(trace: list[dict]) -> dict:\n",
    "    # Small notebook helper for readable demo output.\n",
    "    actions = [t.get(\"action\") for t in trace if t.get(\"action\")]\n",
    "    blocked_steps = sum(1 for t in trace if t.get(\"blocked\"))\n",
    "    stop_reason = next((t.get(\"reason\") for t in trace if t.get(\"action\") == \"stop\"), None)\n",
    "    return {\n",
    "        \"steps\": len(trace),\n",
    "        \"actions\": actions,\n",
    "        \"blocked_steps\": blocked_steps,\n",
    "        \"stop_reason\": stop_reason,\n",
    "    }\n",
    "\n",
    "print(\"Using pipeline module:\", run_react_pipeline.__module__)\n",
    "print(\"ReAct config:\", REACT_CONFIG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45c9413",
   "metadata": {},
   "source": [
    "## 9) Interactive Demo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e205536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12A) Interactive walkthrough (single NLQ trace)\n",
    "DEMO_INTERACTIVE = True\n",
    "DEMO_DEFAULT_NLQ = \"Which customers are in France?\"\n",
    "\n",
    "nlq = \"\"\n",
    "if DEMO_INTERACTIVE:\n",
    "    try:\n",
    "        nlq = input(\"Type a ClassicModels question (blank uses default): \").strip()\n",
    "    except Exception:\n",
    "        nlq = \"\"\n",
    "if not nlq:\n",
    "    nlq = DEMO_DEFAULT_NLQ\n",
    "\n",
    "pred_sql, trace = run_react_pipeline(nlq=nlq, config=REACT_CONFIG)\n",
    "summary = summarize_trace_brief(trace)\n",
    "\n",
    "print()\n",
    "print(\"FINAL SQL:\")\n",
    "print(pred_sql or \"(no prediction)\")\n",
    "print()\n",
    "print(\"TRACE SUMMARY:\")\n",
    "print(summary)\n",
    "if trace:\n",
    "    print()\n",
    "    print(\"LAST TRACE ENTRY:\")\n",
    "    print(trace[-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be998691",
   "metadata": {},
   "source": [
    "## 11) Run Controls\n",
    "This cell sets full-vs-quick mode and TS settings for the main ReAct evaluation run.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beacbd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Run controls ===\n",
    "# Default is full benchmark reporting.\n",
    "QUICK_LIMIT = None   # set to 20 for quick checks, None for full 200\n",
    "# quick_limit controls item count only; config logic stays the same.\n",
    "TS_N = 10            # set to 3 for faster debug, 10 for full TS\n",
    "MAX_ROWS_TS = 500\n",
    "TS_PREFIX = \"classicmodels_ts\"\n",
    "\n",
    "REACT_CONFIG = ReactAblationConfig(\n",
    "    name=REACT_CONFIG_NAME,\n",
    "    use_schema_link=REACT_USE_SCHEMA_LINK,\n",
    "    use_constraint_policy=REACT_USE_CONSTRAINT_POLICY,\n",
    "    use_repair_policy=REACT_USE_REPAIR_POLICY,\n",
    "    use_intent_gate=REACT_USE_INTENT_GATE,\n",
    "    max_repairs=REACT_MAX_REPAIRS,\n",
    "    link_max_tables=REACT_LINK_MAX_TABLES,\n",
    "    max_steps=REACT_MAX_STEPS,\n",
    "    max_new_tokens=REACT_MAX_NEW_TOKENS,\n",
    "    do_sample=REACT_DO_SAMPLE,\n",
    "    temperature=REACT_TEMPERATURE,\n",
    "    top_p=REACT_TOP_P,\n",
    ")\n",
    "\n",
    "print(\"Active config:\", REACT_CONFIG)\n",
    "print(\"Run mode:\", \"full_200\" if QUICK_LIMIT is None else f\"quick_{QUICK_LIMIT}\")\n",
    "print(\"TS replicas:\", TS_N)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cb8b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo: End-to-end NLQ -> faulty SQL -> cleaned SQL (single cell)\n",
    "from IPython.display import display, HTML\n",
    "import pandas as pd\n",
    "import html\n",
    "\n",
    "from nl2sql.core.prompting import make_few_shot_messages\n",
    "from nl2sql.agent.constraint_policy import build_constraints\n",
    "from nl2sql.core.llm import debug_extract_first_select\n",
    "from nl2sql.core.postprocess import debug_guarded_postprocess\n",
    "\n",
    "\n",
    "# Small helper to print section headers in the notebook output.\n",
    "def show_title(text):\n",
    "    display(HTML(f\"<h3 style='margin:12px 0 6px 0'>{html.escape(text)}</h3>\"))\n",
    "\n",
    "\n",
    "# Small helper to render SQL/text in a boxed monospace block.\n",
    "def show_pre(text, label=None):\n",
    "    label_html = f\"<div style='font-weight:600;margin-bottom:6px'>{html.escape(label)}</div>\" if label else \"\"\n",
    "    display(HTML(\n",
    "        \"<div style='border:1px solid #ddd;border-radius:8px;padding:10px 12px;margin:8px 0'>\"\n",
    "        f\"{label_html}\"\n",
    "        f\"<pre style='white-space:pre-wrap;margin:0;font-family:ui-monospace, SFMono-Regular, Menlo, Consolas, monospace'>{html.escape(str(text))}</pre>\"\n",
    "        \"</div>\"\n",
    "    ))\n",
    "\n",
    "\n",
    "# Convert postprocess steps into a small readable table.\n",
    "def steps_df(pp):\n",
    "    return pd.DataFrame([\n",
    "        {\n",
    "            \"changed\": \"yes\" if s[\"changed\"] else \"no\",\n",
    "            \"stage\": s[\"stage\"],\n",
    "            \"note\": s.get(\"note\", \"\"),\n",
    "        }\n",
    "        for s in pp[\"steps\"]\n",
    "    ])\n",
    "\n",
    "\n",
    "# Demo NLQs: one implicit question and one explicit field-list question.\n",
    "DEMO_NLQ_IMPLICIT = \"List all customer names in France\"\n",
    "DEMO_NLQ_EXPLICIT = \"List contact last name, customer name, and customer number for customers in France\"\n",
    "\n",
    "# Use real schema text if available; otherwise use a minimal fallback.\n",
    "schema_text = (\n",
    "    SCHEMA_SUMMARY\n",
    "    if \"SCHEMA_SUMMARY\" in globals() and isinstance(SCHEMA_SUMMARY, str) and SCHEMA_SUMMARY.strip()\n",
    "    else \"Table customers (customerNumber INT, customerName TEXT, contactLastName TEXT, country TEXT, creditLimit REAL)\"\n",
    ")\n",
    "\n",
    "# Pull a couple of real exemplars when the benchmark is loaded.\n",
    "exemplars = []\n",
    "if \"test_set\" in globals() and isinstance(test_set, list):\n",
    "    exemplars = [x for x in test_set[:2] if isinstance(x, dict) and \"nlq\" in x and \"sql\" in x]\n",
    "\n",
    "# Build the same style of messages used by the real pipeline.\n",
    "messages = make_few_shot_messages(schema=schema_text, exemplars=exemplars, nlq=DEMO_NLQ_IMPLICIT)\n",
    "constraints_implicit = build_constraints(DEMO_NLQ_IMPLICIT, schema_text)\n",
    "\n",
    "# Step 1: show the NLQ and the prompt context.\n",
    "show_title(\"Step 1 - NLQ and prompt context\")\n",
    "display(pd.DataFrame([\n",
    "    {\n",
    "        \"nlq\": DEMO_NLQ_IMPLICIT,\n",
    "        \"schema_lines\": len(schema_text.splitlines()),\n",
    "        \"exemplars_used\": len(exemplars),\n",
    "        \"message_count\": len(messages),\n",
    "        \"explicit_fields\": constraints_implicit.get(\"explicit_fields\"),\n",
    "    }\n",
    "]))\n",
    "\n",
    "display(pd.DataFrame([\n",
    "    {\n",
    "        \"role\": m.get(\"role\"),\n",
    "        \"content_preview\": str(m.get(\"content\", \"\")).replace(\"\\n\", \" \")[:140],\n",
    "    }\n",
    "    for m in messages[:6]\n",
    "]))\n",
    "\n",
    "# Step 2: simulate a noisy/faulty model output (on purpose).\n",
    "FAULTY_TEXT = \"\"\"Model draft + noise:\n",
    "select from the options above\n",
    "\n",
    "SQL:\n",
    "SELECT c.customerNumber, c.customerName, c.contactLastName, c.creditLimit\n",
    "FROM customers c\n",
    "WHERE c.country = 'France'\n",
    "ORDER BY c.customerName DESC\n",
    "LIMIT 5;\n",
    "\n",
    "Extra explanation after SQL.\n",
    "\"\"\"\n",
    "\n",
    "show_title(\"Step 2 - Simulated faulty SQL draft\")\n",
    "show_pre(FAULTY_TEXT, \"Faulty model output (simulated)\")\n",
    "\n",
    "# Step 3: run extraction logic to pick the best SQL candidate.\n",
    "show_title(\"Step 3 - Extraction debug\")\n",
    "extract_debug = debug_extract_first_select(FAULTY_TEXT)\n",
    "selected_sql = extract_debug.get(\"selected_sql\") or FAULTY_TEXT\n",
    "\n",
    "display(pd.DataFrame([\n",
    "    {\n",
    "        \"candidate\": i,\n",
    "        \"accepted\": c.get(\"accepted\"),\n",
    "        \"reject_reason\": c.get(\"reject_reason\"),\n",
    "        \"from_target\": c.get(\"from_target\"),\n",
    "        \"candidate_sql\": c.get(\"candidate_sql\"),\n",
    "    }\n",
    "    for i, c in enumerate(extract_debug.get(\"candidates\", []), start=1)\n",
    "]))\n",
    "show_pre(selected_sql, \"Selected SQL candidate\")\n",
    "\n",
    "# Step 4A: clean SQL for implicit-field question behavior.\n",
    "show_title(\"Step 4A - Cleaning trace (implicit fields)\")\n",
    "pp_a = debug_guarded_postprocess(\n",
    "    selected_sql,\n",
    "    DEMO_NLQ_IMPLICIT,\n",
    "    explicit_fields=constraints_implicit.get(\"explicit_fields\") if constraints_implicit.get(\"explicit_projection\") else None,\n",
    "    required_fields=constraints_implicit.get(\"required_output_fields\"),\n",
    ")\n",
    "display(steps_df(pp_a))\n",
    "show_pre(pp_a[\"final_sql\"], \"Final cleaned SQL (implicit)\")\n",
    "\n",
    "# Step 4B: clean SQL for explicit-field question behavior.\n",
    "show_title(\"Step 4B - Cleaning trace (explicit fields)\")\n",
    "pp_b = debug_guarded_postprocess(\n",
    "    selected_sql,\n",
    "    DEMO_NLQ_EXPLICIT,\n",
    "    explicit_fields=[\"contactLastName\", \"customerName\", \"customerNumber\"],\n",
    ")\n",
    "display(steps_df(pp_b))\n",
    "show_pre(pp_b[\"final_sql\"], \"Final cleaned SQL (explicit)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8946e8",
   "metadata": {},
   "source": [
    "## 12) Eval Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ff8fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Full-eval helpers and setup ---\n",
    "import json\n",
    "import shutil\n",
    "import subprocess\n",
    "from datetime import datetime, timezone\n",
    "from functools import lru_cache\n",
    "from pathlib import Path\n",
    "from sqlalchemy.engine import Engine\n",
    "\n",
    "# Run metadata for reproducibility logs.\n",
    "try:\n",
    "    commit = subprocess.check_output([\"git\", \"rev-parse\", \"--short\", \"HEAD\"]).decode().strip()\n",
    "except Exception:\n",
    "    commit = \"unknown\"\n",
    "\n",
    "RUN_TAG = f\"react_{REACT_CONFIG.name}\"\n",
    "RUN_TS = datetime.now(timezone.utc).strftime(\"%Y%m%d_%H%M%SZ\")\n",
    "RUN_DIR = Path(\"results/agent/runs\") / f\"{RUN_TAG}_{RUN_TS}\"\n",
    "RUN_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SUITE_DBS = [f\"{TS_PREFIX}_{i:02d}\" for i in range(1, TS_N + 1)] if TS_N and TS_N > 0 else []\n",
    "\n",
    "@lru_cache(maxsize=32)\n",
    "def make_engine_cached(db_name: str) -> Engine:\n",
    "    return make_engine(db_name)\n",
    "\n",
    "def make_engine_fn(db_name: str) -> Engine:\n",
    "    return make_engine_cached(db_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fcc704",
   "metadata": {},
   "source": [
    "## 13) Run Full Eval\n",
    "This is the long-running evidence cell: it executes `evaluate_react_ablation`, saves JSON, and updates canonical artifacts for downstream comparison.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32aeeb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Execute full evaluation loop ---\n",
    "out_path = RUN_DIR / \"results_react_eval.json\"\n",
    "\n",
    "run_metadata = {\n",
    "    \"commit\": commit,\n",
    "    \"notebook\": \"03_agentic_eval.ipynb\",\n",
    "    \"model_id\": MODEL_ID,\n",
    "    \"adapter_path\": ADAPTER_PATH,\n",
    "    \"config_name\": REACT_CONFIG.name,\n",
    "    \"quick_limit\": QUICK_LIMIT,\n",
    "    \"ts_n\": TS_N,\n",
    "}\n",
    "\n",
    "report = evaluate_react_ablation(\n",
    "    test_set=test_set,\n",
    "    engine=engine,\n",
    "    config=REACT_CONFIG,\n",
    "    limit=QUICK_LIMIT,\n",
    "    ts_suite_db_names=SUITE_DBS if SUITE_DBS else None,\n",
    "    ts_make_engine_fn=make_engine_fn if SUITE_DBS else None,\n",
    "    ts_max_rows=MAX_ROWS_TS,\n",
    "    progress_every=20,\n",
    "    run_metadata=run_metadata,\n",
    "    save_path=out_path,\n",
    ")\n",
    "\n",
    "results = report.get(\"items\", [])\n",
    "print(\n",
    "    \"ReAct\",\n",
    "    \"VA=\", round(report.get(\"va_rate\", 0.0), 3),\n",
    "    \"EM=\", round(report.get(\"em_rate\", 0.0), 3),\n",
    "    \"EX=\", round(report.get(\"ex_rate\", 0.0), 3),\n",
    "    \"TS=\", \"NA\" if report.get(\"ts_rate\") is None else round(report.get(\"ts_rate\", 0.0), 3),\n",
    ")\n",
    "print(\"Saved report:\", out_path)\n",
    "\n",
    "# Canonical compatibility copy for downstream scripts (full run only).\n",
    "if QUICK_LIMIT is None:\n",
    "    canonical_path = Path(\"results/agent/results_react_200.json\")\n",
    "    canonical_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    shutil.copy2(out_path, canonical_path)\n",
    "    print(\"Updated canonical file:\", canonical_path)\n",
    "else:\n",
    "    print(\"Quick run detected; canonical file not updated.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4f0255",
   "metadata": {},
   "source": [
    "## 14) Failure Profile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31eaf5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "# 15B) EX failure profiling (quick categories)\n",
    "def categorize_ex_failure(item: dict) -> str:\n",
    "    pred = item.get(\"pred_sql\")\n",
    "    va = int(item.get(\"va\", 0))\n",
    "    ex = int(item.get(\"ex\", 0))\n",
    "    err = str(item.get(\"error\") or \"\").lower()\n",
    "\n",
    "    if not pred:\n",
    "        if \"repair_budget_exhausted\" in err:\n",
    "            return \"repair_budget_exhausted\"\n",
    "        return \"no_prediction\"\n",
    "    if va == 0:\n",
    "        if \"guardrail_reject\" in err:\n",
    "            return \"guardrail_reject\"\n",
    "        if \"validate_sql\" in err:\n",
    "            return \"validate_sql_failed\"\n",
    "        return \"invalid_sql\"\n",
    "    if ex == 1:\n",
    "        return \"correct\"\n",
    "    if \"validate_constraints\" in err:\n",
    "        return \"constraint_mismatch\"\n",
    "    if \"intent_mismatch\" in err:\n",
    "        return \"intent_mismatch\"\n",
    "    return \"semantic_mismatch\"\n",
    "\n",
    "counts = Counter(categorize_ex_failure(r) for r in results)\n",
    "print(\"EX failure categories:\")\n",
    "for k, v in counts.most_common():\n",
    "    print(f\"  {k}: {v}\")\n",
    "\n",
    "profile_path = Path(\"results/agent/ex_failure_profile.json\")\n",
    "profile_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "profile = {\n",
    "    \"counts\": dict(counts),\n",
    "    \"n_items\": len(results),\n",
    "    \"quick_limit\": QUICK_LIMIT,\n",
    "    \"ts_n\": TS_N,\n",
    "    \"config_name\": REACT_CONFIG.name,\n",
    "}\n",
    "profile_path.write_text(json.dumps(profile, indent=2), encoding=\"utf-8\")\n",
    "print(\"Saved failure profile:\", profile_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
