{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "50805a1c",
      "metadata": {},
      "source": [
        "# QLoRA Fine-tuning + Evaluation (ClassicModels NL\u2192SQL)\n",
        "\n",
        "This notebook fine-tunes the base model with **QLoRA** on a **training set that must not overlap** with `data/classicmodels_test_200.json`, then re-runs evaluation using the same `nl2sql.eval.eval_run` harness.\n",
        "\n",
        "## Expected inputs\n",
        "- Test set (fixed): `data/classicmodels_test_200.json`\n",
        "- Training set (you create): `data/train/classicmodels_train_200.jsonl` (JSON Lines with `nlq` + `sql` per row)\n",
        "\n",
        "## Outputs\n",
        "- Adapter checkpoint: `results/adapters/qlora_classicmodels/`\n",
        "- Eval outputs: `results/qlora/results_*_200.json`\n",
        "\n",
        "Note: `results/` is gitignored by default. Download the outputs from Colab when finished.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "786cb02c",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, sys, shutil\n",
        "from pathlib import Path\n",
        "\n",
        "# If opened directly in Colab, clone the repo first\n",
        "if Path(\"data/classicmodels_test_200.json\").exists() is False and Path(\"/content\").exists():\n",
        "    repo_dir = Path(\"/content/NLtoSQL\")\n",
        "    if repo_dir.exists():\n",
        "        shutil.rmtree(repo_dir)\n",
        "    !git clone https://github.com/MacKenzieOBrian/NLtoSQL.git \"{repo_dir}\"\n",
        "    os.chdir(repo_dir)\n",
        "\n",
        "sys.path.insert(0, os.getcwd())\n",
        "print(\"cwd:\", os.getcwd())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ce274f7",
      "metadata": {},
      "source": [
        "## 0) Install dependencies (Colab)\n",
        "\n",
        "Install pinned dependencies from `requirements.txt`. Colab often needs a **runtime restart** after installs (Runtime \u2192 Restart runtime), then rerun from the top.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9bc1044",
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    import google.colab  # noqa: F401\n",
        "    IN_COLAB = True\n",
        "except Exception:\n",
        "    IN_COLAB = False\n",
        "\n",
        "if IN_COLAB:\n",
        "    !pip -q install -r requirements.txt\n",
        "\n",
        "    import torch\n",
        "    import accelerate\n",
        "    import peft\n",
        "    import transformers\n",
        "    import trl\n",
        "\n",
        "    print('torch:', torch.__version__, 'cuda:', torch.cuda.is_available())\n",
        "    print('transformers:', transformers.__version__)\n",
        "    print('accelerate:', accelerate.__version__)\n",
        "    print('peft:', peft.__version__)\n",
        "    print('trl:', trl.__version__)\n",
        "\n",
        "    if not torch.cuda.is_available():\n",
        "        print('WARNING: CUDA is not available. In Colab, use a GPU runtime and avoid installing CPU-only torch wheels.')\n",
        "        print('If you just changed torch packages, do: Runtime -> Restart runtime, then run from the top.')\n",
        "else:\n",
        "    print('Not in Colab; ensure requirements are installed.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e0f3751",
      "metadata": {},
      "source": [
        "## 1) Authentication (GCP + Hugging Face)\n",
        "\n",
        "- GCP auth is required for Cloud SQL access (VA evaluation).\n",
        "- HF auth is required for gated models (Meta Llama 3).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9612d759",
      "metadata": {},
      "outputs": [],
      "source": [
        "# GCP auth (Colab) \u2014 safe to skip locally if using ADC\n",
        "try:\n",
        "    from google.colab import auth\n",
        "except ModuleNotFoundError:\n",
        "    auth = None\n",
        "if auth:\n",
        "    auth.authenticate_user()\n",
        "else:\n",
        "    print(\"Not running in Colab; ensure ADC/service account auth is configured.\")\n",
        "\n",
        "# Hugging Face auth\n",
        "hf_token = os.getenv(\"HF_TOKEN\") or os.getenv(\"HUGGINGFACE_HUB_TOKEN\")\n",
        "if hf_token:\n",
        "    os.environ[\"HUGGINGFACE_HUB_TOKEN\"] = hf_token\n",
        "    print(\"Using HF token from env\")\n",
        "else:\n",
        "    try:\n",
        "        from huggingface_hub import notebook_login\n",
        "        notebook_login()\n",
        "    except Exception as e:\n",
        "        print(\"HF auth not configured:\", e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc190ec3",
      "metadata": {},
      "source": [
        "## 2) Load benchmark + training set\n\nTraining set must be separate from the 200-item benchmark.\n\nRecommended workflow:\n- Run `notebooks/04_build_training_set.ipynb` to validate (and edit if needed) `data/train/classicmodels_train_200.jsonl`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7529e213",
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "test_path = Path(\"data/classicmodels_test_200.json\")\n",
        "train_path = Path(\"data/train/classicmodels_train_200.jsonl\")\n",
        "\n",
        "test_set = json.loads(test_path.read_text(encoding=\"utf-8\"))\n",
        "print(\"Test items:\", len(test_set))\n",
        "\n",
        "if not train_path.exists():\n",
        "    raise FileNotFoundError(\n",
        "        f\"Missing training set at {train_path}. Create it before running QLoRA. \"\n",
        "        \"Expected JSONL lines with keys: nlq, sql.\"\n",
        "    )\n",
        "\n",
        "train_records = []\n",
        "for line in train_path.read_text(encoding=\"utf-8\").splitlines():\n",
        "    line = line.strip()\n",
        "    if not line:\n",
        "        continue\n",
        "    train_records.append(json.loads(line))\n",
        "\n",
        "print(\"Train items:\", len(train_records))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Leakage check (train vs test)\n",
        "\n",
        "At minimum, ensure there is no exact NLQ overlap.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_nlqs = {item[\"nlq\"].strip() for item in test_set}\n",
        "train_nlqs = [r.get(\"nlq\", \"\").strip() for r in train_records]\n",
        "overlap = sorted({nlq for nlq in train_nlqs if nlq in test_nlqs})\n",
        "\n",
        "print(\"NLQ overlap count:\", len(overlap))\n",
        "if overlap:\n",
        "    print(\"Example overlaps:\")\n",
        "    for x in overlap[:10]:\n",
        "        print(\"-\", x)\n",
        "    raise ValueError(\"Training set overlaps test set; remove overlapping items before training.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) DB engine + schema summary\n",
        "\n",
        "Schema grounding is kept consistent with the baseline by using `nl2sql.schema.build_schema_summary`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from getpass import getpass\n",
        "from nl2sql.db import create_engine_with_connector\n",
        "from nl2sql.schema import build_schema_summary\n",
        "\n",
        "INSTANCE_CONNECTION_NAME = os.getenv(\"INSTANCE_CONNECTION_NAME\")\n",
        "DB_USER = os.getenv(\"DB_USER\")\n",
        "DB_PASS = os.getenv(\"DB_PASS\")\n",
        "DB_NAME = os.getenv(\"DB_NAME\", \"classicmodels\")\n",
        "\n",
        "if not INSTANCE_CONNECTION_NAME:\n",
        "    INSTANCE_CONNECTION_NAME = input(\"Enter INSTANCE_CONNECTION_NAME: \").strip()\n",
        "if not DB_USER:\n",
        "    DB_USER = input(\"Enter DB_USER: \").strip()\n",
        "if not DB_PASS:\n",
        "    DB_PASS = getpass(\"Enter DB_PASS: \")\n",
        "\n",
        "engine, connector = create_engine_with_connector(\n",
        "    instance_connection_name=INSTANCE_CONNECTION_NAME,\n",
        "    user=DB_USER,\n",
        "    password=DB_PASS,\n",
        "    db_name=DB_NAME,\n",
        ")\n",
        "\n",
        "SCHEMA_SUMMARY = build_schema_summary(engine, db_name=DB_NAME, max_cols_per_table=50)\n",
        "print(\"Schema summary length:\", len(SCHEMA_SUMMARY))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Load base model (4-bit) + configure QLoRA\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
        "\n",
        "MODEL_ID = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
        "\n",
        "tok = AutoTokenizer.from_pretrained(MODEL_ID, token=True)\n",
        "if tok.pad_token is None:\n",
        "    tok.pad_token = tok.eos_token\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        ")\n",
        "\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_ID,\n",
        "    quantization_config=bnb_config,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\",\n",
        "    token=True,\n",
        ")\n",
        "\n",
        "# Deterministic defaults for later evaluation\n",
        "base_model.generation_config.do_sample = False\n",
        "base_model.generation_config.temperature = 1.0\n",
        "base_model.generation_config.top_p = 1.0\n",
        "\n",
        "base_model = prepare_model_for_kbit_training(base_model)\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")\n",
        "\n",
        "model = get_peft_model(base_model, lora_config)\n",
        "model.print_trainable_parameters()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Build the SFT dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "from nl2sql.prompting import SYSTEM_INSTRUCTIONS\n",
        "\n",
        "def format_example(nlq: str, sql: str) -> str:\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": SYSTEM_INSTRUCTIONS},\n",
        "        {\"role\": \"user\", \"content\": \"Schema:\\n\" + SCHEMA_SUMMARY},\n",
        "        {\"role\": \"user\", \"content\": f\"NLQ: {nlq}\"},\n",
        "        {\"role\": \"assistant\", \"content\": sql.rstrip(\";\") + \";\"},\n",
        "    ]\n",
        "    return tok.apply_chat_template(messages, tokenize=False)\n",
        "\n",
        "train_texts = [format_example(r[\"nlq\"], r[\"sql\"]) for r in train_records]\n",
        "train_ds = Dataset.from_dict({\"text\": train_texts})\n",
        "print(train_ds)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Train (SFT with TRL)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "\n",
        "output_dir = \"results/adapters/qlora_classicmodels\"\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    per_device_train_batch_size=1,\n",
        "    gradient_accumulation_steps=8,\n",
        "    learning_rate=2e-4,\n",
        "    num_train_epochs=1,\n",
        "    logging_steps=10,\n",
        "    save_steps=200,\n",
        "    save_total_limit=2,\n",
        "    bf16=True,\n",
        "    optim=\"paged_adamw_8bit\",\n",
        "    report_to=[],\n",
        ")\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    tokenizer=tok,\n",
        "    train_dataset=train_ds,\n",
        "    dataset_text_field=\"text\",\n",
        "    args=training_args,\n",
        "    max_seq_length=1024,\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "trainer.model.save_pretrained(output_dir)\n",
        "tok.save_pretrained(output_dir)\n",
        "print(\"Saved adapters to:\", output_dir)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) Evaluate adapters on the same 200-item test set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from peft import PeftModel\n",
        "from nl2sql.eval import eval_run\n",
        "from pathlib import Path\n",
        "import subprocess\n",
        "\n",
        "eval_base = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_ID,\n",
        "    quantization_config=bnb_config,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\",\n",
        "    token=True,\n",
        ")\n",
        "eval_base.generation_config.do_sample = False\n",
        "eval_base.generation_config.temperature = 1.0\n",
        "eval_base.generation_config.top_p = 1.0\n",
        "\n",
        "eval_model = PeftModel.from_pretrained(eval_base, output_dir)\n",
        "\n",
        "try:\n",
        "    commit = subprocess.check_output([\"git\", \"rev-parse\", \"--short\", \"HEAD\"]).decode().strip()\n",
        "except Exception:\n",
        "    commit = \"unknown\"\n",
        "\n",
        "run_metadata = {\n",
        "    \"commit\": commit,\n",
        "    \"model_id\": MODEL_ID,\n",
        "    \"method\": \"qlora\",\n",
        "    \"adapter_dir\": output_dir,\n",
        "}\n",
        "\n",
        "Path(\"results/qlora\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "qlora_zero_200 = eval_run(\n",
        "    test_set=test_set,\n",
        "    exemplar_pool=test_set,\n",
        "    k=0,\n",
        "    limit=None,\n",
        "    seed=7,\n",
        "    engine=engine,\n",
        "    model=eval_model,\n",
        "    tokenizer=tok,\n",
        "    schema_summary=SCHEMA_SUMMARY,\n",
        "    save_path=\"results/qlora/results_zero_shot_200.json\",\n",
        "    run_metadata=run_metadata,\n",
        "    avoid_exemplar_leakage=True,\n",
        ")\n",
        "\n",
        "qlora_few_200 = eval_run(\n",
        "    test_set=test_set,\n",
        "    exemplar_pool=test_set,\n",
        "    k=3,\n",
        "    limit=None,\n",
        "    seed=7,\n",
        "    engine=engine,\n",
        "    model=eval_model,\n",
        "    tokenizer=tok,\n",
        "    schema_summary=SCHEMA_SUMMARY,\n",
        "    save_path=\"results/qlora/results_few_shot_k3_200.json\",\n",
        "    run_metadata=run_metadata,\n",
        "    avoid_exemplar_leakage=True,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8) Compare against baseline outputs (optional)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "baseline_zero = Path(\"results/baseline/results_zero_shot_200.json\")\n",
        "baseline_few  = Path(\"results/baseline/results_few_shot_k3_200.json\")\n",
        "\n",
        "if baseline_zero.exists() and baseline_few.exists():\n",
        "    b0 = json.loads(baseline_zero.read_text(encoding=\"utf-8\"))\n",
        "    b3 = json.loads(baseline_few.read_text(encoding=\"utf-8\"))\n",
        "    q0 = json.loads(Path(\"results/qlora/results_zero_shot_200.json\").read_text(encoding=\"utf-8\"))\n",
        "    q3 = json.loads(Path(\"results/qlora/results_few_shot_k3_200.json\").read_text(encoding=\"utf-8\"))\n",
        "\n",
        "    print(\"Baseline zero-shot:\", \"VA\", round(b0[\"va_rate\"], 3), \"EM\", round(b0.get(\"em_rate\", 0.0), 3), \"EX\", round(b0[\"ex_rate\"], 3))\n",
        "    print(\"QLoRA   zero-shot:\", \"VA\", round(q0[\"va_rate\"], 3), \"EM\", round(q0.get(\"em_rate\", 0.0), 3), \"EX\", round(q0[\"ex_rate\"], 3))\n",
        "    print(\"Baseline few-shot :\", \"VA\", round(b3[\"va_rate\"], 3), \"EM\", round(b3.get(\"em_rate\", 0.0), 3), \"EX\", round(b3[\"ex_rate\"], 3))\n",
        "    print(\"QLoRA   few-shot :\", \"VA\", round(q3[\"va_rate\"], 3), \"EM\", round(q3.get(\"em_rate\", 0.0), 3), \"EX\", round(q3[\"ex_rate\"], 3))\n",
        "else:\n",
        "    print(\"Baseline JSONs not found under results/baseline/. Run the baseline notebook first (or upload the JSONs).\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}