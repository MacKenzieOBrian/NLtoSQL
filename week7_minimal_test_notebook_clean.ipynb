{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b5d82ff",
   "metadata": {},
   "source": [
    "# NL-to-SQL scaffold (classicmodels)\n",
    "\n",
    "What this notebook does:\n",
    "- Auth to GCP\n",
    "- Safe Cloud SQL connection (classicmodels) via connector + SQLAlchemy\n",
    "- Schema helpers + QueryRunner tool\n",
    "- Smoke tests and dataset validator\n",
    "- Base Llama-3-8B load (pre-QLoRA placeholder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5de0879d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not running in Colab; ensure GCP auth via gcloud/ADC or service account if needed.\n"
     ]
    }
   ],
   "source": [
    "# Auth to Google Cloud (Colab) or skip gracefully elsewhere\n",
    "try:\n",
    "    from google.colab import auth\n",
    "except ModuleNotFoundError:\n",
    "    auth = None\n",
    "if auth:\n",
    "    auth.authenticate_user()\n",
    "else:\n",
    "    print(\"Not running in Colab; ensure GCP auth via gcloud/ADC or service account if needed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42845b0",
   "metadata": {},
   "source": [
    "## Project context\n",
    "Swap to env var in production if you don't want to hardcode project_id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67cf85fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "project_id = \"modified-enigma-476414-h9\"  # replace with env var in production\n",
    "os.environ[\"GOOGLE_CLOUD_PROJECT\"] = project_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98191e1b",
   "metadata": {},
   "source": [
    "## Installs\n",
    "Pin these in a requirements cell/file for real runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "597edacf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/anaconda3/lib/python3.12/site-packages (25.3)\n",
      "Collecting torch==2.2.2 (from -r requirements.txt (line 1))\n",
      "  Downloading torch-2.2.2-cp312-none-macosx_11_0_arm64.whl.metadata (25 kB)\n",
      "Collecting transformers==4.37.2 (from -r requirements.txt (line 2))\n",
      "  Downloading transformers-4.37.2-py3-none-any.whl.metadata (129 kB)\n",
      "Collecting accelerate==0.27.2 (from -r requirements.txt (line 3))\n",
      "  Downloading accelerate-0.27.2-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: bitsandbytes==0.42.0 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (0.42.0)\n",
      "Collecting peft==0.10.0 (from -r requirements.txt (line 5))\n",
      "  Downloading peft-0.10.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting trl==0.7.10 (from -r requirements.txt (line 6))\n",
      "  Downloading trl-0.7.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting datasets==2.16.1 (from -r requirements.txt (line 7))\n",
      "  Downloading datasets-2.16.1-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting google-api-core==2.11.1 (from -r requirements.txt (line 8))\n",
      "  Downloading google_api_core-2.11.1-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting cloud-sql-python-connector==1.18.5 (from cloud-sql-python-connector[pymysql]==1.18.5->-r requirements.txt (line 9))\n",
      "  Downloading cloud_sql_python_connector-1.18.5-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: SQLAlchemy==2.0.7 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 10)) (2.0.7)\n",
      "Collecting pymysql==1.1.0 (from -r requirements.txt (line 11))\n",
      "  Downloading PyMySQL-1.1.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting cryptography==42.0.5 (from -r requirements.txt (line 12))\n",
      "  Downloading cryptography-42.0.5-cp39-abi3-macosx_10_12_universal2.whl.metadata (5.3 kB)\n",
      "Collecting pandas==2.2.1 (from -r requirements.txt (line 13))\n",
      "  Downloading pandas-2.2.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from torch==2.2.2->-r requirements.txt (line 1)) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/anaconda3/lib/python3.12/site-packages (from torch==2.2.2->-r requirements.txt (line 1)) (4.15.0)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/lib/python3.12/site-packages (from torch==2.2.2->-r requirements.txt (line 1)) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch==2.2.2->-r requirements.txt (line 1)) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch==2.2.2->-r requirements.txt (line 1)) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.12/site-packages (from torch==2.2.2->-r requirements.txt (line 1)) (2024.3.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/anaconda3/lib/python3.12/site-packages (from transformers==4.37.2->-r requirements.txt (line 2)) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers==4.37.2->-r requirements.txt (line 2)) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers==4.37.2->-r requirements.txt (line 2)) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from transformers==4.37.2->-r requirements.txt (line 2)) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers==4.37.2->-r requirements.txt (line 2)) (2023.10.3)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from transformers==4.37.2->-r requirements.txt (line 2)) (2.32.5)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers==4.37.2->-r requirements.txt (line 2))\n",
      "  Downloading tokenizers-0.15.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/anaconda3/lib/python3.12/site-packages (from transformers==4.37.2->-r requirements.txt (line 2)) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/lib/python3.12/site-packages (from transformers==4.37.2->-r requirements.txt (line 2)) (4.66.4)\n",
      "Requirement already satisfied: psutil in /opt/anaconda3/lib/python3.12/site-packages (from accelerate==0.27.2->-r requirements.txt (line 3)) (5.9.0)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.12/site-packages (from bitsandbytes==0.42.0->-r requirements.txt (line 4)) (1.13.1)\n",
      "Collecting tyro>=0.5.11 (from trl==0.7.10->-r requirements.txt (line 6))\n",
      "  Downloading tyro-0.9.35-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from datasets==2.16.1->-r requirements.txt (line 7)) (22.0.0)\n",
      "Collecting pyarrow-hotfix (from datasets==2.16.1->-r requirements.txt (line 7))\n",
      "  Downloading pyarrow_hotfix-0.7-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting dill<0.3.8,>=0.3.0 (from datasets==2.16.1->-r requirements.txt (line 7))\n",
      "  Downloading dill-0.3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: xxhash in /opt/anaconda3/lib/python3.12/site-packages (from datasets==2.16.1->-r requirements.txt (line 7)) (3.6.0)\n",
      "Requirement already satisfied: multiprocess in /opt/anaconda3/lib/python3.12/site-packages (from datasets==2.16.1->-r requirements.txt (line 7)) (0.70.18)\n",
      "Collecting fsspec (from torch==2.2.2->-r requirements.txt (line 1))\n",
      "  Downloading fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: aiohttp in /opt/anaconda3/lib/python3.12/site-packages (from datasets==2.16.1->-r requirements.txt (line 7)) (3.13.2)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/anaconda3/lib/python3.12/site-packages (from google-api-core==2.11.1->-r requirements.txt (line 8)) (1.72.0)\n",
      "Collecting protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 (from google-api-core==2.11.1->-r requirements.txt (line 8))\n",
      "  Downloading protobuf-4.25.8-cp37-abi3-macosx_10_9_universal2.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in /opt/anaconda3/lib/python3.12/site-packages (from google-api-core==2.11.1->-r requirements.txt (line 8)) (2.43.0)\n",
      "Collecting aiofiles (from cloud-sql-python-connector==1.18.5->cloud-sql-python-connector[pymysql]==1.18.5->-r requirements.txt (line 9))\n",
      "  Downloading aiofiles-25.1.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting dnspython>=2.0.0 (from cloud-sql-python-connector==1.18.5->cloud-sql-python-connector[pymysql]==1.18.5->-r requirements.txt (line 9))\n",
      "  Downloading dnspython-2.8.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/anaconda3/lib/python3.12/site-packages (from cryptography==42.0.5->-r requirements.txt (line 12)) (2.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas==2.2.1->-r requirements.txt (line 13)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas==2.2.1->-r requirements.txt (line 13)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas==2.2.1->-r requirements.txt (line 13)) (2023.3)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core==2.11.1->-r requirements.txt (line 8)) (6.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/anaconda3/lib/python3.12/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core==2.11.1->-r requirements.txt (line 8)) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/anaconda3/lib/python3.12/site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core==2.11.1->-r requirements.txt (line 8)) (4.9.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.37.2->-r requirements.txt (line 2)) (1.2.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers==4.37.2->-r requirements.txt (line 2)) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers==4.37.2->-r requirements.txt (line 2)) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers==4.37.2->-r requirements.txt (line 2)) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers==4.37.2->-r requirements.txt (line 2)) (2025.11.12)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /opt/anaconda3/lib/python3.12/site-packages (from rsa<5,>=3.1.4->google-auth<3.0.dev0,>=2.14.1->google-api-core==2.11.1->-r requirements.txt (line 8)) (0.6.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets==2.16.1->-r requirements.txt (line 7)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets==2.16.1->-r requirements.txt (line 7)) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets==2.16.1->-r requirements.txt (line 7)) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets==2.16.1->-r requirements.txt (line 7)) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets==2.16.1->-r requirements.txt (line 7)) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets==2.16.1->-r requirements.txt (line 7)) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets==2.16.1->-r requirements.txt (line 7)) (1.22.0)\n",
      "Requirement already satisfied: pycparser in /opt/anaconda3/lib/python3.12/site-packages (from cffi>=1.12->cryptography==42.0.5->-r requirements.txt (line 12)) (2.23)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas==2.2.1->-r requirements.txt (line 13)) (1.16.0)\n",
      "Collecting docstring-parser>=0.15 (from tyro>=0.5.11->trl==0.7.10->-r requirements.txt (line 6))\n",
      "  Downloading docstring_parser-0.17.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: rich>=11.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from tyro>=0.5.11->trl==0.7.10->-r requirements.txt (line 6)) (13.7.1)\n",
      "Collecting shtab>=1.5.6 (from tyro>=0.5.11->trl==0.7.10->-r requirements.txt (line 6))\n",
      "  Downloading shtab-1.8.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typeguard>=4.0.0 (from tyro>=0.5.11->trl==0.7.10->-r requirements.txt (line 6))\n",
      "  Downloading typeguard-4.4.4-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.7.10->-r requirements.txt (line 6)) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.7.10->-r requirements.txt (line 6)) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl==0.7.10->-r requirements.txt (line 6)) (0.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch==2.2.2->-r requirements.txt (line 1)) (2.1.3)\n",
      "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting multiprocess (from datasets==2.16.1->-r requirements.txt (line 7))\n",
      "  Downloading multiprocess-0.70.17-py312-none-any.whl.metadata (7.2 kB)\n",
      "  Downloading multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "  Downloading multiprocess-0.70.15-py311-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy->torch==2.2.2->-r requirements.txt (line 1)) (1.3.0)\n",
      "Downloading torch-2.2.2-cp312-none-macosx_11_0_arm64.whl (59.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m  \u001b[33m0:00:07\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.37.2-py3-none-any.whl (8.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-0.27.2-py3-none-any.whl (279 kB)\n",
      "Downloading peft-0.10.0-py3-none-any.whl (199 kB)\n",
      "Downloading trl-0.7.10-py3-none-any.whl (150 kB)\n",
      "Downloading datasets-2.16.1-py3-none-any.whl (507 kB)\n",
      "Downloading google_api_core-2.11.1-py3-none-any.whl (120 kB)\n",
      "Downloading cloud_sql_python_connector-1.18.5-py3-none-any.whl (49 kB)\n",
      "Downloading PyMySQL-1.1.0-py3-none-any.whl (44 kB)\n",
      "Downloading cryptography-42.0.5-cp39-abi3-macosx_10_12_universal2.whl (5.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.2.1-cp312-cp312-macosx_11_0_arm64.whl (11.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
      "Downloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
      "Downloading protobuf-4.25.8-cp37-abi3-macosx_10_9_universal2.whl (394 kB)\n",
      "Downloading tokenizers-0.15.2-cp312-cp312-macosx_11_0_arm64.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading dnspython-2.8.0-py3-none-any.whl (331 kB)\n",
      "Downloading tyro-0.9.35-py3-none-any.whl (132 kB)\n",
      "Downloading docstring_parser-0.17.0-py3-none-any.whl (36 kB)\n",
      "Downloading shtab-1.8.0-py3-none-any.whl (14 kB)\n",
      "Downloading typeguard-4.4.4-py3-none-any.whl (34 kB)\n",
      "Downloading aiofiles-25.1.0-py3-none-any.whl (14 kB)\n",
      "Downloading multiprocess-0.70.15-py311-none-any.whl (135 kB)\n",
      "Downloading pyarrow_hotfix-0.7-py3-none-any.whl (7.9 kB)\n",
      "Installing collected packages: typeguard, shtab, pymysql, pyarrow-hotfix, protobuf, fsspec, docstring-parser, dnspython, dill, aiofiles, torch, pandas, multiprocess, cryptography, tyro, tokenizers, google-api-core, cloud-sql-python-connector, accelerate, transformers, datasets, trl, peft\n",
      "\u001b[2K  Attempting uninstall: pymysql\n",
      "\u001b[2K    Found existing installation: PyMySQL 1.1.2\n",
      "\u001b[2K    Uninstalling PyMySQL-1.1.2:\n",
      "\u001b[2K      Successfully uninstalled PyMySQL-1.1.2\n",
      "\u001b[2K  Attempting uninstall: protobuf\n",
      "\u001b[2K    Found existing installation: protobuf 6.33.1\n",
      "\u001b[2K    Uninstalling protobuf-6.33.1:\n",
      "\u001b[2K      Successfully uninstalled protobuf-6.33.1\n",
      "\u001b[2K  Attempting uninstall: fsspec90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/23\u001b[0m [protobuf]\n",
      "\u001b[2K    Found existing installation: fsspec 2024.3.1━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/23\u001b[0m [protobuf]\n",
      "\u001b[2K    Uninstalling fsspec-2024.3.1:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/23\u001b[0m [protobuf]\n",
      "\u001b[2K      Successfully uninstalled fsspec-2024.3.1━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/23\u001b[0m [protobuf]\n",
      "\u001b[2K  Attempting uninstall: dillm╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/23\u001b[0m [dnspython]\n",
      "\u001b[2K    Found existing installation: dill 0.4.0━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/23\u001b[0m [dnspython]\n",
      "\u001b[2K    Uninstalling dill-0.4.0:0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/23\u001b[0m [dnspython]\n",
      "\u001b[2K      Successfully uninstalled dill-0.4.0━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/23\u001b[0m [dnspython]\n",
      "\u001b[2K  Attempting uninstall: torchm╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/23\u001b[0m [dill]]\n",
      "\u001b[2K    Found existing installation: torch 2.9.1━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/23\u001b[0m [dill]\n",
      "\u001b[2K    Uninstalling torch-2.9.1:\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/23\u001b[0m [torch]\n",
      "\u001b[2K      Successfully uninstalled torch-2.9.1━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/23\u001b[0m [torch]\n",
      "\u001b[2K  Attempting uninstall: pandas[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/23\u001b[0m [torch]\n",
      "\u001b[2K    Found existing installation: pandas 2.2.2━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/23\u001b[0m [torch]\n",
      "\u001b[2K    Uninstalling pandas-2.2.2:m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/23\u001b[0m [pandas]\n",
      "\u001b[2K      Successfully uninstalled pandas-2.2.2━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/23\u001b[0m [pandas]\n",
      "\u001b[2K  Attempting uninstall: multiprocess╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/23\u001b[0m [pandas]\n",
      "\u001b[2K    Found existing installation: multiprocess 0.70.18━━━━━━━━━\u001b[0m \u001b[32m11/23\u001b[0m [pandas]\n",
      "\u001b[2K    Uninstalling multiprocess-0.70.18:[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/23\u001b[0m [pandas]\n",
      "\u001b[2K      Successfully uninstalled multiprocess-0.70.18━━━━━━━━━━━\u001b[0m \u001b[32m11/23\u001b[0m [pandas]\n",
      "\u001b[2K  Attempting uninstall: cryptographym╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12/23\u001b[0m [multiprocess]\n",
      "\u001b[2K    Found existing installation: cryptography 41.0.0━━━━━━━━━━\u001b[0m \u001b[32m12/23\u001b[0m [multiprocess]\n",
      "\u001b[2K    Uninstalling cryptography-41.0.0:m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12/23\u001b[0m [multiprocess]\n",
      "\u001b[2K      Successfully uninstalled cryptography-41.0.0━━━━━━━━━━━━\u001b[0m \u001b[32m12/23\u001b[0m [multiprocess]\n",
      "\u001b[2K  Attempting uninstall: tokenizers0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14/23\u001b[0m [tyro]ography]\n",
      "\u001b[2K    Found existing installation: tokenizers 0.22.1━━━━━━━━━━━━\u001b[0m \u001b[32m14/23\u001b[0m [tyro]\n",
      "\u001b[2K    Uninstalling tokenizers-0.22.1:0m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14/23\u001b[0m [tyro]\n",
      "\u001b[2K      Successfully uninstalled tokenizers-0.22.1━━━━━━━━━━━━━━\u001b[0m \u001b[32m14/23\u001b[0m [tyro]\n",
      "\u001b[2K  Attempting uninstall: google-api-core[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14/23\u001b[0m [tyro]\n",
      "\u001b[2K    Found existing installation: google-api-core 2.28.1━━━━━━━\u001b[0m \u001b[32m14/23\u001b[0m [tyro]\n",
      "\u001b[2K    Uninstalling google-api-core-2.28.1:0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14/23\u001b[0m [tyro]\n",
      "\u001b[2K      Successfully uninstalled google-api-core-2.28.1━━━━━━━━━\u001b[0m \u001b[32m14/23\u001b[0m [tyro]\n",
      "\u001b[2K  Attempting uninstall: cloud-sql-python-connector[90m━━━━━━━━━━━━\u001b[0m \u001b[32m16/23\u001b[0m [google-api-core]\n",
      "\u001b[2K    Found existing installation: cloud-sql-python-connector 1.6.0m \u001b[32m16/23\u001b[0m [google-api-core]\n",
      "\u001b[2K    Uninstalling cloud-sql-python-connector-1.6.0:━━━━━━━━━━━━\u001b[0m \u001b[32m16/23\u001b[0m [google-api-core]\n",
      "\u001b[2K      Successfully uninstalled cloud-sql-python-connector-1.6.0[0m \u001b[32m16/23\u001b[0m [google-api-core]\n",
      "\u001b[2K  Attempting uninstall: acceleratem\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m16/23\u001b[0m [google-api-core]\n",
      "\u001b[2K    Found existing installation: accelerate 1.12.0━━━━━━━━━━━━\u001b[0m \u001b[32m16/23\u001b[0m [google-api-core]\n",
      "\u001b[2K    Uninstalling accelerate-1.12.0:\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m16/23\u001b[0m [google-api-core]\n",
      "\u001b[2K      Successfully uninstalled accelerate-1.12.00m━━━━━━━━━━━━\u001b[0m \u001b[32m16/23\u001b[0m [google-api-core]\n",
      "\u001b[2K  Attempting uninstall: transformers━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m18/23\u001b[0m [accelerate]]\n",
      "\u001b[2K    Found existing installation: transformers 4.57.30m━━━━━━━━\u001b[0m \u001b[32m18/23\u001b[0m [accelerate]\n",
      "\u001b[2K    Uninstalling transformers-4.57.3:━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m19/23\u001b[0m [transformers]\n",
      "\u001b[2K      Successfully uninstalled transformers-4.57.3m\u001b[90m━━━━━━\u001b[0m \u001b[32m19/23\u001b[0m [transformers]\n",
      "\u001b[2K  Attempting uninstall: datasets━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m19/23\u001b[0m [transformers]\n",
      "\u001b[2K    Found existing installation: datasets 4.4.1\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m19/23\u001b[0m [transformers]\n",
      "\u001b[2K    Uninstalling datasets-4.4.1:━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m19/23\u001b[0m [transformers]\n",
      "\u001b[2K      Successfully uninstalled datasets-4.4.1m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m19/23\u001b[0m [transformers]\n",
      "\u001b[2K  Attempting uninstall: trl━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m20/23\u001b[0m [datasets]\n",
      "\u001b[2K    Found existing installation: trl 0.25.1[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m20/23\u001b[0m [datasets]\n",
      "\u001b[2K    Uninstalling trl-0.25.1:━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m20/23\u001b[0m [datasets]\n",
      "\u001b[2K      Successfully uninstalled trl-0.25.1━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m21/23\u001b[0m [trl]]\n",
      "\u001b[2K  Attempting uninstall: peft━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m21/23\u001b[0m [trl]\n",
      "\u001b[2K    Found existing installation: peft 0.18.0\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m21/23\u001b[0m [trl]\n",
      "\u001b[2K    Uninstalling peft-0.18.0:━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m21/23\u001b[0m [trl]\n",
      "\u001b[2K      Successfully uninstalled peft-0.18.00m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m21/23\u001b[0m [trl]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23/23\u001b[0m [peft]2m22/23\u001b[0m [peft]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "s3fs 2024.3.1 requires fsspec==2024.3.1, but you have fsspec 2023.10.0 which is incompatible.\n",
      "streamlit 1.32.0 requires cachetools<6,>=4.0, but you have cachetools 6.2.2 which is incompatible.\n",
      "streamlit 1.32.0 requires packaging<24,>=16.8, but you have packaging 24.2 which is incompatible.\n",
      "awsebcli 3.25 requires termcolor<3,>=2.4.0, but you have termcolor 2.3.0 which is incompatible.\n",
      "awsebcli 3.25 requires urllib3<2,>=1.26.5, but you have urllib3 2.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed accelerate-0.27.2 aiofiles-25.1.0 cloud-sql-python-connector-1.18.5 cryptography-42.0.5 datasets-2.16.1 dill-0.3.7 dnspython-2.8.0 docstring-parser-0.17.0 fsspec-2023.10.0 google-api-core-2.11.1 multiprocess-0.70.15 pandas-2.2.1 peft-0.10.0 protobuf-4.25.8 pyarrow-hotfix-0.7 pymysql-1.1.0 shtab-1.8.0 tokenizers-0.15.2 torch-2.2.2 transformers-4.37.2 trl-0.7.10 typeguard-4.4.4 tyro-0.9.35\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# Prefer installing from pinned requirements.txt for reproducibility\n",
    "!{sys.executable} -m pip install --upgrade pip\n",
    "!{sys.executable} -m pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a59fec6",
   "metadata": {},
   "source": [
    "\n",
    "### Runtime tips (Colab/local)\n",
    "- Install from pinned `requirements.txt`.\n",
    "- Set env vars/ADC before connecting (project, instance, DB creds).\n",
    "- If NumPy binary mismatch shows up, force-reinstall once and restart runtime.\n",
    "- Run cells in order: installs → env/auth → connector/smoke tests → validation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bb0e44",
   "metadata": {},
   "source": [
    "## Imports and logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c814f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "from google.cloud.sql.connector import Connector\n",
    "import sqlalchemy\n",
    "from sqlalchemy import text\n",
    "import pymysql\n",
    "from typing import Optional\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(\"nl2sql_db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c470662b",
   "metadata": {},
   "source": [
    "## Connection params\n",
    "Env first, prompt fallback during dev."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "615caadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "INSTANCE_CONNECTION_NAME = os.getenv(\"INSTANCE_CONNECTION_NAME\")\n",
    "DB_USER = os.getenv(\"DB_USER\")\n",
    "DB_PASS = os.getenv(\"DB_PASS\")\n",
    "DB_NAME = os.getenv(\"DB_NAME\", \"classicmodels\")\n",
    "\n",
    "if not INSTANCE_CONNECTION_NAME:\n",
    "    INSTANCE_CONNECTION_NAME = input(\"Enter INSTANCE_CONNECTION_NAME: \").strip()\n",
    "if not DB_USER:\n",
    "    DB_USER = input(\"Enter DB_USER: \").strip()\n",
    "if not DB_PASS:\n",
    "    DB_PASS = getpass(\"Enter DB_PASS: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460e3ebd",
   "metadata": {},
   "source": [
    "## Connector + engine setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36e357f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.api_core import retry\n",
    "from sqlalchemy.engine import Engine\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "\n",
    "connector = Connector()\n",
    "\n",
    "def getconn():\n",
    "    \"\"\"SQLAlchemy creator hook using the Cloud SQL connector.\"\"\"\n",
    "    return connector.connect(\n",
    "        INSTANCE_CONNECTION_NAME,\n",
    "        \"pymysql\",\n",
    "        user=DB_USER,\n",
    "        password=DB_PASS,\n",
    "        db=DB_NAME,\n",
    "    )\n",
    "\n",
    "engine: Engine = sqlalchemy.create_engine(\"mysql+pymysql://\", creator=getconn, future=True)\n",
    "\n",
    "@contextmanager\n",
    "def safe_connection(engine):\n",
    "    \"\"\"Yield a connection and clean up after use.\"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = engine.connect()\n",
    "        yield conn\n",
    "    finally:\n",
    "        if conn:\n",
    "            conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19d19d7",
   "metadata": {},
   "source": [
    "## Schema exploration helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "777e17cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def list_tables(engine) -> list:\n",
    "    \"\"\"Return a list of table names.\"\"\"\n",
    "    with safe_connection(engine) as conn:\n",
    "        result = conn.execute(text(\"SHOW TABLES;\")).fetchall()\n",
    "    return [r[0] for r in result]\n",
    "\n",
    "def get_table_columns(engine, table_name: str) -> pd.DataFrame:\n",
    "    \"\"\"Return a DataFrame of columns.\"\"\"\n",
    "    query = text(\"\"\"\n",
    "        SELECT COLUMN_NAME, DATA_TYPE, IS_NULLABLE, COLUMN_KEY\n",
    "        FROM INFORMATION_SCHEMA.COLUMNS\n",
    "        WHERE TABLE_SCHEMA = :db AND TABLE_NAME = :table\n",
    "        ORDER BY ORDINAL_POSITION\n",
    "    \"\"\")\n",
    "    with safe_connection(engine) as conn:\n",
    "        df = pd.read_sql(query, conn, params={\"db\": DB_NAME, \"table\": table_name})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ad4a14",
   "metadata": {},
   "source": [
    "## Smoke tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6956eebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nl2sql_db:Tables in classicmodels: ['customers', 'employees', 'offices', 'orderdetails', 'orders', 'payments', 'productlines', 'products']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerNumber</th>\n",
       "      <th>customerName</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>103</td>\n",
       "      <td>Atelier graphique</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>112</td>\n",
       "      <td>Signal Gift Stores</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>114</td>\n",
       "      <td>Australian Collectors, Co.</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>119</td>\n",
       "      <td>La Rochelle Gifts</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>121</td>\n",
       "      <td>Baane Mini Imports</td>\n",
       "      <td>Norway</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customerNumber                customerName    country\n",
       "0             103           Atelier graphique     France\n",
       "1             112          Signal Gift Stores        USA\n",
       "2             114  Australian Collectors, Co.  Australia\n",
       "3             119           La Rochelle Gifts     France\n",
       "4             121          Baane Mini Imports     Norway"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def fetch_sample_customers(limit: int = 10):\n",
    "    q = text(\"SELECT customerNumber, customerName, country FROM customers LIMIT :limit;\")\n",
    "    with safe_connection(engine) as conn:\n",
    "        df = pd.read_sql(q, conn, params={\"limit\": limit})\n",
    "    return df\n",
    "\n",
    "try:\n",
    "    tables = list_tables(engine)\n",
    "    logger.info(\"Tables in classicmodels: %s\", tables)\n",
    "    sample_df = fetch_sample_customers(5)\n",
    "    display(sample_df)\n",
    "except Exception as e:\n",
    "    logger.exception(\"Smoke test failed: %s\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e296f6e4",
   "metadata": {},
   "source": [
    "## QueryRunner (read-only tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6f9f164",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime, timezone\n",
    "from typing import Any, Dict\n",
    "\n",
    "class QueryExecutionError(Exception):\n",
    "    pass\n",
    "\n",
    "def now_utc_iso() -> str:\n",
    "    return datetime.now(timezone.utc).isoformat().replace(\"+00:00\", \"Z\")\n",
    "\n",
    "class QueryRunner:\n",
    "    \"\"\"\n",
    "    Execute generated SQL safely against the engine, capture results and metadata,\n",
    "    and keep a history suitable for evaluation and error analysis.\n",
    "    \"\"\"\n",
    "    def __init__(self, engine, max_rows: int = 1000, forbidden_tokens=None):\n",
    "        self.engine = engine\n",
    "        self.max_rows = max_rows\n",
    "        self.history = []\n",
    "        self.forbidden_tokens = forbidden_tokens or [\"drop \", \"delete \", \"truncate \", \"alter \", \"create \", \"update \", \"insert \"]\n",
    "\n",
    "    def _safety_check(self, sql: str) -> None:\n",
    "        lowered = (sql or \"\").strip().lower()\n",
    "        if not lowered:\n",
    "            raise QueryExecutionError(\"Empty SQL string\")\n",
    "        for token in self.forbidden_tokens:\n",
    "            if token in lowered:\n",
    "                raise QueryExecutionError(f\"Destructive SQL token detected: {token.strip()}\")\n",
    "\n",
    "    def run(self, sql: str, params: Optional[Dict[str, Any]] = None, capture_df: bool = True) -> Dict[str, Any]:\n",
    "        entry = {\n",
    "            \"sql\": sql,\n",
    "            \"params\": params,\n",
    "            \"timestamp\": now_utc_iso(),\n",
    "            \"success\": False,\n",
    "            \"rowcount\": 0,\n",
    "            \"exec_time_s\": None,\n",
    "            \"error\": None,\n",
    "            \"columns\": None,\n",
    "            \"result_preview\": None,\n",
    "        }\n",
    "        try:\n",
    "            self._safety_check(sql)\n",
    "            start = datetime.now(timezone.utc)\n",
    "            with safe_connection(self.engine) as conn:\n",
    "                result = conn.execute(sqlalchemy.text(sql), params or {})\n",
    "                rows = result.fetchall()\n",
    "                cols = list(result.keys())\n",
    "            end = datetime.now(timezone.utc)\n",
    "            exec_time = (end - start).total_seconds()\n",
    "            df = None\n",
    "            if capture_df:\n",
    "                df = pd.DataFrame(rows, columns=cols)\n",
    "                if len(df) > self.max_rows:\n",
    "                    df = df.iloc[: self.max_rows]\n",
    "            entry.update({\n",
    "                \"success\": True,\n",
    "                \"rowcount\": min(len(rows), self.max_rows),\n",
    "                \"exec_time_s\": exec_time,\n",
    "                \"columns\": cols,\n",
    "                \"result_preview\": df\n",
    "            })\n",
    "        except Exception as e:\n",
    "            entry.update({\n",
    "                \"error\": str(e),\n",
    "                \"success\": False\n",
    "            })\n",
    "        finally:\n",
    "            self.history.append(entry)\n",
    "        return entry\n",
    "\n",
    "    def last(self):\n",
    "        return self.history[-1] if self.history else None\n",
    "\n",
    "    def save_history(self, path: str):\n",
    "        serializable = []\n",
    "        for h in self.history:\n",
    "            s = {k: v for k, v in h.items() if k != \"result_preview\"}\n",
    "            serializable.append(s)\n",
    "        with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(serializable, f, indent=2, default=str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428221bd",
   "metadata": {},
   "source": [
    "## QueryRunner quick test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7cb08aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerNumber</th>\n",
       "      <th>customerName</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>103</td>\n",
       "      <td>Atelier graphique</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>112</td>\n",
       "      <td>Signal Gift Stores</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>114</td>\n",
       "      <td>Australian Collectors, Co.</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>119</td>\n",
       "      <td>La Rochelle Gifts</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>121</td>\n",
       "      <td>Baane Mini Imports</td>\n",
       "      <td>Norway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>124</td>\n",
       "      <td>Mini Gifts Distributors Ltd.</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>125</td>\n",
       "      <td>Havel &amp; Zbyszek Co</td>\n",
       "      <td>Poland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>128</td>\n",
       "      <td>Blauer See Auto, Co.</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>129</td>\n",
       "      <td>Mini Wheels Co.</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>131</td>\n",
       "      <td>Land of Toys Inc.</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customerNumber                  customerName    country\n",
       "0             103             Atelier graphique     France\n",
       "1             112            Signal Gift Stores        USA\n",
       "2             114    Australian Collectors, Co.  Australia\n",
       "3             119             La Rochelle Gifts     France\n",
       "4             121            Baane Mini Imports     Norway\n",
       "5             124  Mini Gifts Distributors Ltd.        USA\n",
       "6             125            Havel & Zbyszek Co     Poland\n",
       "7             128          Blauer See Auto, Co.    Germany\n",
       "8             129               Mini Wheels Co.        USA\n",
       "9             131             Land of Toys Inc.        USA"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Schema for table: customers\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COLUMN_NAME</th>\n",
       "      <th>DATA_TYPE</th>\n",
       "      <th>IS_NULLABLE</th>\n",
       "      <th>COLUMN_KEY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>customerNumber</td>\n",
       "      <td>int</td>\n",
       "      <td>NO</td>\n",
       "      <td>PRI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>customerName</td>\n",
       "      <td>varchar</td>\n",
       "      <td>NO</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>contactLastName</td>\n",
       "      <td>varchar</td>\n",
       "      <td>NO</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>contactFirstName</td>\n",
       "      <td>varchar</td>\n",
       "      <td>NO</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>phone</td>\n",
       "      <td>varchar</td>\n",
       "      <td>NO</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>addressLine1</td>\n",
       "      <td>varchar</td>\n",
       "      <td>NO</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>addressLine2</td>\n",
       "      <td>varchar</td>\n",
       "      <td>YES</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>city</td>\n",
       "      <td>varchar</td>\n",
       "      <td>NO</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>state</td>\n",
       "      <td>varchar</td>\n",
       "      <td>YES</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>postalCode</td>\n",
       "      <td>varchar</td>\n",
       "      <td>YES</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>country</td>\n",
       "      <td>varchar</td>\n",
       "      <td>NO</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>salesRepEmployeeNumber</td>\n",
       "      <td>int</td>\n",
       "      <td>YES</td>\n",
       "      <td>MUL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>creditLimit</td>\n",
       "      <td>decimal</td>\n",
       "      <td>YES</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               COLUMN_NAME DATA_TYPE IS_NULLABLE COLUMN_KEY\n",
       "0           customerNumber       int          NO        PRI\n",
       "1             customerName   varchar          NO           \n",
       "2          contactLastName   varchar          NO           \n",
       "3         contactFirstName   varchar          NO           \n",
       "4                    phone   varchar          NO           \n",
       "5             addressLine1   varchar          NO           \n",
       "6             addressLine2   varchar         YES           \n",
       "7                     city   varchar          NO           \n",
       "8                    state   varchar         YES           \n",
       "9               postalCode   varchar         YES           \n",
       "10                 country   varchar          NO           \n",
       "11  salesRepEmployeeNumber       int         YES        MUL\n",
       "12             creditLimit   decimal         YES           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Schema for table: employees\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COLUMN_NAME</th>\n",
       "      <th>DATA_TYPE</th>\n",
       "      <th>IS_NULLABLE</th>\n",
       "      <th>COLUMN_KEY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>employeeNumber</td>\n",
       "      <td>int</td>\n",
       "      <td>NO</td>\n",
       "      <td>PRI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lastName</td>\n",
       "      <td>varchar</td>\n",
       "      <td>NO</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>firstName</td>\n",
       "      <td>varchar</td>\n",
       "      <td>NO</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>extension</td>\n",
       "      <td>varchar</td>\n",
       "      <td>NO</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>email</td>\n",
       "      <td>varchar</td>\n",
       "      <td>NO</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>officeCode</td>\n",
       "      <td>varchar</td>\n",
       "      <td>NO</td>\n",
       "      <td>MUL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>reportsTo</td>\n",
       "      <td>int</td>\n",
       "      <td>YES</td>\n",
       "      <td>MUL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>jobTitle</td>\n",
       "      <td>varchar</td>\n",
       "      <td>NO</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      COLUMN_NAME DATA_TYPE IS_NULLABLE COLUMN_KEY\n",
       "0  employeeNumber       int          NO        PRI\n",
       "1        lastName   varchar          NO           \n",
       "2       firstName   varchar          NO           \n",
       "3       extension   varchar          NO           \n",
       "4           email   varchar          NO           \n",
       "5      officeCode   varchar          NO        MUL\n",
       "6       reportsTo       int         YES        MUL\n",
       "7        jobTitle   varchar          NO           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Schema for table: offices\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COLUMN_NAME</th>\n",
       "      <th>DATA_TYPE</th>\n",
       "      <th>IS_NULLABLE</th>\n",
       "      <th>COLUMN_KEY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>officeCode</td>\n",
       "      <td>varchar</td>\n",
       "      <td>NO</td>\n",
       "      <td>PRI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>city</td>\n",
       "      <td>varchar</td>\n",
       "      <td>NO</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>phone</td>\n",
       "      <td>varchar</td>\n",
       "      <td>NO</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>addressLine1</td>\n",
       "      <td>varchar</td>\n",
       "      <td>NO</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>addressLine2</td>\n",
       "      <td>varchar</td>\n",
       "      <td>YES</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>state</td>\n",
       "      <td>varchar</td>\n",
       "      <td>YES</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>country</td>\n",
       "      <td>varchar</td>\n",
       "      <td>NO</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>postalCode</td>\n",
       "      <td>varchar</td>\n",
       "      <td>NO</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>territory</td>\n",
       "      <td>varchar</td>\n",
       "      <td>NO</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    COLUMN_NAME DATA_TYPE IS_NULLABLE COLUMN_KEY\n",
       "0    officeCode   varchar          NO        PRI\n",
       "1          city   varchar          NO           \n",
       "2         phone   varchar          NO           \n",
       "3  addressLine1   varchar          NO           \n",
       "4  addressLine2   varchar         YES           \n",
       "5         state   varchar         YES           \n",
       "6       country   varchar          NO           \n",
       "7    postalCode   varchar          NO           \n",
       "8     territory   varchar          NO           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Schema for table: orderdetails\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COLUMN_NAME</th>\n",
       "      <th>DATA_TYPE</th>\n",
       "      <th>IS_NULLABLE</th>\n",
       "      <th>COLUMN_KEY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>orderNumber</td>\n",
       "      <td>int</td>\n",
       "      <td>NO</td>\n",
       "      <td>PRI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>productCode</td>\n",
       "      <td>varchar</td>\n",
       "      <td>NO</td>\n",
       "      <td>PRI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>quantityOrdered</td>\n",
       "      <td>int</td>\n",
       "      <td>NO</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>priceEach</td>\n",
       "      <td>decimal</td>\n",
       "      <td>NO</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>orderLineNumber</td>\n",
       "      <td>smallint</td>\n",
       "      <td>NO</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       COLUMN_NAME DATA_TYPE IS_NULLABLE COLUMN_KEY\n",
       "0      orderNumber       int          NO        PRI\n",
       "1      productCode   varchar          NO        PRI\n",
       "2  quantityOrdered       int          NO           \n",
       "3        priceEach   decimal          NO           \n",
       "4  orderLineNumber  smallint          NO           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Schema for table: orders\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COLUMN_NAME</th>\n",
       "      <th>DATA_TYPE</th>\n",
       "      <th>IS_NULLABLE</th>\n",
       "      <th>COLUMN_KEY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>orderNumber</td>\n",
       "      <td>int</td>\n",
       "      <td>NO</td>\n",
       "      <td>PRI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>orderDate</td>\n",
       "      <td>date</td>\n",
       "      <td>NO</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>requiredDate</td>\n",
       "      <td>date</td>\n",
       "      <td>NO</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>shippedDate</td>\n",
       "      <td>date</td>\n",
       "      <td>YES</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>status</td>\n",
       "      <td>varchar</td>\n",
       "      <td>NO</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>comments</td>\n",
       "      <td>text</td>\n",
       "      <td>YES</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>customerNumber</td>\n",
       "      <td>int</td>\n",
       "      <td>NO</td>\n",
       "      <td>MUL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      COLUMN_NAME DATA_TYPE IS_NULLABLE COLUMN_KEY\n",
       "0     orderNumber       int          NO        PRI\n",
       "1       orderDate      date          NO           \n",
       "2    requiredDate      date          NO           \n",
       "3     shippedDate      date         YES           \n",
       "4          status   varchar          NO           \n",
       "5        comments      text         YES           \n",
       "6  customerNumber       int          NO        MUL"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Schema for table: payments\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COLUMN_NAME</th>\n",
       "      <th>DATA_TYPE</th>\n",
       "      <th>IS_NULLABLE</th>\n",
       "      <th>COLUMN_KEY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>customerNumber</td>\n",
       "      <td>int</td>\n",
       "      <td>NO</td>\n",
       "      <td>PRI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>checkNumber</td>\n",
       "      <td>varchar</td>\n",
       "      <td>NO</td>\n",
       "      <td>PRI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>paymentDate</td>\n",
       "      <td>date</td>\n",
       "      <td>NO</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>amount</td>\n",
       "      <td>decimal</td>\n",
       "      <td>NO</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      COLUMN_NAME DATA_TYPE IS_NULLABLE COLUMN_KEY\n",
       "0  customerNumber       int          NO        PRI\n",
       "1     checkNumber   varchar          NO        PRI\n",
       "2     paymentDate      date          NO           \n",
       "3          amount   decimal          NO           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Schema for table: productlines\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COLUMN_NAME</th>\n",
       "      <th>DATA_TYPE</th>\n",
       "      <th>IS_NULLABLE</th>\n",
       "      <th>COLUMN_KEY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>productLine</td>\n",
       "      <td>varchar</td>\n",
       "      <td>NO</td>\n",
       "      <td>PRI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>textDescription</td>\n",
       "      <td>varchar</td>\n",
       "      <td>YES</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>htmlDescription</td>\n",
       "      <td>mediumtext</td>\n",
       "      <td>YES</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>image</td>\n",
       "      <td>mediumblob</td>\n",
       "      <td>YES</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       COLUMN_NAME   DATA_TYPE IS_NULLABLE COLUMN_KEY\n",
       "0      productLine     varchar          NO        PRI\n",
       "1  textDescription     varchar         YES           \n",
       "2  htmlDescription  mediumtext         YES           \n",
       "3            image  mediumblob         YES           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Schema for table: products\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COLUMN_NAME</th>\n",
       "      <th>DATA_TYPE</th>\n",
       "      <th>IS_NULLABLE</th>\n",
       "      <th>COLUMN_KEY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>productCode</td>\n",
       "      <td>varchar</td>\n",
       "      <td>NO</td>\n",
       "      <td>PRI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>productName</td>\n",
       "      <td>varchar</td>\n",
       "      <td>NO</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>productLine</td>\n",
       "      <td>varchar</td>\n",
       "      <td>NO</td>\n",
       "      <td>MUL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>productScale</td>\n",
       "      <td>varchar</td>\n",
       "      <td>NO</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>productVendor</td>\n",
       "      <td>varchar</td>\n",
       "      <td>NO</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>productDescription</td>\n",
       "      <td>text</td>\n",
       "      <td>NO</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>quantityInStock</td>\n",
       "      <td>smallint</td>\n",
       "      <td>NO</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>buyPrice</td>\n",
       "      <td>decimal</td>\n",
       "      <td>NO</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MSRP</td>\n",
       "      <td>decimal</td>\n",
       "      <td>NO</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          COLUMN_NAME DATA_TYPE IS_NULLABLE COLUMN_KEY\n",
       "0         productCode   varchar          NO        PRI\n",
       "1         productName   varchar          NO           \n",
       "2         productLine   varchar          NO        MUL\n",
       "3        productScale   varchar          NO           \n",
       "4       productVendor   varchar          NO           \n",
       "5  productDescription      text          NO           \n",
       "6     quantityInStock  smallint          NO           \n",
       "7            buyPrice   decimal          NO           \n",
       "8                MSRP   decimal          NO           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "qr = QueryRunner(engine, max_rows=200)\n",
    "test_sql = \"SELECT customerNumber, customerName, country FROM customers LIMIT 10;\"\n",
    "meta = qr.run(test_sql)\n",
    "print(\"Success:\", meta[\"success\"])\n",
    "if meta[\"success\"]:\n",
    "    display(meta[\"result_preview\"])\n",
    "else:\n",
    "    print(\"Error:\", meta[\"error\"])\n",
    "\n",
    "# List and display schema\n",
    "for table_name in list_tables(engine):\n",
    "    print(f\"\\nSchema for table: {table_name}\")\n",
    "    df_columns = get_table_columns(engine, table_name)\n",
    "    display(df_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6211d4d",
   "metadata": {},
   "source": [
    "## Dataset validation helper\n",
    "Run the static classicmodels test set against the live DB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be2672f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_test_set(path: str = \"data/classicmodels_test_200.json\", limit: Optional[int] = None):\n",
    "    import json\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        items = json.load(f)\n",
    "    if limit:\n",
    "        items = items[:limit]\n",
    "\n",
    "    qr = QueryRunner(engine, max_rows=200)\n",
    "    successes = []\n",
    "    failures = []\n",
    "    for idx, item in enumerate(items):\n",
    "        meta = qr.run(item[\"sql\"], capture_df=False)\n",
    "        if meta[\"success\"]:\n",
    "            successes.append(idx)\n",
    "        else:\n",
    "            failures.append({\n",
    "                \"index\": idx,\n",
    "                \"nlq\": item.get(\"nlq\"),\n",
    "                \"sql\": item.get(\"sql\"),\n",
    "                \"error\": meta[\"error\"],\n",
    "            })\n",
    "    print(f\"Ran {len(items)} queries. Success: {len(successes)}. Failures: {len(failures)}.\")\n",
    "    if failures:\n",
    "        print(\"Failures (first 5):\")\n",
    "        for f in failures[:5]:\n",
    "            print(f)\n",
    "    else:\n",
    "        print(\"All queries succeeded in this run.\")\n",
    "    return successes, failures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae55a72",
   "metadata": {},
   "source": [
    "## Load static test set\n",
    "Use the fixed 200-sample NLQ-SQL pairs from data/classicmodels_test_200.json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25d6fd24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 200 test items from data/classicmodels_test_200.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open('data/classicmodels_test_200.json', 'r', encoding='utf-8') as f:\n",
    "    test_set = json.load(f)\n",
    "print(f\"Loaded {len(test_set)} test items from data/classicmodels_test_200.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1deb57f",
   "metadata": {},
   "source": [
    "## Load base model/tokenizer (pre-QLoRA placeholder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fba9603",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "LocalTokenNotFoundError",
     "evalue": "Token is required (`token=True`), but no token found. You need to provide a token or be logged in to Hugging Face with `hf auth login` or `huggingface_hub.login`. See https://huggingface.co/settings/tokens.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLocalTokenNotFoundError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, AutoModelForCausalLM\n\u001b[1;32m      4\u001b[0m model_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta-llama/Meta-Llama-3-8B-Instruct\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 6\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_id, token\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModelForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m      8\u001b[0m     model_id,\n\u001b[1;32m      9\u001b[0m     torch_dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mbfloat16,\n\u001b[1;32m     10\u001b[0m     device_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m     token\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTokenizer and model \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m loaded successfully.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/models/auto/tokenization_auto.py:758\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    757\u001b[0m \u001b[38;5;66;03m# Next, let's try to use the tokenizer_config file to get the tokenizer class.\u001b[39;00m\n\u001b[0;32m--> 758\u001b[0m tokenizer_config \u001b[38;5;241m=\u001b[39m get_tokenizer_config(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m tokenizer_config:\n\u001b[1;32m    760\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m tokenizer_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/models/auto/tokenization_auto.py:590\u001b[0m, in \u001b[0;36mget_tokenizer_config\u001b[0;34m(pretrained_model_name_or_path, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, **kwargs)\u001b[0m\n\u001b[1;32m    587\u001b[0m     token \u001b[38;5;241m=\u001b[39m use_auth_token\n\u001b[1;32m    589\u001b[0m commit_hash \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 590\u001b[0m resolved_config_file \u001b[38;5;241m=\u001b[39m cached_file(\n\u001b[1;32m    591\u001b[0m     pretrained_model_name_or_path,\n\u001b[1;32m    592\u001b[0m     TOKENIZER_CONFIG_FILE,\n\u001b[1;32m    593\u001b[0m     cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[1;32m    594\u001b[0m     force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[1;32m    595\u001b[0m     resume_download\u001b[38;5;241m=\u001b[39mresume_download,\n\u001b[1;32m    596\u001b[0m     proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[1;32m    597\u001b[0m     token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[1;32m    598\u001b[0m     revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[1;32m    599\u001b[0m     local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m    600\u001b[0m     subfolder\u001b[38;5;241m=\u001b[39msubfolder,\n\u001b[1;32m    601\u001b[0m     _raise_exceptions_for_missing_entries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    602\u001b[0m     _raise_exceptions_for_connection_errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    603\u001b[0m     _commit_hash\u001b[38;5;241m=\u001b[39mcommit_hash,\n\u001b[1;32m    604\u001b[0m )\n\u001b[1;32m    605\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resolved_config_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    606\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not locate the tokenizer configuration file, will try to use the model config instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/utils/hub.py:385\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    382\u001b[0m user_agent \u001b[38;5;241m=\u001b[39m http_user_agent(user_agent)\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 385\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m hf_hub_download(\n\u001b[1;32m    386\u001b[0m         path_or_repo_id,\n\u001b[1;32m    387\u001b[0m         filename,\n\u001b[1;32m    388\u001b[0m         subfolder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(subfolder) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m subfolder,\n\u001b[1;32m    389\u001b[0m         repo_type\u001b[38;5;241m=\u001b[39mrepo_type,\n\u001b[1;32m    390\u001b[0m         revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[1;32m    391\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[1;32m    392\u001b[0m         user_agent\u001b[38;5;241m=\u001b[39muser_agent,\n\u001b[1;32m    393\u001b[0m         force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[1;32m    394\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[1;32m    395\u001b[0m         resume_download\u001b[38;5;241m=\u001b[39mresume_download,\n\u001b[1;32m    396\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[1;32m    397\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m    398\u001b[0m     )\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    401\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to access a gated repo.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMake sure to request access at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    402\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and pass a token having permission to this repo either \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mby logging in with `huggingface-cli login` or by passing `token=<your_token>`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    404\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/huggingface_hub/file_download.py:969\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m    966\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m repo_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m constants\u001b[38;5;241m.\u001b[39mREPO_TYPES:\n\u001b[1;32m    967\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid repo type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Accepted repo types are: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(constants\u001b[38;5;241m.\u001b[39mREPO_TYPES)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 969\u001b[0m hf_headers \u001b[38;5;241m=\u001b[39m build_hf_headers(\n\u001b[1;32m    970\u001b[0m     token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[1;32m    971\u001b[0m     library_name\u001b[38;5;241m=\u001b[39mlibrary_name,\n\u001b[1;32m    972\u001b[0m     library_version\u001b[38;5;241m=\u001b[39mlibrary_version,\n\u001b[1;32m    973\u001b[0m     user_agent\u001b[38;5;241m=\u001b[39muser_agent,\n\u001b[1;32m    974\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m    975\u001b[0m )\n\u001b[1;32m    977\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m local_dir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    978\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m local_dir_use_symlinks \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/huggingface_hub/utils/_deprecation.py:101\u001b[0m, in \u001b[0;36m_deprecate_arguments.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     99\u001b[0m         message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m custom_message\n\u001b[1;32m    100\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m)\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/huggingface_hub/utils/_headers.py:126\u001b[0m, in \u001b[0;36mbuild_hf_headers\u001b[0;34m(token, library_name, library_version, user_agent, headers, is_write_action)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;124;03mBuild headers dictionary to send in a HF Hub call.\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;124;03m        If `token=True` but token is not saved locally.\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;66;03m# Get auth token to send\u001b[39;00m\n\u001b[0;32m--> 126\u001b[0m token_to_send \u001b[38;5;241m=\u001b[39m get_token_to_send(token)\n\u001b[1;32m    128\u001b[0m \u001b[38;5;66;03m# Combine headers\u001b[39;00m\n\u001b[1;32m    129\u001b[0m hf_headers \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser-agent\u001b[39m\u001b[38;5;124m\"\u001b[39m: _http_user_agent(\n\u001b[1;32m    131\u001b[0m         library_name\u001b[38;5;241m=\u001b[39mlibrary_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    134\u001b[0m     )\n\u001b[1;32m    135\u001b[0m }\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/huggingface_hub/utils/_headers.py:159\u001b[0m, in \u001b[0;36mget_token_to_send\u001b[0;34m(token)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cached_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 159\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LocalTokenNotFoundError(\n\u001b[1;32m    160\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mToken is required (`token=True`), but no token found. You\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    161\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m need to provide a token or be logged in to Hugging Face with\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    162\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `hf auth login` or `huggingface_hub.login`. See\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    163\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m https://huggingface.co/settings/tokens.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    164\u001b[0m         )\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cached_token\n\u001b[1;32m    167\u001b[0m \u001b[38;5;66;03m# Case implicit use of the token is forbidden by env variable\u001b[39;00m\n",
      "\u001b[0;31mLocalTokenNotFoundError\u001b[0m: Token is required (`token=True`), but no token found. You need to provide a token or be logged in to Hugging Face with `hf auth login` or `huggingface_hub.login`. See https://huggingface.co/settings/tokens."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, token=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    token=True\n",
    ")\n",
    "\n",
    "print(f\"Tokenizer and model '{model_id}' loaded successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
