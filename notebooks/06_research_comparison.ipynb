{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53a1dd45",
   "metadata": {},
   "source": [
    "# research comparison (hypothesis stats)\n",
    "\n",
    "links:\n",
    "- code: `/Users/mackenzieobrian/MacDoc/Dissertation/scripts/generate_research_comparison.py`\n",
    "- docs: [shapiro](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.shapiro.html), [paired t-test](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_rel.html)\n",
    "- literature: [dror et al. 2018](https://aclanthology.org/P18-1128/), [spider](https://aclanthology.org/D18-1425/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b67c83",
   "metadata": {},
   "source": [
    "this notebook runs the required stats on one chosen per-item file and shows compact visuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba0ac70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# set project root for local or colab\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "if not (PROJECT_ROOT / \"results\").exists():\n",
    "    PROJECT_ROOT = PROJECT_ROOT.parent\n",
    "\n",
    "sys.path.append(str(PROJECT_ROOT))\n",
    "from scripts.generate_research_comparison import generate\n",
    "\n",
    "OUT_DIR = PROJECT_ROOT / \"results\" / \"analysis\"\n",
    "\n",
    "# choose input file for this demo\n",
    "PER_ITEM = OUT_DIR / \"per_item_metrics_extension_constrained.csv\"\n",
    "if not PER_ITEM.exists():\n",
    "    PER_ITEM = OUT_DIR / \"per_item_metrics.csv\"\n",
    "\n",
    "DEMO_OUT_DIR = OUT_DIR / \"demo_stats\"\n",
    "summary = generate(per_item_csv=PER_ITEM, out_dir=DEMO_OUT_DIR)\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2191dd",
   "metadata": {},
   "source": [
    "## summary tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82031fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapiro_df = pd.read_csv(DEMO_OUT_DIR / \"stats_mean_median_shapiro.csv\")\n",
    "ttest_df = pd.read_csv(DEMO_OUT_DIR / \"stats_paired_ttests.csv\")\n",
    "\n",
    "display(shapiro_df.sort_values([\"run_id\", \"metric\"]).reset_index(drop=True))\n",
    "display(ttest_df.sort_values([\"comparison\", \"metric\"]).reset_index(drop=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b2136c",
   "metadata": {},
   "source": [
    "## how to read these stats\n",
    "\n",
    "- mean: average metric value (for va/em/ex this is a rate).\n",
    "- median: middle value across examples.\n",
    "- shapiro_p: normality check p-value.\n",
    "- paired t-test p_value: significance of right-minus-left delta.\n",
    "- reject_H0: statistically significant difference at alpha=0.05.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe44dc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compact interpretation from current outputs\n",
    "ex_rows = ttest_df[ttest_df[\"metric\"] == \"ex\"].copy()\n",
    "va_rows = ttest_df[ttest_df[\"metric\"] == \"va\"].copy()\n",
    "ts_rows = ttest_df[ttest_df[\"metric\"] == \"ts\"].copy()\n",
    "\n",
    "print(\"ex interpretation:\")\n",
    "if ex_rows.empty:\n",
    "    print(\"- no ex paired rows found\")\n",
    "else:\n",
    "    for _, r in ex_rows.iterrows():\n",
    "        diff = r[\"mean_diff_right_minus_left\"]\n",
    "        pval = r[\"p_value\"]\n",
    "        dec = r[\"decision_alpha_0_05\"]\n",
    "        sign = \"improved\" if diff > 0 else \"decreased\"\n",
    "        if dec == \"reject_H0\":\n",
    "            print(f\"- {r['comparison']}: {sign} by {abs(diff):.3f} (p={pval:.4g}, significant)\")\n",
    "        else:\n",
    "            print(f\"- {r['comparison']}: change {diff:.3f} (p={pval:.4g}, not significant)\")\n",
    "\n",
    "print()\n",
    "print(\"va interpretation:\")\n",
    "if va_rows.empty:\n",
    "    print(\"- no va paired rows found\")\n",
    "else:\n",
    "    sig = va_rows[va_rows[\"decision_alpha_0_05\"] == \"reject_H0\"]\n",
    "    if sig.empty:\n",
    "        print(\"- no significant va differences in current paired comparisons\")\n",
    "    else:\n",
    "        for _, r in sig.iterrows():\n",
    "            print(f\"- {r['comparison']}: va delta {r['mean_diff_right_minus_left']:.3f} (p={r['p_value']:.4g})\")\n",
    "\n",
    "print()\n",
    "print(\"ts interpretation:\")\n",
    "if ts_rows.empty:\n",
    "    print(\"- no ts paired rows found\")\n",
    "else:\n",
    "    usable = ts_rows[ts_rows[\"n_pairs\"] > 0]\n",
    "    if usable.empty:\n",
    "        print(\"- ts exists in artifacts but has no paired coverage for these comparisons\")\n",
    "    else:\n",
    "        print(\"- ts has paired coverage and can be interpreted for listed rows\")\n",
    "\n",
    "print()\n",
    "print(\"note: this notebook uses the selected per-item file shown in the summary above.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0875411c",
   "metadata": {},
   "source": [
    "## run-level means (va and ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc03a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_df = shapiro_df[shapiro_df[\"metric\"].isin([\"va\", \"ex\"])].copy()\n",
    "mean_pivot = mean_df.pivot(index=\"run_id\", columns=\"metric\", values=\"mean\").sort_index()\n",
    "display(mean_pivot)\n",
    "\n",
    "if not mean_pivot.empty:\n",
    "    ax = mean_pivot.plot(kind=\"bar\", figsize=(9, 4), rot=30)\n",
    "    ax.set_ylim(0, 1.0)\n",
    "    ax.set_ylabel(\"mean score\")\n",
    "    ax.set_title(\"run-level means\")\n",
    "    ax.grid(axis=\"y\", alpha=0.25)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d01d4ac",
   "metadata": {},
   "source": [
    "## paired ex deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68190eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = ttest_df[ttest_df[\"metric\"] == \"ex\"].copy()\n",
    "if not plot_df.empty:\n",
    "    plot_df = plot_df.sort_values(\"mean_diff_right_minus_left\")\n",
    "    colors = [\"#2a9d8f\" if (p < 0.05) else \"#457b9d\" for p in plot_df[\"p_value\"].fillna(1.0)]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(9, 4))\n",
    "    ax.barh(plot_df[\"comparison\"], plot_df[\"mean_diff_right_minus_left\"], color=colors)\n",
    "    ax.axvline(0.0, color=\"black\", linewidth=1)\n",
    "    ax.set_xlabel(\"delta (right - left)\")\n",
    "    ax.set_title(\"ex deltas with p<0.05 highlight\")\n",
    "    ax.grid(axis=\"x\", alpha=0.25)\n",
    "\n",
    "    for y, (_, row) in enumerate(plot_df.iterrows()):\n",
    "        pv = row.get(\"p_value\")\n",
    "        label = f\"p={pv:.3g}\" if pd.notna(pv) else \"p=na\"\n",
    "        ax.text(row[\"mean_diff_right_minus_left\"], y, f\"  {label}\", va=\"center\", fontsize=9)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"no ex rows found in paired test output\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
