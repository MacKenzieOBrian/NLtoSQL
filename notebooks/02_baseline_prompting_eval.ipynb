{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "962754b6",
   "metadata": {},
   "source": [
    "# Baseline Eval\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4a3467",
   "metadata": {},
   "source": [
    "## Summary\n",
    "- Purpose: establish the prompting-only baseline for NL->SQL (`k=0` and `k=3`).\n",
    "- Scope: runs on the fixed 200-item ClassicModels benchmark for paired comparisons.\n",
    "- Outputs: baseline run JSON files under `results/baseline/` for downstream analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f6773c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "set -e\n",
    "export PIP_DEFAULT_TIMEOUT=120\n",
    "\n",
    "# Clean conflicting preinstalls\n",
    "pip uninstall -y torch torchvision torchaudio bitsandbytes triton transformers accelerate peft trl datasets numpy pandas fsspec requests google-auth scipy scikit-learn || true\n",
    "\n",
    "# Base deps\n",
    "pip install -q --no-cache-dir --force-reinstall \\\n",
    "  numpy==1.26.4 pandas==2.2.1 scipy scikit-learn \\\n",
    "  fsspec==2024.5.0 requests==2.31.0 google-auth==2.43.0\n",
    "\n",
    "# Torch + CUDA 12.1\n",
    "pip install -q --no-cache-dir --force-reinstall \\\n",
    "  torch==2.3.1+cu121 torchvision==0.18.1+cu121 torchaudio==2.3.1+cu121 \\\n",
    "  --index-url https://download.pytorch.org/whl/cu121\n",
    "\n",
    "# bitsandbytes + triton + HF stack\n",
    "pip install -q --no-cache-dir --force-reinstall \\\n",
    "  bitsandbytes==0.43.3 triton==2.3.1 \\\n",
    "  transformers==4.44.2 accelerate==0.33.0 peft==0.17.0 trl==0.9.6 datasets==2.20.0\n",
    "\n",
    "echo \"Setup complete. Restart runtime once, then run the rest of the notebook top-to-bottom.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba5f922",
   "metadata": {},
   "source": [
    "## 0) Bootstrap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd30aacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# If this notebook is opened directly in Colab (not from a cloned repo), clone the repo first.\n",
    "if Path(\"data/classicmodels_test_200.json\").exists() is False and Path(\"/content\").exists():\n",
    "    repo_dir = Path(\"/content/NLtoSQL\")\n",
    "    if repo_dir.exists():\n",
    "        shutil.rmtree(repo_dir)\n",
    "    !git clone https://github.com/MacKenzieOBrian/NLtoSQL.git \"{repo_dir}\"\n",
    "    os.chdir(repo_dir)\n",
    "\n",
    "# Ensure repo root is on sys.path for `import nl2sql`\n",
    "sys.path.insert(0, os.getcwd())\n",
    "print(\"cwd:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a65e12",
   "metadata": {},
   "source": [
    "## 1) Install\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4a0263",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab  # noqa: F401\n",
    "    IN_COLAB = True\n",
    "except Exception:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    !pip -q install -r requirements.txt\n",
    "else:\n",
    "    print(\"Not in Colab; ensure requirements are installed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644e4296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colab-only: authenticate with GCP (safe to skip locally)\n",
    "try:\n",
    "    from google.colab import auth\n",
    "except ModuleNotFoundError:\n",
    "    auth = None\n",
    "\n",
    "if auth:\n",
    "    auth.authenticate_user()\n",
    "else:\n",
    "    print(\"Not running in Colab; ensure ADC or service account auth is configured.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a375d04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hugging Face auth (gated model)\n",
    "import os\n",
    "\n",
    "hf_token = os.getenv(\"HF_TOKEN\") or os.getenv(\"HUGGINGFACE_HUB_TOKEN\")\n",
    "if hf_token:\n",
    "    os.environ[\"HUGGINGFACE_HUB_TOKEN\"] = hf_token\n",
    "    print(\"Using HF token from env\")\n",
    "else:\n",
    "    try:\n",
    "        from huggingface_hub import notebook_login\n",
    "        notebook_login()\n",
    "    except Exception as e:\n",
    "        print(\"HF auth not configured:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8db21f",
   "metadata": {},
   "source": [
    "## 2) Data + DB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc093bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from getpass import getpass\n",
    "\n",
    "INSTANCE_CONNECTION_NAME = os.getenv(\"INSTANCE_CONNECTION_NAME\")\n",
    "DB_USER = os.getenv(\"DB_USER\")\n",
    "DB_PASS = os.getenv(\"DB_PASS\")\n",
    "DB_NAME = os.getenv(\"DB_NAME\", \"classicmodels\")\n",
    "\n",
    "if not INSTANCE_CONNECTION_NAME:\n",
    "    INSTANCE_CONNECTION_NAME = input(\"Enter INSTANCE_CONNECTION_NAME: \").strip()\n",
    "if not DB_USER:\n",
    "    DB_USER = input(\"Enter DB_USER: \").strip()\n",
    "if not DB_PASS:\n",
    "    DB_PASS = getpass(\"Enter DB_PASS: \")\n",
    "\n",
    "print(\"Using DB:\", DB_NAME)\n",
    "\n",
    "test_set = json.loads(open(\"data/classicmodels_test_200.json\", \"r\", encoding=\"utf-8\").read())\n",
    "print(\"Loaded test items:\", len(test_set))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1016babb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nl2sql.db import create_engine_with_connector\n",
    "\n",
    "engine, connector = create_engine_with_connector(\n",
    "    instance_connection_name=INSTANCE_CONNECTION_NAME,\n",
    "    user=DB_USER,\n",
    "    password=DB_PASS,\n",
    "    db_name=DB_NAME,\n",
    ")\n",
    "\n",
    "print(\"Engine ready\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b951b4",
   "metadata": {},
   "source": [
    "## 3) Load Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9070492",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "MODEL_ID = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "\n",
    "print(\"Loading tokenizer...\")\n",
    "tok = AutoTokenizer.from_pretrained(MODEL_ID, token=True)\n",
    "if tok.pad_token is None:\n",
    "    tok.pad_token = tok.eos_token\n",
    "\n",
    "# Try 4-bit loading (fallback to fp/bf16)\n",
    "try:\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    )\n",
    "    print(\"Attempting 4-bit quantized load...\")\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_ID,\n",
    "        quantization_config=bnb_config,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        device_map=\"auto\",\n",
    "        token=True,\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(\"4-bit load failed, falling back. Error:\")\n",
    "    print(e)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_ID,\n",
    "        torch_dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float32,\n",
    "        device_map=\"auto\" if torch.cuda.is_available() else None,\n",
    "        token=True,\n",
    "    )\n",
    "\n",
    "model.generation_config.do_sample = False\n",
    "model.generation_config.num_beams = 1\n",
    "\n",
    "print(\"Model device:\", model.device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb7e719",
   "metadata": {},
   "source": [
    "## 4) Schema Context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274de10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nl2sql.schema import build_schema_summary\n",
    "\n",
    "SCHEMA_SUMMARY = build_schema_summary(engine, db_name=DB_NAME, max_cols_per_table=50)\n",
    "print(\"Schema summary built (chars):\", len(SCHEMA_SUMMARY))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382bccdf",
   "metadata": {},
   "source": [
    "## 5) Run Controls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89802cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Orchestration helpers for baseline sweep runs.\n",
    "# Core NL->SQL logic stays in nl2sql imports below.\n",
    "import re\n",
    "import subprocess\n",
    "import shutil\n",
    "from functools import lru_cache\n",
    "from datetime import datetime, timezone\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from nl2sql.eval import eval_run\n",
    "from nl2sql.db import create_engine_with_connector\n",
    "import nl2sql.prompting as prompting_mod\n",
    "\n",
    "DEFAULT_SYSTEM_INSTRUCTIONS = prompting_mod.SYSTEM_INSTRUCTIONS\n",
    "\n",
    "\n",
    "def _model_alias_from_id(model_id: str) -> str:\n",
    "    tail = (model_id or \"model\").split(\"/\")[-1]\n",
    "    alias = re.sub(r\"[^a-z0-9]+\", \"_\", tail.lower()).strip(\"_\")\n",
    "    return alias or \"model\"\n",
    "\n",
    "\n",
    "# Prompt variants for controlled prompt-ablation runs.\n",
    "PROMPT_VARIANTS = {\n",
    "    \"default\": DEFAULT_SYSTEM_INSTRUCTIONS,\n",
    "    \"schema_only_minimal\": \"\"\"You are an expert data analyst writing MySQL queries.\n",
    "Given the database schema and a natural language question, write a single SQL SELECT query.\n",
    "\n",
    "Rules:\n",
    "- Output ONLY SQL (no explanation, no markdown).\n",
    "- Output exactly ONE statement, starting with SELECT.\n",
    "- Use only tables/columns listed in the schema.\n",
    "\"\"\",\n",
    "    \"no_routing_hints\": DEFAULT_SYSTEM_INSTRUCTIONS.split(\"- Routing hints:\")[0].rstrip(),\n",
    "}\n",
    "\n",
    "# Schema truncation variants for schema-ablation experiments.\n",
    "def schema_variant_text(schema_text: str, variant: str) -> str:\n",
    "    lines = schema_text.splitlines()\n",
    "    if variant == \"full\":\n",
    "        return schema_text\n",
    "    if variant == \"first_80_lines\":\n",
    "        return \"\\n\".join(lines[:80])\n",
    "    if variant == \"first_40_lines\":\n",
    "        return \"\\n\".join(lines[:40])\n",
    "    raise ValueError(f\"Unknown SCHEMA_VARIANT: {variant}\")\n",
    "\n",
    "# Exemplar-pool strategies for few-shot ablations.\n",
    "def exemplar_pool_for_strategy(items: list[dict], strategy: str) -> list[dict]:\n",
    "    if strategy == \"all\":\n",
    "        return list(items)\n",
    "\n",
    "    def _sql(x):\n",
    "        return str(x.get(\"sql\", \"\")).strip()\n",
    "\n",
    "    def _is_join(sql: str) -> bool:\n",
    "        s = sql.lower()\n",
    "        return \" join \" in f\" {s} \"\n",
    "\n",
    "    def _is_agg(sql: str) -> bool:\n",
    "        return bool(re.search(r\"\\b(sum|avg|count|min|max)\\s*\\(\", sql.lower()))\n",
    "\n",
    "    if strategy == \"brief_sql\":\n",
    "        ranked = sorted(items, key=lambda x: len(_sql(x)))\n",
    "        keep = max(50, int(0.4 * len(ranked)))\n",
    "        pool = ranked[:keep]\n",
    "    elif strategy == \"join_heavy\":\n",
    "        pool = [x for x in items if _is_join(_sql(x))]\n",
    "    elif strategy == \"agg_heavy\":\n",
    "        pool = [x for x in items if _is_agg(_sql(x))]\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown EXEMPLAR_STRATEGY: {strategy}\")\n",
    "\n",
    "    return pool if len(pool) >= 10 else list(items)\n",
    "\n",
    "# Capture git commit for run provenance (optional).\n",
    "try:\n",
    "    commit = subprocess.check_output([\"git\", \"rev-parse\", \"--short\", \"HEAD\"]).decode().strip()\n",
    "except Exception:\n",
    "    commit = \"unknown\"\n",
    "\n",
    "# Base metadata attached to each saved run JSON.\n",
    "run_metadata_base = {\n",
    "    \"commit\": commit,\n",
    "    \"model_id\": MODEL_ID,\n",
    "    \"model_alias\": _model_alias_from_id(MODEL_ID),\n",
    "    \"notebook\": \"02_baseline_prompting_eval.ipynb\",\n",
    "    \"method\": \"baseline\",\n",
    "}\n",
    "\n",
    "# Ensure output root exists before writing run artifacts.\n",
    "Path(\"results/baseline\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "# Optional Colab helper: copy completed run artifacts to Drive.\n",
    "def persist_run_to_drive(\n",
    "    run_dir: str | Path,\n",
    "    model_alias: str,\n",
    "    k_values: list[int],\n",
    "    run_tag: str,\n",
    "    persist_root: str = \"/content/drive/MyDrive/nl2sql_persistent_runs\",\n",
    "):\n",
    "    # Copy baseline run outputs to Google Drive to survive Colab disconnects.\n",
    "    run_dir = Path(run_dir)\n",
    "    root = Path(persist_root)\n",
    "    root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    stamp = datetime.now(timezone.utc).strftime(\"%Y%m%d_%H%M%SZ\")\n",
    "    dst = root / f\"{run_dir.name}_{stamp}\"\n",
    "    dst.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for p in run_dir.glob(\"*\"):\n",
    "        if p.is_file():\n",
    "            shutil.copy2(p, dst / p.name)\n",
    "\n",
    "    mf_src = Path(\"results/baseline/model_family\")\n",
    "    mf_dst = dst / \"model_family\"\n",
    "    mf_dst.mkdir(parents=True, exist_ok=True)\n",
    "    for k in k_values:\n",
    "        mf = mf_src / f\"{model_alias}_k{k}.json\"\n",
    "        if mf.exists():\n",
    "            shutil.copy2(mf, mf_dst / mf.name)\n",
    "\n",
    "    (dst / \"backup_manifest.txt\").write_text(\n",
    "        \"\\n\".join([\n",
    "            f\"run_dir={run_dir}\",\n",
    "            f\"backup_dir={dst}\",\n",
    "            f\"run_tag={run_tag}\",\n",
    "            f\"model_alias={model_alias}\",\n",
    "            f\"k_values={k_values}\",\n",
    "        ]),\n",
    "        encoding=\"utf-8\",\n",
    "    )\n",
    "    return dst\n",
    "\n",
    "# Main sweep runner: executes k/seed grid and writes JSON+CSV artifacts.\n",
    "def run_baseline_grid(\n",
    "    *,\n",
    "    k_values: list[int],\n",
    "    seeds: list[int],\n",
    "    run_tag: str,\n",
    "    prompt_variant: str,\n",
    "    schema_variant: str,\n",
    "    exemplar_strategy: str,\n",
    "    limit: int | None = None,\n",
    "    copy_canonical: bool = True,\n",
    "    copy_model_family: bool = True,\n",
    "    model_alias: str | None = None,\n",
    "    enable_ts_for_k: set[int] | None = None,\n",
    "    ts_n: int = 10,\n",
    "    ts_prefix: str = \"classicmodels_ts\",\n",
    "    ts_max_rows: int = 500,\n",
    "):\n",
    "    # Basic guardrails for reproducible runs.\n",
    "    if not seeds:\n",
    "        raise ValueError(\"Provide at least one seed\")\n",
    "\n",
    "    if prompt_variant not in PROMPT_VARIANTS:\n",
    "        raise ValueError(f\"Unknown PROMPT_VARIANT: {prompt_variant}\")\n",
    "\n",
    "    # Run directory is timestamped for traceability and collision safety.\n",
    "    ts = datetime.now(timezone.utc).strftime(\"%Y%m%d_%H%M%SZ\")\n",
    "    run_dir = Path(\"results/baseline/runs\") / f\"{run_tag}_{ts}\"\n",
    "    run_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    schema_used = schema_variant_text(SCHEMA_SUMMARY, schema_variant)\n",
    "    exemplar_pool = exemplar_pool_for_strategy(test_set, exemplar_strategy)\n",
    "    resolved_model_alias = model_alias or run_metadata_base.get(\"model_alias\") or _model_alias_from_id(MODEL_ID)\n",
    "\n",
    "    ts_enabled_k = set(enable_ts_for_k or set())\n",
    "    ts_suite_db_names = (\n",
    "        [f\"{ts_prefix}_{i:02d}\" for i in range(1, ts_n + 1)]\n",
    "        if ts_enabled_k and ts_n > 0\n",
    "        else None\n",
    "    )\n",
    "\n",
    "    # Lazy connector cache for optional TS evaluation databases.\n",
    "    ts_connectors = {}\n",
    "\n",
    "    @lru_cache(maxsize=32)\n",
    "    def _make_engine_cached(db_name: str):\n",
    "        eng, conn = create_engine_with_connector(\n",
    "            instance_connection_name=INSTANCE_CONNECTION_NAME,\n",
    "            user=DB_USER,\n",
    "            password=DB_PASS,\n",
    "            db_name=db_name,\n",
    "        )\n",
    "        ts_connectors[db_name] = conn\n",
    "        return eng\n",
    "\n",
    "    def _make_engine_fn(db_name: str):\n",
    "        return _make_engine_cached(db_name)\n",
    "\n",
    "    rows = []\n",
    "    primary_seed = seeds[0]  # first seed is used for canonical/model-family copies\n",
    "\n",
    "    # Prompt override is temporary and restored in finally.\n",
    "    old_prompt = prompting_mod.SYSTEM_INSTRUCTIONS\n",
    "    prompting_mod.SYSTEM_INSTRUCTIONS = PROMPT_VARIANTS[prompt_variant]\n",
    "\n",
    "    try:\n",
    "        for k in k_values:\n",
    "            # Keep k=0 tied to primary seed for canonical zero-shot consistency.\n",
    "            seed_list = [primary_seed] if k == 0 else seeds\n",
    "            for seed in seed_list:\n",
    "                save_path = run_dir / f\"results_k{k}_seed{seed}.json\"\n",
    "\n",
    "                run_meta = dict(run_metadata_base)\n",
    "                run_meta.update({\n",
    "                    \"run_tag\": run_tag,\n",
    "                    \"k\": k,\n",
    "                    \"seed\": seed,\n",
    "                    \"prompt_variant\": prompt_variant,\n",
    "                    \"schema_variant\": schema_variant,\n",
    "                    \"exemplar_strategy\": exemplar_strategy,\n",
    "                    \"exemplar_pool_size\": len(exemplar_pool),\n",
    "                    \"model_alias\": resolved_model_alias,\n",
    "                    \"ts_enabled\": bool(k in ts_enabled_k),\n",
    "                    \"ts_for_k_values\": sorted(ts_enabled_k),\n",
    "                    \"ts_n\": ts_n if ts_suite_db_names else 0,\n",
    "                })\n",
    "\n",
    "                items = eval_run(\n",
    "                    test_set=test_set,\n",
    "                    exemplar_pool=exemplar_pool,\n",
    "                    k=k,\n",
    "                    limit=limit,\n",
    "                    seed=seed,\n",
    "                    engine=engine,\n",
    "                    model=model,\n",
    "                    tokenizer=tok,\n",
    "                    schema_summary=schema_used,\n",
    "                    save_path=str(save_path),\n",
    "                    run_metadata=run_meta,\n",
    "                    ts_suite_db_names=ts_suite_db_names if k in ts_enabled_k else None,\n",
    "                    ts_make_engine_fn=_make_engine_fn if k in ts_enabled_k else None,\n",
    "                    ts_max_rows=ts_max_rows,\n",
    "                    avoid_exemplar_leakage=True,\n",
    "                )\n",
    "\n",
    "                # Aggregate per-run rates for quick table summaries.\n",
    "                n = len(items)\n",
    "                va = sum(int(x.va) for x in items) / max(n, 1)\n",
    "                em = sum(int(x.em) for x in items) / max(n, 1)\n",
    "                ex = sum(int(x.ex) for x in items) / max(n, 1)\n",
    "                ts_values = [int(x.ts) for x in items if getattr(x, \"ts\", None) is not None]\n",
    "                ts_rate = (sum(ts_values) / len(ts_values)) if ts_values else None\n",
    "\n",
    "                rows.append({\n",
    "                    \"run_tag\": run_tag,\n",
    "                    \"prompt_variant\": prompt_variant,\n",
    "                    \"schema_variant\": schema_variant,\n",
    "                    \"exemplar_strategy\": exemplar_strategy,\n",
    "                    \"exemplar_pool_size\": len(exemplar_pool),\n",
    "                    \"k\": k,\n",
    "                    \"seed\": seed,\n",
    "                    \"n\": n,\n",
    "                    \"va_rate\": va,\n",
    "                    \"em_rate\": em,\n",
    "                    \"ex_rate\": ex,\n",
    "                    \"ts_rate\": ts_rate,\n",
    "                    \"ts_n\": len(ts_values),\n",
    "                    \"json_path\": str(save_path),\n",
    "                })\n",
    "\n",
    "                if seed == primary_seed and k in {0, 3}:\n",
    "                    if copy_canonical:\n",
    "                        target = (\n",
    "                            Path(\"results/baseline/results_zero_shot_200.json\")\n",
    "                            if k == 0\n",
    "                            else Path(\"results/baseline/results_few_shot_k3_200.json\")\n",
    "                        )\n",
    "                        target.parent.mkdir(parents=True, exist_ok=True)\n",
    "                        shutil.copy2(save_path, target)\n",
    "                        print(f\"Updated canonical file: {target}\")\n",
    "\n",
    "                    if copy_model_family:\n",
    "                        model_target = Path(\"results/baseline/model_family\") / f\"{resolved_model_alias}_k{k}.json\"\n",
    "                        model_target.parent.mkdir(parents=True, exist_ok=True)\n",
    "                        shutil.copy2(save_path, model_target)\n",
    "                        print(f\"Updated model-family file: {model_target}\")\n",
    "    finally:\n",
    "        for conn in ts_connectors.values():\n",
    "            try:\n",
    "                conn.close()\n",
    "            except Exception:\n",
    "                pass\n",
    "        prompting_mod.SYSTEM_INSTRUCTIONS = old_prompt\n",
    "\n",
    "    # Save per-run table and per-k mean/std summary.\n",
    "    df = pd.DataFrame(rows).sort_values([\"k\", \"seed\"]).reset_index(drop=True)\n",
    "    df.to_csv(run_dir / \"grid_summary.csv\", index=False)\n",
    "\n",
    "    agg = (\n",
    "        df.groupby([\"prompt_variant\", \"schema_variant\", \"exemplar_strategy\", \"k\"], as_index=False)\n",
    "        .agg(\n",
    "            runs=(\"seed\", \"count\"),\n",
    "            va_mean=(\"va_rate\", \"mean\"),\n",
    "            va_std=(\"va_rate\", \"std\"),\n",
    "            em_mean=(\"em_rate\", \"mean\"),\n",
    "            em_std=(\"em_rate\", \"std\"),\n",
    "            ex_mean=(\"ex_rate\", \"mean\"),\n",
    "            ex_std=(\"ex_rate\", \"std\"),\n",
    "            ts_mean=(\"ts_rate\", \"mean\"),\n",
    "            ts_std=(\"ts_rate\", \"std\"),\n",
    "        )\n",
    "    )\n",
    "    agg.to_csv(run_dir / \"grid_summary_by_k.csv\", index=False)\n",
    "\n",
    "    print(\"Saved grid run to:\", run_dir)\n",
    "    return df, agg, run_dir\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cff0257",
   "metadata": {},
   "source": [
    "### 5A) Run Plan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693a3e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# Plan-driven baseline controls\n",
    "# ============================\n",
    "# Edit only this block for most experiments.\n",
    "# Keep one RUN_PLAN active per execution to isolate effects clearly.\n",
    "RUN_PLAN = \"quick\"  # quick | k5_core | seed_backfill | full_sweep | ts_k3 | custom\n",
    "\n",
    "PROMPT_VARIANT = \"default\"\n",
    "SCHEMA_VARIANT = \"full\"\n",
    "EXEMPLAR_STRATEGY = \"all\"\n",
    "\n",
    "MODEL_ALIAS = _model_alias_from_id(MODEL_ID)\n",
    "COPY_MODEL_FAMILY = True\n",
    "COPY_CANONICAL = False\n",
    "\n",
    "TS_N = 10\n",
    "TS_PREFIX = \"classicmodels_ts\"\n",
    "TS_MAX_ROWS = 500\n",
    "\n",
    "CUSTOM_PLAN = {\n",
    "    \"k_values\": [0, 3],\n",
    "    \"seeds\": [7],\n",
    "    \"run_tag\": \"baseline_custom\",\n",
    "    \"enable_ts\": False,\n",
    "}\n",
    "\n",
    "# Resolve plan -> concrete k/seed/run_tag values.\n",
    "if RUN_PLAN == \"quick\":\n",
    "    K_VALUES = [0, 3]\n",
    "    SEEDS = [7]\n",
    "    RUN_TAG = \"baseline_main\"\n",
    "    ENABLE_TS = False\n",
    "elif RUN_PLAN == \"k5_core\":\n",
    "    K_VALUES = [5]\n",
    "    SEEDS = [7]\n",
    "    RUN_TAG = \"baseline_k5_core\"\n",
    "    ENABLE_TS = False\n",
    "elif RUN_PLAN == \"seed_backfill\":\n",
    "    K_VALUES = [0, 3, 5]\n",
    "    SEEDS = [17, 27]\n",
    "    RUN_TAG = \"baseline_seed_backfill\"\n",
    "    ENABLE_TS = False\n",
    "elif RUN_PLAN == \"full_sweep\":\n",
    "    K_VALUES = [0, 3, 5]\n",
    "    SEEDS = [7, 17, 27]\n",
    "    RUN_TAG = \"baseline_e1_k_sweep\"\n",
    "    ENABLE_TS = False\n",
    "elif RUN_PLAN == \"ts_k3\":\n",
    "    K_VALUES = [3]\n",
    "    SEEDS = [7]\n",
    "    RUN_TAG = \"baseline_ts_k3\"\n",
    "    ENABLE_TS = True\n",
    "elif RUN_PLAN == \"custom\":\n",
    "    K_VALUES = list(CUSTOM_PLAN[\"k_values\"])\n",
    "    SEEDS = list(CUSTOM_PLAN[\"seeds\"])\n",
    "    RUN_TAG = str(CUSTOM_PLAN[\"run_tag\"])\n",
    "    ENABLE_TS = bool(CUSTOM_PLAN[\"enable_ts\"])\n",
    "else:\n",
    "    raise ValueError(f\"Unknown RUN_PLAN: {RUN_PLAN}\")\n",
    "\n",
    "# TS is typically enabled only for k=3 semantic robustness checks.\n",
    "TS_FOR_K_VALUES = [3]\n",
    "\n",
    "# Run card is a quick sanity check before launching a long run.\n",
    "print(\"Baseline run card:\")\n",
    "print({\n",
    "    \"run_plan\": RUN_PLAN,\n",
    "    \"run_tag\": RUN_TAG,\n",
    "    \"model_id\": MODEL_ID,\n",
    "    \"model_alias\": MODEL_ALIAS,\n",
    "    \"k_values\": K_VALUES,\n",
    "    \"seeds\": SEEDS,\n",
    "    \"prompt_variant\": PROMPT_VARIANT,\n",
    "    \"schema_variant\": SCHEMA_VARIANT,\n",
    "    \"exemplar_strategy\": EXEMPLAR_STRATEGY,\n",
    "    \"enable_ts\": ENABLE_TS,\n",
    "})\n",
    "\n",
    "# Colab persistence toggle\n",
    "PERSIST_TO_DRIVE = True\n",
    "DRIVE_PERSIST_ROOT = \"/content/drive/MyDrive/nl2sql_persistent_runs\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo: End-to-end NLQ -> faulty SQL -> cleaned SQL (single cell)\n",
    "from IPython.display import display, HTML\n",
    "import pandas as pd\n",
    "import html\n",
    "\n",
    "from nl2sql.core.prompting import make_few_shot_messages\n",
    "from nl2sql.agent.constraint_policy import build_constraints\n",
    "from nl2sql.core.llm import debug_extract_first_select\n",
    "from nl2sql.core.postprocess import debug_guarded_postprocess\n",
    "\n",
    "\n",
    "# Small helper to print section headers in the notebook output.\n",
    "def show_title(text):\n",
    "    display(HTML(f\"<h3 style='margin:12px 0 6px 0'>{html.escape(text)}</h3>\"))\n",
    "\n",
    "\n",
    "# Small helper to render SQL/text in a boxed monospace block.\n",
    "def show_pre(text, label=None):\n",
    "    label_html = f\"<div style='font-weight:600;margin-bottom:6px'>{html.escape(label)}</div>\" if label else \"\"\n",
    "    display(HTML(\n",
    "        \"<div style='border:1px solid #ddd;border-radius:8px;padding:10px 12px;margin:8px 0'>\"\n",
    "        f\"{label_html}\"\n",
    "        f\"<pre style='white-space:pre-wrap;margin:0;font-family:ui-monospace, SFMono-Regular, Menlo, Consolas, monospace'>{html.escape(str(text))}</pre>\"\n",
    "        \"</div>\"\n",
    "    ))\n",
    "\n",
    "\n",
    "# Convert postprocess steps into a small readable table.\n",
    "def steps_df(pp):\n",
    "    return pd.DataFrame([\n",
    "        {\n",
    "            \"changed\": \"yes\" if s[\"changed\"] else \"no\",\n",
    "            \"stage\": s[\"stage\"],\n",
    "            \"note\": s.get(\"note\", \"\"),\n",
    "        }\n",
    "        for s in pp[\"steps\"]\n",
    "    ])\n",
    "\n",
    "\n",
    "# Demo NLQs: one implicit question and one explicit field-list question.\n",
    "DEMO_NLQ_IMPLICIT = \"List all customer names in France\"\n",
    "DEMO_NLQ_EXPLICIT = \"List contact last name, customer name, and customer number for customers in France\"\n",
    "\n",
    "# Use real schema text if available; otherwise use a minimal fallback.\n",
    "schema_text = (\n",
    "    SCHEMA_SUMMARY\n",
    "    if \"SCHEMA_SUMMARY\" in globals() and isinstance(SCHEMA_SUMMARY, str) and SCHEMA_SUMMARY.strip()\n",
    "    else \"Table customers (customerNumber INT, customerName TEXT, contactLastName TEXT, country TEXT, creditLimit REAL)\"\n",
    ")\n",
    "\n",
    "# Pull a couple of real exemplars when the benchmark is loaded.\n",
    "exemplars = []\n",
    "if \"test_set\" in globals() and isinstance(test_set, list):\n",
    "    exemplars = [x for x in test_set[:2] if isinstance(x, dict) and \"nlq\" in x and \"sql\" in x]\n",
    "\n",
    "# Build the same style of messages used by the real pipeline.\n",
    "messages = make_few_shot_messages(schema=schema_text, exemplars=exemplars, nlq=DEMO_NLQ_IMPLICIT)\n",
    "constraints_implicit = build_constraints(DEMO_NLQ_IMPLICIT, schema_text)\n",
    "\n",
    "# Step 1: show the NLQ and the prompt context.\n",
    "show_title(\"Step 1 - NLQ and prompt context\")\n",
    "display(pd.DataFrame([\n",
    "    {\n",
    "        \"nlq\": DEMO_NLQ_IMPLICIT,\n",
    "        \"schema_lines\": len(schema_text.splitlines()),\n",
    "        \"exemplars_used\": len(exemplars),\n",
    "        \"message_count\": len(messages),\n",
    "        \"explicit_fields\": constraints_implicit.get(\"explicit_fields\"),\n",
    "    }\n",
    "]))\n",
    "\n",
    "display(pd.DataFrame([\n",
    "    {\n",
    "        \"role\": m.get(\"role\"),\n",
    "        \"content_preview\": str(m.get(\"content\", \"\")).replace(\"\\n\", \" \")[:140],\n",
    "    }\n",
    "    for m in messages[:6]\n",
    "]))\n",
    "\n",
    "# Step 2: simulate a noisy/faulty model output (on purpose).\n",
    "FAULTY_TEXT = \"\"\"Model draft + noise:\n",
    "select from the options above\n",
    "\n",
    "SQL:\n",
    "SELECT c.customerNumber, c.customerName, c.contactLastName, c.creditLimit\n",
    "FROM customers c\n",
    "WHERE c.country = 'France'\n",
    "ORDER BY c.customerName DESC\n",
    "LIMIT 5;\n",
    "\n",
    "Extra explanation after SQL.\n",
    "\"\"\"\n",
    "\n",
    "show_title(\"Step 2 - Simulated faulty SQL draft\")\n",
    "show_pre(FAULTY_TEXT, \"Faulty model output (simulated)\")\n",
    "\n",
    "# Step 3: run extraction logic to pick the best SQL candidate.\n",
    "show_title(\"Step 3 - Extraction debug\")\n",
    "extract_debug = debug_extract_first_select(FAULTY_TEXT)\n",
    "selected_sql = extract_debug.get(\"selected_sql\") or FAULTY_TEXT\n",
    "\n",
    "display(pd.DataFrame([\n",
    "    {\n",
    "        \"candidate\": i,\n",
    "        \"accepted\": c.get(\"accepted\"),\n",
    "        \"reject_reason\": c.get(\"reject_reason\"),\n",
    "        \"from_target\": c.get(\"from_target\"),\n",
    "        \"candidate_sql\": c.get(\"candidate_sql\"),\n",
    "    }\n",
    "    for i, c in enumerate(extract_debug.get(\"candidates\", []), start=1)\n",
    "]))\n",
    "show_pre(selected_sql, \"Selected SQL candidate\")\n",
    "\n",
    "# Step 4A: clean SQL for implicit-field question behavior.\n",
    "show_title(\"Step 4A - Cleaning trace (implicit fields)\")\n",
    "pp_a = debug_guarded_postprocess(\n",
    "    selected_sql,\n",
    "    DEMO_NLQ_IMPLICIT,\n",
    "    explicit_fields=constraints_implicit.get(\"explicit_fields\") if constraints_implicit.get(\"explicit_projection\") else None,\n",
    "    required_fields=constraints_implicit.get(\"required_output_fields\"),\n",
    ")\n",
    "display(steps_df(pp_a))\n",
    "show_pre(pp_a[\"final_sql\"], \"Final cleaned SQL (implicit)\")\n",
    "\n",
    "# Step 4B: clean SQL for explicit-field question behavior.\n",
    "show_title(\"Step 4B - Cleaning trace (explicit fields)\")\n",
    "pp_b = debug_guarded_postprocess(\n",
    "    selected_sql,\n",
    "    DEMO_NLQ_EXPLICIT,\n",
    "    explicit_fields=[\"contactLastName\", \"customerName\", \"customerNumber\"],\n",
    ")\n",
    "display(steps_df(pp_b))\n",
    "show_pre(pp_b[\"final_sql\"], \"Final cleaned SQL (explicit)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute selected sweep.\n",
    "baseline_grid, baseline_by_k, baseline_run_dir = run_baseline_grid(\n",
    "    k_values=K_VALUES,\n",
    "    seeds=SEEDS,\n",
    "    run_tag=RUN_TAG,\n",
    "    prompt_variant=PROMPT_VARIANT,\n",
    "    schema_variant=SCHEMA_VARIANT,\n",
    "    exemplar_strategy=EXEMPLAR_STRATEGY,\n",
    "    limit=None,\n",
    "    copy_canonical=COPY_CANONICAL,\n",
    "    copy_model_family=COPY_MODEL_FAMILY,\n",
    "    model_alias=MODEL_ALIAS,\n",
    "    enable_ts_for_k=set(TS_FOR_K_VALUES) if ENABLE_TS else None,\n",
    "    ts_n=TS_N,\n",
    "    ts_prefix=TS_PREFIX,\n",
    "    ts_max_rows=TS_MAX_ROWS,\n",
    ")\n",
    "\n",
    "print(\"\\nPer-run rows:\")\n",
    "display(baseline_grid)\n",
    "print(\"\\nPer-k summary (mean/std across seeds):\")\n",
    "display(baseline_by_k)\n",
    "\n",
    "# Persist artifacts so they survive Colab runtime disconnects.\n",
    "if PERSIST_TO_DRIVE:\n",
    "    try:\n",
    "        backup_dir = persist_run_to_drive(\n",
    "            run_dir=baseline_run_dir,\n",
    "            model_alias=MODEL_ALIAS,\n",
    "            k_values=K_VALUES,\n",
    "            run_tag=RUN_TAG,\n",
    "            persist_root=DRIVE_PERSIST_ROOT,\n",
    "        )\n",
    "        print(\"Persistent backup saved to:\", backup_dir)\n",
    "    except Exception as e:\n",
    "        print(\"Drive backup skipped/failed:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e435ec69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Quick canonical summary (reads saved k=0 and k=3 JSON outputs)\n",
    "import json\n",
    "\n",
    "zero = json.loads(open(\"results/baseline/results_zero_shot_200.json\", \"r\", encoding=\"utf-8\").read())\n",
    "few  = json.loads(open(\"results/baseline/results_few_shot_k3_200.json\", \"r\", encoding=\"utf-8\").read())\n",
    "\n",
    "print(\"Zero-shot:\", \"VA\", round(zero[\"va_rate\"], 3), \"EM\", round(zero.get(\"em_rate\", 0.0), 3), \"EX\", round(zero[\"ex_rate\"], 3))\n",
    "print(\"Few-shot:\",  \"VA\", round(few[\"va_rate\"], 3),  \"EM\", round(few.get(\"em_rate\", 0.0), 3),  \"EX\", round(few[\"ex_rate\"], 3))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}