# Configuration & Reproducibility

## At‑a‑Glance
This file defines the **minimum configuration** to reproduce baseline, QLoRA, and execution‑guided runs on Colab‑class GPUs. It standardises:
- project layout
- environment variables / secrets
- dependency pinning
- model + adapter configuration
- evaluation/agent knobs

---

## Project Structure (Why it’s split)
- `nl2sql/` — stable, importable experiment harness
- `notebooks/` — thin Colab runners
- `data/` — benchmarks
- `results/` — outputs (gitignored by default)

This separation keeps evaluation logic version‑controlled and notebooks reproducible.

---

## Quickstart — Baseline Prompting (Colab)
1) **Runtime:** GPU (T4/A100)
2) **Clone + install:**
   - `git clone https://github.com/MacKenzieOBrian/NLtoSQL.git /content/NLtoSQL`
   - `%cd /content/NLtoSQL`
   - `pip install -r requirements.txt`
   - restart runtime once
3) **Auth & env:**
   - GCP: `google.colab.auth.authenticate_user()` or ADC locally
   - HF: set `HF_TOKEN` (or `notebook_login()`)
   - set DB env vars (`INSTANCE_CONNECTION_NAME`, `DB_USER`, `DB_PASS`, `DB_NAME`)
4) **Run baseline:** `notebooks/02_baseline_prompting_eval.ipynb`
5) **Outputs:** saved to `results/baseline/`

---

## Quickstart — QLoRA Adapters
1) **Prepare training set**
   - Start from `data/train/classicmodels_train_200.jsonl`
   - Validate SELECT‑only, no leakage, executable SQL (VA=True)
2) **Train + eval**
   - `notebooks/05_qlora_train_eval.ipynb`
   - Adapters saved to `results/adapters/qlora_classicmodels/`
   - Metrics saved to `results/qlora/`
3) **Modes**
   - `k=0` = adapter only
   - `k=3` = adapter + exemplars

---

## Core Configuration Keys
| Variable | Purpose | Example |
|---|---|---|
| `INSTANCE_CONNECTION_NAME` | Cloud SQL instance | `modified-enigma-476414-h9:europe-west2:classicmodels` |
| `DB_USER` | MySQL username | `root` |
| `DB_PASS` | MySQL password | (prompt‑only; never commit) |
| `DB_NAME` | Database name | `classicmodels` |
| `HF_TOKEN` | Hugging Face token | `hf_…` |
| `ADAPTER_PATH` | QLoRA adapter folder | `results/adapters/qlora_classicmodels` |

Notes:
- If `ADAPTER_PATH` is missing, code falls back to the base model.
- `HF_TOKEN` is required for gated Llama‑3; never commit it.

---

## Dependencies (Pinned)
All core packages are pinned in `requirements.txt` to avoid Colab drift.

- **LLM stack:** `torch`, `transformers`, `accelerate`, `bitsandbytes`, `triton`, `peft`, `trl`, `datasets`
- **DB stack:** `google-cloud-sql-connector`, `sqlalchemy`, `pymysql`
- **Config/utilities:** `huggingface_hub`, `pydantic`, `python-dotenv`, `numpy`, `pandas`

Colab note: run the notebook’s setup cell (uninstall → install pinned versions) then restart once.

---

## QLoRA Adapter Configuration
- **Location:** `results/adapters/qlora_classicmodels/`
- **Base model:** `meta-llama/Meta-Llama-3-8B-Instruct`
- **LoRA config:** `r=32`, `α=64`, dropout `0.05`, targets `q_proj`, `v_proj`
- **Usage:** set `ADAPTER_PATH` (defaults to location above)

---

## NL→SQL Guardrails (Config Summary)
Always active during evaluation:
- **Projection / ORDER constraints:** remove ORDER/LIMIT unless NLQ implies ranking; trim projections on list‑style NLQs.
- **Schema‑aware routing:** country/creditLimit → `customers`; productLine/vendor → `products` + `orderdetails`.
- **Totals:** use `SUM(orderdetails.quantityOrdered * priceEach)`.
- **Status literals:** `Shipped`, `Cancelled`, `On Hold`, `Disputed`, `In Process`, `Resolved`.

Implementation:
- Prompt rules: `nl2sql/prompting.py`
- Post‑generation guards: `nl2sql/postprocess.py`
- Eval harness: `nl2sql/eval.py`, `scripts/run_full_pipeline.py`

---

## Agentic (Execution‑Guided) Configuration
**Core behaviour**
- execution‑guided reranker over multiple candidates
- strict SELECT‑only filtering
- optional repair using DB error hints
- semantic reranking with projection penalty

**Where it lives**
- helpers: `nl2sql/agent_utils.py`
- notebook: `notebooks/03_agentic_eval.ipynb`
- script: `scripts/run_full_pipeline.py`

**Usage**
- set `MODE=react` or use the notebook toggles
- tune `num_cands` and `max_steps` as needed

**Scope**
ReAct‑inspired, not a full Thought/Action/Observation grammar. Observations are used for repair + reranking; explicit tool traces are future work.
