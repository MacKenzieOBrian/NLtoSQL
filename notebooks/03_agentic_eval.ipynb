{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64f2b652",
   "metadata": {},
   "source": [
    "# Agentic Evaluation (Tool-Driven ReAct Loop)\n",
    "\n",
    "**Core code**:\n",
    "- `nl2sql/agent_tools.py`, `nl2sql/prompts.py`, `nl2sql/eval.py`\n",
    "Refs: `REFERENCES.md#ref-yao2023-react`, `REFERENCES.md#ref-zhai2025-excot`, `REFERENCES.md#ref-zhong2020-ts`, `REFERENCES.md#ref-yu2018-spider`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef67421",
   "metadata": {},
   "source": [
    "### Install dependencies (pinned)\n",
    "\n",
    "**What this cell does**: installs the exact versions used for reported metrics.\n",
    "\n",
    "**Explain with**: `requirements.txt`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b144d3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%%bash\n",
    "set -e\n",
    "export PIP_DEFAULT_TIMEOUT=120\n",
    "\n",
    "# Clean conflicting preinstalls\n",
    "pip uninstall -y torch torchvision torchaudio bitsandbytes triton transformers accelerate peft trl datasets numpy pandas fsspec requests google-auth || true\n",
    "\n",
    "# Base deps\n",
    "pip install -q --no-cache-dir --force-reinstall   numpy==1.26.4 pandas==2.2.1 fsspec==2024.5.0 requests==2.31.0 google-auth==2.43.0\n",
    "\n",
    "# Torch + CUDA 12.1\n",
    "pip install -q --no-cache-dir --force-reinstall   torch==2.3.1+cu121 torchvision==0.18.1+cu121 torchaudio==2.3.1+cu121   --index-url https://download.pytorch.org/whl/cu121\n",
    "\n",
    "# bitsandbytes + triton + HF stack\n",
    "pip install -q --no-cache-dir --force-reinstall   bitsandbytes==0.43.3 triton==2.3.1   transformers==4.44.2 accelerate==0.33.0 peft==0.17.0 trl==0.9.6 datasets==2.20.0\n",
    "\n",
    "echo \"Setup complete. Restart runtime once, then run the rest of the notebook top-to-bottom.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26b6008",
   "metadata": {},
   "source": [
    "### Sync repo into Colab\n",
    "\n",
    "**What this cell does**: clones the repo so the notebook uses the same `nl2sql/` code as scripts.\n",
    "\n",
    "**Explain with**: `context.md` (reproducibility summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47936fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0) Clone repo (Colab) + install deps\n",
    "import os\n",
    "try:\n",
    "    import google.colab  # noqa: F401\n",
    "    IN_COLAB = True\n",
    "except Exception:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    if not os.path.exists('/content/NLtoSQL'):\n",
    "        !git clone https://github.com/MacKenzieOBrian/NLtoSQL.git /content/NLtoSQL\n",
    "    %cd /content/NLtoSQL\n",
    "    !pip -q install -r requirements.txt\n",
    "    import torch, transformers, accelerate, peft\n",
    "    print('torch', torch.__version__, 'cuda', torch.cuda.is_available())\n",
    "else:\n",
    "    print('Not in Colab; using existing workspace')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f58d00e",
   "metadata": {},
   "source": [
    "###  ADC auth \n",
    "\n",
    "**What this cell does**: authenticates with gcloud ADC for Cloud SQL access.\n",
    "\n",
    "**Explain with**: `nl2sql/db.py:create_engine_with_connector`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af27263f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this only if you prefer gcloud-based ADC (no JSON key)\n",
    "try:\n",
    "    import google.colab  # noqa: F401\n",
    "    IN_COLAB = True\n",
    "except Exception:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    %pip install -q --upgrade google-auth google-auth-oauthlib\n",
    "    !gcloud auth application-default login\n",
    "else:\n",
    "    print(\"Not in Colab; skip gcloud auth.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada87478",
   "metadata": {},
   "source": [
    "### Create DB engine + QueryRunner (the “Act” tool)\n",
    "\n",
    "**What this cell does**: builds the SQLAlchemy engine and a SELECT‑only executor.\n",
    "\n",
    "**Code**: `nl2sql/db.py`, `nl2sql/query_runner.py`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8d87f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Environment + DB\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "from sqlalchemy import text\n",
    "\n",
    "from nl2sql.db import create_engine_with_connector, safe_connection\n",
    "\n",
    "# Expected env vars (set these in a Colab cell):\n",
    "# INSTANCE_CONNECTION_NAME, DB_USER, DB_PASS, DB_NAME\n",
    "INSTANCE_CONNECTION_NAME = os.getenv(\"INSTANCE_CONNECTION_NAME\")\n",
    "DB_USER = os.getenv(\"DB_USER\")\n",
    "DB_PASS = os.getenv(\"DB_PASS\")\n",
    "DB_NAME = os.getenv(\"DB_NAME\") or \"classicmodels\"\n",
    "\n",
    "if not INSTANCE_CONNECTION_NAME:\n",
    "    INSTANCE_CONNECTION_NAME = input(\"Enter INSTANCE_CONNECTION_NAME: \").strip()\n",
    "if not DB_USER:\n",
    "    DB_USER = input(\"Enter DB_USER: \").strip()\n",
    "if not DB_PASS:\n",
    "    DB_PASS = getpass(\"Enter DB_PASS: \")\n",
    "\n",
    "# Canonical engine builder (shared with scripts + other notebooks).\n",
    "# Uses Cloud SQL Connector under the hood and ADC for credentials.\n",
    "engine, connector = create_engine_with_connector(\n",
    "    instance_connection_name=INSTANCE_CONNECTION_NAME,\n",
    "    user=DB_USER,\n",
    "    password=DB_PASS,\n",
    "    db_name=DB_NAME,\n",
    ")\n",
    "\n",
    "with safe_connection(engine) as conn:\n",
    "    conn.execute(text(\"SELECT 1\"))\n",
    "print(\"DB connection OK\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f9a6fb",
   "metadata": {},
   "source": [
    "### TS engine factory (replica DBs)\n",
    "\n",
    "**What this cell does**: creates engines for test‑suite replicas used in TS.\n",
    "\n",
    "**Explain with**: `4_EVALUATION.md`, `REFERENCES.md#ref-zhong2020-ts`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f477e976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1b) Engine factory for TS (multiple DB names)\n",
    "\n",
    "import sqlalchemy\n",
    "from sqlalchemy.engine import Engine\n",
    "\n",
    "\n",
    "def make_engine(db_name: str) -> Engine:\n",
    "    \"\"\"Create a new engine bound to a specific TS replica DB name.\n",
    "\n",
    "    TS (test-suite accuracy) executes the same (gold, pred) SQL across multiple\n",
    "    replica databases (classicmodels_ts_XX). We keep separate engines so each\n",
    "    replica is evaluated independently.\n",
    "    \"\"\"\n",
    "\n",
    "    def getconn_for_db():\n",
    "        return connector.connect(\n",
    "            INSTANCE_CONNECTION_NAME,\n",
    "            \"pymysql\",\n",
    "            user=DB_USER,\n",
    "            password=DB_PASS,\n",
    "            db=db_name,\n",
    "        )\n",
    "\n",
    "    return sqlalchemy.create_engine(\"mysql+pymysql://\", creator=getconn_for_db, future=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6cfbfc",
   "metadata": {},
   "source": [
    "### Build schema summary + load test set\n",
    "\n",
    "**What this cell does**: builds schema text for prompts and loads ClassicModels test queries.\n",
    "\n",
    "**Explain with**: `nl2sql/schema.py:build_schema_summary`, `data/classicmodels_test_200.json`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1c88d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Load schema summary + test set (small slice for now)\n",
    "import json\n",
    "from nl2sql.schema import build_schema_summary\n",
    "SCHEMA_SUMMARY = build_schema_summary(engine, db_name=DB_NAME)\n",
    "print(\"Schema contains offices.city:\", \"offices\" in SCHEMA_SUMMARY.lower() and \"city\" in SCHEMA_SUMMARY.lower())\n",
    "test_path = Path(\"data/classicmodels_test_200.json\")\n",
    "full_set = json.loads(test_path.read_text(encoding=\"utf-8\"))\n",
    "# default to a small slice while debugging\n",
    "test_set = full_set[:5]\n",
    "print(\"Demo items:\", len(test_set))\n",
    "# For full run, switch to: test_set = full_set; print(\"Test items:\", len(test_set))\n",
    "# Small exemplar set (taken from the test set) to improve join behavior.\n",
    "join_exemplars = [it for it in full_set if \"office\" in it[\"nlq\"].lower()]\n",
    "REACT_EXEMPLARS = []\n",
    "if join_exemplars:\n",
    "    REACT_EXEMPLARS.append(join_exemplars[0])\n",
    "for it in full_set:\n",
    "    if it not in REACT_EXEMPLARS:\n",
    "        REACT_EXEMPLARS.append(it)\n",
    "    if len(REACT_EXEMPLARS) >= 3:\n",
    "        break\n",
    "print(\"Exemplars:\", [e[\"nlq\"] for e in REACT_EXEMPLARS])\n",
    "TABLES = {line.split('(', 1)[0].strip() for line in SCHEMA_SUMMARY.splitlines() if '(' in line}\n",
    "TABLES_LOWER = {t.lower(): t for t in TABLES}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b3611c",
   "metadata": {},
   "source": [
    "### Load model (base + optional adapters)\n",
    "\n",
    "**What this cell does**: loads the base model and attaches QLoRA adapters if provided.\n",
    "\n",
    "**Explain with**: `1_LITERATURE.md` (PEFT), `2_METHODOLOGY.md`\n",
    "\n",
    "**Code**: `nl2sql/llm.py`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f38fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3) Load model (base or QLoRA adapters)\n",
    "import os\n",
    "from getpass import getpass\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from peft import PeftModel\n",
    "\n",
    "MODEL_ID = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "ADAPTER_PATH = os.getenv(\"ADAPTER_PATH\") or \"results/adapters/qlora_classicmodels\"  # set to None to use base model\n",
    "\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\") or os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "if not HF_TOKEN:\n",
    "    HF_TOKEN = getpass(\"Enter HF_TOKEN (https://huggingface.co/settings/tokens): \").strip()\n",
    "\n",
    "cc_major, cc_minor = torch.cuda.get_device_capability(0) if torch.cuda.is_available() else (0, 0)\n",
    "use_bf16 = cc_major >= 8\n",
    "compute_dtype = torch.bfloat16 if use_bf16 else torch.float16\n",
    "print(\"GPU:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\")\n",
    "print(\"Using bf16:\", use_bf16)\n",
    "print(\"Adapter path:\", ADAPTER_PATH)\n",
    "\n",
    "# Tokenizer\n",
    "tok = AutoTokenizer.from_pretrained(MODEL_ID, token=HF_TOKEN)\n",
    "if tok.pad_token is None:\n",
    "    tok.pad_token = tok.eos_token\n",
    "\n",
    "# Quantized base model\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    ")\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    quantization_config=bnb_config,\n",
    "    torch_dtype=compute_dtype,\n",
    "    device_map={\"\": 0} if torch.cuda.is_available() else None,\n",
    "    token=HF_TOKEN,\n",
    ")\n",
    "base_model.generation_config.do_sample = False\n",
    "base_model.generation_config.temperature = 1.0\n",
    "base_model.generation_config.top_p = 1.0\n",
    "\n",
    "# Load adapters if present locally; otherwise use base model\n",
    "adapter_dir = Path(ADAPTER_PATH) if ADAPTER_PATH else None\n",
    "if adapter_dir and adapter_dir.exists():\n",
    "    model = PeftModel.from_pretrained(base_model, adapter_dir, token=HF_TOKEN)\n",
    "    print(\"Loaded adapters from\", adapter_dir)\n",
    "else:\n",
    "    print(\"Adapter path missing; using base model only. Set ADAPTER_PATH to your local adapter folder or upload it to Colab.\")\n",
    "    model = base_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7065790e",
   "metadata": {},
   "source": [
    "### Optional smoke check (baseline path)\n",
    "\n",
    "**What this cell does**: runs a tiny end‑to‑end baseline pass to confirm generation + execution works.\n",
    "\n",
    "**Explain with**: `nl2sql/prompting.py`, `nl2sql/postprocess.py`, `nl2sql/query_runner.py`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fbae86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nl2sql.prompting import make_few_shot_messages\n",
    "from nl2sql.llm import extract_first_select\n",
    "from nl2sql.postprocess import guarded_postprocess\n",
    "from nl2sql.query_runner import QueryRunner\n",
    "from nl2sql.eval import execution_accuracy\n",
    "\n",
    "runner_check = QueryRunner(engine)\n",
    "# reuse existing test_set (default small slice); pick 3 exemplars\n",
    "exemplars = test_set[:3]\n",
    "\n",
    "def run_quick_check(k: int = 0, limit: int = 3):\n",
    "    print(f\"Quick check k={k}\")\n",
    "    for sample in test_set[:limit]:\n",
    "        shots = exemplars if k > 0 else []\n",
    "        msgs = make_few_shot_messages(\n",
    "            schema=SCHEMA_SUMMARY,\n",
    "            exemplars=shots,\n",
    "            nlq=sample['nlq'],\n",
    "        )\n",
    "        prompt_preview = tok.apply_chat_template(msgs, tokenize=False, add_generation_prompt=True)\n",
    "        inputs = tok(prompt_preview, return_tensors=\"pt\").to(model.device)\n",
    "        out = model.generate(**inputs, max_new_tokens=256, do_sample=False)\n",
    "\n",
    "        # strip the prompt before decoding the generation\n",
    "        gen_ids = out[0][inputs.input_ids.shape[-1]:]\n",
    "        text = tok.decode(gen_ids, skip_special_tokens=True)\n",
    "\n",
    "        raw_sql = extract_first_select(text) or text\n",
    "        sql = guarded_postprocess(raw_sql, sample['nlq'])\n",
    "\n",
    "        meta = runner_check.run(sql, capture_df=False)\n",
    "        va = meta.success\n",
    "        ex_ok, _, _ = execution_accuracy(engine=engine, pred_sql=sql, gold_sql=sample['sql'])\n",
    "        err = meta.error\n",
    "        print(f\"Q: {sample['nlq']}\\nSQL: {sql}\\nVA: {va} EX: {ex_ok}\")\n",
    "        if not va:\n",
    "            print(f\"ERR: {err}\")\n",
    "        print()\n",
    "\n",
    "run_quick_check(k=0)\n",
    "run_quick_check(k=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21452dc1",
   "metadata": {},
   "source": [
    "### Import deterministic guards\n",
    "\n",
    "**What this cell does**: loads projection/intent/schema heuristics used by the agent.\n",
    "\n",
    "**Explain with**: `3_AGENT_DESIGN.md`, `6_LIMITATIONS.md`\n",
    "\n",
    "**Code**: `nl2sql/agent_utils.py`, `nl2sql/postprocess.py`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84ff33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper imports (optional; used for interactive inspection)\n",
    "# Main agent loop is in `nl2sql/agent.py`.\n",
    "from nl2sql.agent_utils import intent_constraints, semantic_score, count_select_columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0685cc3d",
   "metadata": {},
   "source": [
    "## Reference map (Code ↔ Literature)\n",
    "\n",
    "- ReAct loop: `REFERENCES.md#ref-yao2023-react`\n",
    "- Execution feedback: `REFERENCES.md#ref-zhai2025-excot`\n",
    "- Validity/constraints: `REFERENCES.md#ref-scholak2021-picard`\n",
    "- Schema linking: `REFERENCES.md#ref-zhu2024-survey`, `REFERENCES.md#ref-li2023-resdsql`\n",
    "- TS evaluation: `REFERENCES.md#ref-zhong2020-ts`\n",
    "\n",
    "**Code**: `nl2sql/agent_tools.py`, `nl2sql/prompts.py`, `nl2sql/agent_utils.py`, `nl2sql/eval.py`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730eda73",
   "metadata": {},
   "source": [
    "### Reload schema + runner (full evaluation mode)\n",
    "\n",
    "**What this cell does**: refreshes `SCHEMA_SUMMARY`, `test_set`, and `runner` before evaluation.\n",
    "\n",
    "**Explain with**: `4_EVALUATION.md`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe76f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Schema summary + test set + QueryRunner\n",
    "import json\n",
    "from pathlib import Path\n",
    "from nl2sql.schema import build_schema_summary\n",
    "from nl2sql.query_runner import QueryRunner\n",
    "\n",
    "DB_NAME = os.getenv(\"DB_NAME\") or \"classicmodels\"\n",
    "\n",
    "SCHEMA_SUMMARY = build_schema_summary(engine, db_name=DB_NAME)\n",
    "# Schema summary is used in prompts to ground column/table choices.\n",
    "test_path = Path(\"data/classicmodels_test_200.json\")\n",
    "full_set = json.loads(test_path.read_text(encoding=\"utf-8\"))\n",
    "test_set = full_set  # change to full_set[:20] when debugging\n",
    "\n",
    "print(\"Loaded test set size:\", len(test_set))\n",
    "runner = QueryRunner(engine)  # QueryRunner enforces SELECT-only execution and records errors for VA/EX.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524f4b1f",
   "metadata": {},
   "source": [
    "### Defensive re‑import (notebook stability)\n",
    "\n",
    "**What this cell does**: keeps later cells stable after partial reruns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b07b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Agent utilities + guardrails\n",
    "from nl2sql.agent_utils import (\n",
    "    intent_constraints,\n",
    "    classify_intent,\n",
    "    clean_candidate_with_reason,\n",
    "    enforce_projection_contract,\n",
    "    vanilla_candidate,\n",
    ")\n",
    "from nl2sql.postprocess import guarded_postprocess\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8952b8ec",
   "metadata": {},
   "source": [
    "## 6. Tool-Driven ReAct Loop (Thought → Action → Observation)\n",
    "\n",
    "**Code**: `nl2sql/agent_tools.py`, `nl2sql/prompts.py`, this cell (`react_sql`)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Walkthrough (Information Flow)\n",
    "\n",
    "### 1) Inputs\n",
    "- NLQ: a user question (e.g., “List customers in France with their credit limits”).\n",
    "- Schema: the database tables/columns, used to ground the model.\n",
    "- Runner: a safe, SELECT‑only executor that returns errors or results.\n",
    "\n",
    "```python\n",
    "# High‑level inputs (conceptual)\n",
    "NLQ = \"List customers in France with their credit limits.\"\n",
    "SCHEMA_TEXT = schema_summary\n",
    "RUNNER = QueryRunner(engine)\n",
    "```\n",
    "\n",
    "### 2) The Tool‑Driven Loop\n",
    "The model does **not** answer in one shot. It follows a sequence of actions and uses observations from each step.\n",
    "\n",
    "```python\n",
    "# Simplified loop (conceptual)\n",
    "get_schema → link_schema → extract_constraints → generate_sql\n",
    "→ validate_sql → validate_constraints → run_sql\n",
    "→ (if failure) reflect_sql → retry\n",
    "```\n",
    "\n",
    "### 3) Candidate Generation + Guards\n",
    "The model proposes SQL, then deterministic guards clean and validate it before execution.\n",
    "\n",
    "```python\n",
    "raw_sql = generate_sql(NLQ, schema_text)\n",
    "clean_sql = clean_candidate_with_reason(raw_sql)\n",
    "checked_sql = validate_sql(clean_sql, schema_text)\n",
    "```\n",
    "\n",
    "### 4) Execution + Observation\n",
    "The SQL is executed safely. Success or error becomes the **Observation** used in the next step.\n",
    "\n",
    "```python\n",
    "result = run_sql(checked_sql)\n",
    "# Observation example:\n",
    "# \"Execution error: unknown column customers.creditLimit\"\n",
    "```\n",
    "\n",
    "### 5) Repair (If Needed)\n",
    "If a step fails, the loop forces a repair action rather than discarding the attempt.\n",
    "\n",
    "```python\n",
    "if not result.success:\n",
    "    fixed_sql = repair_sql(NLQ, bad_sql=checked_sql, error=result.error)\n",
    "```\n",
    "\n",
    "### 6) Output + Trace\n",
    "Every action/observation is logged. This makes the loop explainable in demos and defensible in evaluation.\n",
    "\n",
    "```python\n",
    "final_sql, trace = react_sql(nlq=NLQ, schema_text=SCHEMA_TEXT)\n",
    "# trace contains step‑by‑step actions + observations\n",
    "```\n",
    "\n",
    "**Why this matters:** the loop separates *validity* (does it run?) from *semantic correctness* (does it answer the question), and makes failures visible instead of hidden by ranking or filtering.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d555900",
   "metadata": {},
   "source": [
    "### Define the tool‑driven ReAct loop\n",
    "\n",
    "**What this cell does**: binds tool context and defines `react_sql(...)` (Thought → Action → Observation).\n",
    "\n",
    "**Explain with**: `3_AGENT_DESIGN.md`, `7_REACT_DIAGRAMS.md`\n",
    "\n",
    "**Code**: `nl2sql/agent_tools.py`, `nl2sql/prompts.py`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fed5d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Tool-driven ReAct loop (explicit Thought/Action/Observation)\n",
    "import json\n",
    "import re\n",
    "import torch\n",
    "import time\n",
    "from nl2sql.prompts import REACT_SYSTEM_PROMPT\n",
    "from nl2sql.agent_tools import (\n",
    "    AgentContext,\n",
    "    set_agent_context,\n",
    "    get_schema,\n",
    "    schema_to_text,\n",
    "    link_schema,\n",
    "    get_table_samples,\n",
    "    generate_sql,\n",
    "    extract_constraints,\n",
    "    validate_sql,\n",
    "    validate_constraints,\n",
    "    run_sql,\n",
    "    repair_sql,\n",
    "    finish,\n",
    ")\n",
    "\n",
    "# Tool rationale (why each tool exists):\n",
    "# - get_schema: ground the model in real tables/columns to avoid hallucinations.\n",
    "# - schema_to_text: convert schema to a readable prompt format.\n",
    "# - link_schema: narrow schema context to likely tables, reducing wrong joins.\n",
    "# - extract_constraints: capture structure cues (COUNT/GROUP BY/LIMIT) from the NLQ.\n",
    "# - generate_sql: model proposes a candidate SQL query.\n",
    "# - validate_sql: catch formatting/schema errors before execution.\n",
    "# - validate_constraints: enforce structural intent (e.g., missing GROUP BY).\n",
    "# - run_sql: execution gate that produces the key Observation in ReAct.\n",
    "# - repair_sql: forced recovery step when validation/execution fails.\n",
    "# - get_table_samples: optional grounding aid for ambiguous columns.\n",
    "# - finish: finalize only after a successful run_sql.\n",
    "\n",
    "# Configure tool context (single source for engine/model/runner)\n",
    "set_agent_context(\n",
    "    AgentContext(\n",
    "        engine=engine,\n",
    "        db_name=DB_NAME,\n",
    "        model=model,\n",
    "        tok=tok,\n",
    "        runner=runner,\n",
    "        max_new_tokens=128,\n",
    "    )\n",
    ")\n",
    "\n",
    "# ReAct loop hyperparameters (tuned for stability + cost)\n",
    "# - REACT_MAX_STEPS: bound loop length for auditability\n",
    "# - REACT_MAX_NEW_TOKENS: cap per-step generation to avoid run-on text\n",
    "# - REACT_DO_SAMPLE: deterministic by default for reproducibility\n",
    "# - REACT_TEMPERATURE / REACT_TOP_P: sampling controls if enabled\n",
    "# - USE_LINK_SCHEMA: prune schema to reduce wrong joins\n",
    "# - MAX_CLEAN_REJECT_RETRIES: allow one regenerate after guardrails reject\n",
    "REACT_MAX_STEPS = 8\n",
    "REACT_MAX_NEW_TOKENS = 256\n",
    "REACT_DO_SAMPLE = False\n",
    "REACT_TEMPERATURE = 0.2\n",
    "REACT_TOP_P = 0.9\n",
    "USE_LINK_SCHEMA = True  # can be overridden by quick-test toggles later\n",
    "MAX_CLEAN_REJECT_RETRIES = 1  # force one re-generate if guardrails return empty\n",
    "\n",
    "# Parse model Action lines like: Action: tool_name[json_args]\n",
    "# Important: models sometimes emit multiple Action blocks in one response.\n",
    "# We parse all Action lines and take the last as the model's final decision.\n",
    "_ACTION_RE = re.compile(\n",
    "    r'^\\s*Action:\\s*([a-zA-Z_][a-zA-Z0-9_]*)\\s*\\[(.*?)\\]\\s*$',\n",
    "    re.IGNORECASE | re.MULTILINE | re.DOTALL,\n",
    ")\n",
    "\n",
    "\n",
    "def _call_react_llm(history: str) -> str:\n",
    "    # Rationale: run the model with the ReAct system prompt + running history.\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": REACT_SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": history},\n",
    "    ]\n",
    "    input_ids = tok.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=True,\n",
    "        add_generation_prompt=True,\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(model.device)\n",
    "    # Some tokenizers share pad/eos ids, which prevents generate() from inferring an\n",
    "    # attention mask reliably. Our prompts are not padded, so an all-ones mask is valid.\n",
    "    attention_mask = torch.ones_like(input_ids)\n",
    "\n",
    "    gen_kwargs = {\n",
    "        \"max_new_tokens\": REACT_MAX_NEW_TOKENS,\n",
    "        \"do_sample\": REACT_DO_SAMPLE,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"pad_token_id\": getattr(tok, \"pad_token_id\", getattr(tok, \"eos_token_id\", None)),\n",
    "        \"eos_token_id\": getattr(tok, \"eos_token_id\", None),\n",
    "    }\n",
    "    if REACT_DO_SAMPLE:\n",
    "        gen_kwargs.update({\"temperature\": REACT_TEMPERATURE, \"top_p\": REACT_TOP_P})\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = model.generate(input_ids, **gen_kwargs)\n",
    "\n",
    "    gen_ids = out[0][input_ids.shape[-1] :]\n",
    "    gen_text = tok.decode(gen_ids, skip_special_tokens=True)\n",
    "    return gen_text.strip()\n",
    "\n",
    "\n",
    "def _normalize_llm_text(text: str) -> str:\n",
    "    # Rationale: models sometimes wrap actions in code fences or add trailing prose.\n",
    "    # We strip common wrappers so Action parsing is stable.\n",
    "    t = (text or \"\").replace(\"```json\", \"```\").replace(\"```sql\", \"```\")\n",
    "    t = re.sub(r\"```(.*?)```\", r\"\\1\", t, flags=re.DOTALL)\n",
    "    return t.strip()\n",
    "\n",
    "\n",
    "def _parse_action(text: str) -> tuple[str | None, dict]:\n",
    "    # Rationale: extract the last Action so we follow the most recent tool choice.\n",
    "    text = _normalize_llm_text(text)\n",
    "    matches = list(_ACTION_RE.finditer(text))\n",
    "    if not matches:\n",
    "        return None, {}\n",
    "    m = matches[-1]\n",
    "    name = m.group(1).strip()\n",
    "    raw_args = (m.group(2) or \"\").strip()\n",
    "    if not raw_args:\n",
    "        return name, {}\n",
    "    try:\n",
    "        parsed = json.loads(raw_args)\n",
    "    except Exception:\n",
    "        return name, {}\n",
    "    return name, parsed if isinstance(parsed, dict) else {}\n",
    "\n",
    "\n",
    "def _canonicalize_table_casing(sql: str, schema_text: str) -> str:\n",
    "    # Rationale: normalize table casing to match schema for clearer traces.\n",
    "    if not sql or not schema_text:\n",
    "        return sql\n",
    "    tables = []\n",
    "    for line in schema_text.splitlines():\n",
    "        if \"(\" in line and \")\" in line:\n",
    "            tables.append(line.split(\"(\", 1)[0].strip())\n",
    "    out = sql\n",
    "    for t in tables:\n",
    "        out = re.sub(rf\"\\b{re.escape(t)}\\b\", t, out, flags=re.IGNORECASE)\n",
    "    return out\n",
    "\n",
    "\n",
    "def _print_guardrail_stage(label: str, before: str, after: str, *, reason: str | None = None, max_chars: int = 320, show_unchanged: bool = False) -> None:\n",
    "    # Rationale: explain what each guardrail changed (if anything).\n",
    "    before = \"\" if before is None else str(before)\n",
    "    after = \"\" if after is None else str(after)\n",
    "    if reason and not after:\n",
    "        print(f\"{label}: reject ({reason})\")\n",
    "        return\n",
    "    if before.strip() == after.strip():\n",
    "        if show_unchanged:\n",
    "            print(f\"{label}: unchanged\")\n",
    "        return\n",
    "    print(f\"{label}: changed\")\n",
    "    print(\"  before:\", _truncate_text(before, max_chars=max_chars))\n",
    "    print(\"  after: \", _truncate_text(after, max_chars=max_chars))\n",
    "\n",
    "\n",
    "def _apply_guardrails(raw_sql: str, nlq: str, schema_text: str) -> tuple[str, str | None, dict]:\n",
    "    # Rationale: deterministic cleanup before validation/execution to keep behavior explainable.\n",
    "    stages: dict = {\"raw\": raw_sql}\n",
    "    sql, reason = clean_candidate_with_reason(raw_sql)\n",
    "    stages[\"clean\"] = sql\n",
    "    stages[\"clean_reason\"] = reason\n",
    "    if not sql:\n",
    "        return \"\", f\"clean_reject:{reason}\", stages\n",
    "    post = guarded_postprocess(sql, nlq)\n",
    "    stages[\"postprocess\"] = post\n",
    "    proj = enforce_projection_contract(post, nlq)\n",
    "    stages[\"projection\"] = proj\n",
    "    canon = _canonicalize_table_casing(proj, schema_text)\n",
    "    stages[\"casing\"] = canon\n",
    "    return canon, None, stages\n",
    "\n",
    "def log_decision(decisions: list[dict], step: int, decision: str, reason: str, data: dict | None = None, status: str = \"ok\") -> dict:\n",
    "    entry = {\"step\": step, \"decision\": decision, \"reason\": reason, \"status\": status}\n",
    "    if data is not None:\n",
    "        entry[\"data\"] = data\n",
    "    decisions.append(entry)\n",
    "    return entry\n",
    "\n",
    "\n",
    "def format_decision_log(decisions: list[dict], max_items: int | None = 20) -> str:\n",
    "    if not decisions:\n",
    "        return \"(no decisions logged)\"\n",
    "    out: list[str] = []\n",
    "    limit = max_items or len(decisions)\n",
    "    for d in decisions[:limit]:\n",
    "        line = f\"[step {d.get('step')}] {d.get('decision')} — {d.get('reason')} ({d.get('status')})\"\n",
    "        out.append(line)\n",
    "        data = d.get(\"data\")\n",
    "        if data is not None:\n",
    "            try:\n",
    "                snippet = json.dumps(data, ensure_ascii=False)\n",
    "            except Exception:\n",
    "                snippet = str(data)\n",
    "            if len(snippet) > 400:\n",
    "                snippet = snippet[:397] + \"...\"\n",
    "            out.append(f\"  data: {snippet}\")\n",
    "    return \"\\n\".join(out)\n",
    "\n",
    "\n",
    "def summarize_trace(trace: list[dict]) -> dict:\n",
    "    actions = [t.get(\"action\") for t in trace if t.get(\"action\")]\n",
    "    attempted = [t.get(\"attempted_action\") for t in trace if t.get(\"attempted_action\") is not None]\n",
    "    blocked_steps = sum(1 for t in trace if t.get(\"blocked\"))\n",
    "    forced_repairs = [t for t in trace if t.get(\"forced_action\") == \"repair_sql\"]\n",
    "    repair_count = sum(1 for t in trace if t.get(\"action\") == \"repair_sql\")\n",
    "    errors: list[str] = []\n",
    "    for i, a in enumerate(actions):\n",
    "        if a == \"generate_sql\" and \"extract_constraints\" not in actions[:i]:\n",
    "            errors.append(\"generate_without_constraints\")\n",
    "        if a == \"run_sql\" and \"validate_sql\" not in actions[:i]:\n",
    "            errors.append(\"run_without_validate\")\n",
    "        if a == \"run_sql\" and \"validate_constraints\" not in actions[:i]:\n",
    "            errors.append(\"run_without_validate_constraints\")\n",
    "        if a == \"finish\" and \"run_sql\" not in actions[:i]:\n",
    "            errors.append(\"finish_without_run\")\n",
    "    compliance_ok = len(errors) == 0\n",
    "    return {\n",
    "        \"actions\": actions,\n",
    "        \"attempted_actions\": attempted,\n",
    "        \"blocked_steps\": blocked_steps,\n",
    "        \"repairs\": repair_count,\n",
    "        \"forced_repairs\": len(forced_repairs),\n",
    "        \"compliance_ok\": compliance_ok,\n",
    "        \"compliance_errors\": errors,\n",
    "    }\n",
    "\n",
    "\n",
    "def _truncate_text(s: str, max_chars: int = 1200) -> str:\n",
    "    if s is None:\n",
    "        return \"\"\n",
    "    s = str(s)\n",
    "    if max_chars <= 0 or len(s) <= max_chars:\n",
    "        return s\n",
    "    return s[: max_chars - 3] + \"...\"\n",
    "\n",
    "\n",
    "def _print_prompt_tail(prompt: str, *, tail_lines: int = 30, max_line_chars: int = 200) -> None:\n",
    "    if not prompt:\n",
    "        print(\"(empty prompt)\")\n",
    "        return\n",
    "    lines = prompt.splitlines()\n",
    "    tail = lines[-max(1, int(tail_lines)) :]\n",
    "    for ln in tail:\n",
    "        if max_line_chars and len(ln) > max_line_chars:\n",
    "            ln = ln[: max_line_chars - 3] + \"...\"\n",
    "        print(ln)\n",
    "\n",
    "\n",
    "_TOOL_EXPLAIN: dict[str, str] = {\n",
    "    \"get_schema\": \"Look up the database tables/columns (ground truth).\",\n",
    "    \"link_schema\": \"Focus on the most relevant tables/columns for this question.\",\n",
    "    \"extract_constraints\": \"Infer structural needs (COUNT, GROUP BY, LIMIT, DISTINCT, etc.).\",\n",
    "    \"get_table_samples\": \"Fetch a few example rows to ground ambiguous columns.\",\n",
    "    \"generate_sql\": \"Draft a SQL query for the question.\",\n",
    "    \"validate_sql\": \"Check the SQL is safe/valid (single SELECT + known schema refs).\",\n",
    "    \"validate_constraints\": \"Check the SQL matches the question's required structure.\",\n",
    "    \"run_sql\": \"Run the SQL against the DB and observe results/errors.\",\n",
    "    \"repair_sql\": \"Fix the SQL using the latest error feedback.\",\n",
    "    \"finish\": \"Return the final SQL (only after a successful run).\",\n",
    "}\n",
    "\n",
    "\n",
    "def _extract_last_thought(text: str) -> str:\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    for line in reversed(text.splitlines()):\n",
    "        if line.strip().lower().startswith(\"thought:\"):\n",
    "            return line.split(\":\", 1)[1].strip()\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def _friendly_progress(\n",
    "    *,\n",
    "    constraints: dict | None,\n",
    "    last_sql: str | None,\n",
    "    last_valid: bool | None,\n",
    "    last_constraints_ok: bool | None,\n",
    "    last_run: dict | None,\n",
    ") -> str:\n",
    "    parts = []\n",
    "    parts.append(\"constraints: \" + (\"done\" if constraints else \"pending\"))\n",
    "    parts.append(\"sql draft: \" + (\"done\" if last_sql else \"pending\"))\n",
    "    if last_valid is None:\n",
    "        parts.append(\"sql check: pending\")\n",
    "    else:\n",
    "        parts.append(\"sql check: \" + (\"pass\" if last_valid else \"fail\"))\n",
    "    if last_constraints_ok is None:\n",
    "        parts.append(\"shape check: pending\")\n",
    "    else:\n",
    "        parts.append(\"shape check: \" + (\"pass\" if last_constraints_ok else \"fail\"))\n",
    "    if last_run is None:\n",
    "        parts.append(\"run: pending\")\n",
    "    else:\n",
    "        parts.append(\"run: \" + (\"pass\" if last_run.get(\"success\") else \"fail\"))\n",
    "    return \" | \".join(parts)\n",
    "\n",
    "\n",
    "\n",
    "def react_sql(\n",
    "    *,\n",
    "    nlq: str,\n",
    "    schema_text: str | None = None,\n",
    "    schema_summary: str | None = None,\n",
    "    exemplars: list[dict] | None = None,\n",
    "    max_steps: int = REACT_MAX_STEPS,\n",
    "    debug: bool = False,\n",
    "    debug_sleep_s: float = 0.0,\n",
    "    debug_prompt_tail_lines: int = 0,\n",
    "    debug_rows_preview: int = 3,\n",
    "    auto_order: bool = False,  # If True, force the next required tool step (demo-friendly).\n",
    ") -> tuple[str, list[dict], list[dict]]:\n",
    "    trace: list[dict] = []\n",
    "    history: list[str] = []\n",
    "    decision_log: list[dict] = []\n",
    "\n",
    "    schema = get_schema()\n",
    "    schema_text_full = schema_to_text(schema)\n",
    "    schema_text_focus = schema_text_full\n",
    "\n",
    "    schema_tables = [line.split(\"(\", 1)[0].strip() for line in schema_text_full.splitlines() if \"(\" in line]\n",
    "\n",
    "    # Trace bootstrap (required): user question + get_schema + link_schema\n",
    "    history.append(f\"User question: {nlq}\")\n",
    "    history.append(\"Action: get_schema[{}]\")\n",
    "    history.append(f\"Observation: {schema_text_full}\")\n",
    "    log_decision(decision_log, -1, \"get_schema\", \"loaded schema\", {\"tables\": schema_tables})\n",
    "\n",
    "    link_obs = link_schema(nlq, schema_text_full, max_tables=6 if USE_LINK_SCHEMA else 0)\n",
    "    schema_text_focus = link_obs.get(\"schema_text\") or schema_text_full\n",
    "    history.append('Action: link_schema[{\"max_tables\": 6}]')\n",
    "    history.append(f\"Observation: {schema_text_focus}\")\n",
    "    log_decision(decision_log, -1, \"link_schema\", \"prune schema context\", link_obs)\n",
    "\n",
    "    if debug:\n",
    "        print(\"=\" * 80)\n",
    "        print(\"ReAct walkthrough (tool-driven NL->SQL)\")\n",
    "        print(\"NLQ:\", nlq)\n",
    "        print(\"What you'll see: a small set of tools run in order until the SQL executes.\")\n",
    "        print(\"Order: schema -> focus -> requirements -> draft -> checks -> run -> finish\")\n",
    "        print()\n",
    "        print(\"[Bootstrap]\")\n",
    "        print(f\"- schema tables: {len(schema_tables)}\")\n",
    "        focus_lines = schema_text_focus.splitlines()\n",
    "        print(f\"- link_schema enabled: {bool(USE_LINK_SCHEMA)} | changed: {bool(link_obs.get('changed'))} | focus lines: {len(focus_lines)}\")\n",
    "        if focus_lines:\n",
    "            focus_tables = [ln.split(\"(\", 1)[0].strip() for ln in focus_lines if \"(\" in ln and \")\" in ln]\n",
    "            focus_tables = [t for t in focus_tables if t]\n",
    "            if focus_tables:\n",
    "                print(\"- focused tables:\", \", \".join(focus_tables))\n",
    "            join_hint_lines = [ln for ln in focus_lines if ln.lower().startswith(\"join hints:\")]\n",
    "            if join_hint_lines:\n",
    "                print(\"- join hints included: yes\")\n",
    "        print(\"=\" * 80)\n",
    "\n",
    "    last_sql: str | None = None\n",
    "    last_error: str | None = None\n",
    "    last_run: dict | None = None\n",
    "    last_valid: bool | None = None\n",
    "    last_constraints_ok: bool | None = None\n",
    "    constraints: dict | None = None\n",
    "    pending_repair_error: str | None = None\n",
    "    pending_force_generate: str | None = None\n",
    "    clean_reject_retries = 0\n",
    "\n",
    "    for step in range(max_steps):\n",
    "        prompt = \"\\n\".join(history)\n",
    "\n",
    "        if debug:\n",
    "            print(\"\\n\" + \"-\" * 80)\n",
    "            print(f\"STEP {step} / {max_steps - 1}\")\n",
    "            print(\n",
    "                _friendly_progress(\n",
    "                    constraints=constraints,\n",
    "                    last_sql=last_sql,\n",
    "                    last_valid=last_valid,\n",
    "                    last_constraints_ok=last_constraints_ok,\n",
    "                    last_run=last_run,\n",
    "                )\n",
    "            )\n",
    "            if debug_prompt_tail_lines and int(debug_prompt_tail_lines) > 0:\n",
    "                print(\"\\nTranscript tail (what the LLM sees):\")\n",
    "                _print_prompt_tail(prompt, tail_lines=int(debug_prompt_tail_lines))\n",
    "\n",
    "        llm_out = _call_react_llm(prompt)\n",
    "        trace.append({\"step\": step, \"llm\": llm_out})\n",
    "\n",
    "        action, args = _parse_action(llm_out)\n",
    "        if not isinstance(args, dict):\n",
    "            args = {}\n",
    "        attempted_action = action\n",
    "        attempted_args = dict(args)\n",
    "        history.append(llm_out.strip())\n",
    "\n",
    "        if debug:\n",
    "            thought = _extract_last_thought(llm_out)\n",
    "            if thought:\n",
    "                print(\"\\nModel thought:\", _truncate_text(thought, max_chars=240))\n",
    "            print(\"Model action:\", action)\n",
    "\n",
    "        # If we have a pending validation/execution error, force a repair action.\n",
    "        if pending_repair_error and action != \"repair_sql\":\n",
    "            trace.append({\"step\": step, \"forced_action\": \"repair_sql\", \"requested_action\": action, \"reason\": pending_repair_error})\n",
    "            log_decision(decision_log, step, \"force_repair\", pending_repair_error, {\"requested_action\": action})\n",
    "            action = \"repair_sql\"\n",
    "            args = {\"error\": pending_repair_error, \"forced\": True}\n",
    "            history[-1] = f\"Action: repair_sql[{json.dumps(args, ensure_ascii=False)}]\"\n",
    "            if debug:\n",
    "                print(f\"FORCED -> repair_sql (reason: {pending_repair_error})\")\n",
    "\n",
    "        # If guardrails returned empty SQL, force one regenerate.\n",
    "        if pending_force_generate and action != \"generate_sql\":\n",
    "            trace.append({\"step\": step, \"forced_action\": \"generate_sql\", \"requested_action\": action, \"reason\": pending_force_generate})\n",
    "            log_decision(decision_log, step, \"force_generate_sql\", pending_force_generate, {\"requested_action\": action})\n",
    "            action = \"generate_sql\"\n",
    "            args = {\"constraints\": constraints} if constraints else {}\n",
    "            history[-1] = f\"Action: generate_sql[{json.dumps(args, ensure_ascii=False)}]\"\n",
    "            pending_force_generate = None\n",
    "            if debug:\n",
    "                print(\"FORCED -> generate_sql (one retry after guardrail reject)\")\n",
    "\n",
    "        if constraints is None and action not in (\"extract_constraints\", \"repair_sql\"):\n",
    "            trace.append({\"step\": step, \"forced_action\": \"extract_constraints\", \"requested_action\": action, \"reason\": \"constraints_missing\"})\n",
    "            log_decision(decision_log, step, \"force_extract_constraints\", \"constraints_missing\", {\"requested_action\": action})\n",
    "            action = \"extract_constraints\"\n",
    "            args = {}\n",
    "            history[-1] = \"Action: extract_constraints[{}]\"\n",
    "            if debug:\n",
    "                print(\"FORCED -> extract_constraints (constraints missing)\")\n",
    "\n",
    "        # If the model tries to jump ahead (run_sql/finish), redirect to the next required step.\n",
    "        # This avoids burning the step budget on blocked actions and keeps traces easier to read.\n",
    "        if not auto_order and action in (\"run_sql\", \"finish\"):\n",
    "            if pending_repair_error:\n",
    "                required = \"repair_sql\"\n",
    "            elif pending_force_generate:\n",
    "                required = \"generate_sql\"\n",
    "            elif constraints is None:\n",
    "                required = \"extract_constraints\"\n",
    "            elif last_sql is None:\n",
    "                required = \"generate_sql\"\n",
    "            elif last_valid is None:\n",
    "                required = \"validate_sql\"\n",
    "            elif last_valid is False:\n",
    "                required = \"repair_sql\"\n",
    "            elif last_constraints_ok is None:\n",
    "                required = \"validate_constraints\"\n",
    "            elif last_constraints_ok is False:\n",
    "                required = \"repair_sql\"\n",
    "            elif not last_run or not last_run.get(\"success\"):\n",
    "                required = \"run_sql\"\n",
    "            else:\n",
    "                required = \"finish\"\n",
    "\n",
    "            if action != required:\n",
    "                trace.append({\"step\": step, \"forced_action\": required, \"requested_action\": action, \"reason\": \"controller_order\"})\n",
    "                log_decision(decision_log, step, \"force_order\", \"controller_order\", {\"requested_action\": action, \"required_action\": required})\n",
    "                if debug:\n",
    "                    print(f\"FORCED -> {required} (required before {action})\")\n",
    "                action = required\n",
    "                if required == \"generate_sql\":\n",
    "                    args = {\"constraints\": constraints} if constraints else {}\n",
    "                elif required == \"repair_sql\":\n",
    "                    args = {\"error\": pending_repair_error or last_error or \"\"} if (pending_repair_error or last_error) else {}\n",
    "                else:\n",
    "                    args = {}\n",
    "                history[-1] = f\"Action: {required}[{json.dumps(args, ensure_ascii=False)}]\"\n",
    "\n",
    "        # Demo-friendly strict ordering: force the next required step based on state.\n",
    "        # This keeps walkthroughs understandable even when the model proposes out-of-order actions.\n",
    "        if auto_order:\n",
    "            required: str\n",
    "            if pending_repair_error:\n",
    "                required = \"repair_sql\"\n",
    "            elif pending_force_generate:\n",
    "                required = \"generate_sql\"\n",
    "            elif constraints is None:\n",
    "                required = \"extract_constraints\"\n",
    "            elif last_sql is None:\n",
    "                required = \"generate_sql\"\n",
    "            elif last_valid is None:\n",
    "                required = \"validate_sql\"\n",
    "            elif last_valid is False:\n",
    "                required = \"repair_sql\"\n",
    "            elif last_constraints_ok is None:\n",
    "                required = \"validate_constraints\"\n",
    "            elif last_constraints_ok is False:\n",
    "                required = \"repair_sql\"\n",
    "            elif not last_run or not last_run.get(\"success\"):\n",
    "                required = \"run_sql\"\n",
    "            else:\n",
    "                required = \"finish\"\n",
    "\n",
    "            if action != required:\n",
    "                trace.append({\"step\": step, \"forced_action\": required, \"requested_action\": action, \"reason\": \"auto_order\"})\n",
    "                log_decision(decision_log, step, \"force_order\", \"auto_order\", {\"requested_action\": action, \"required_action\": required})\n",
    "                if debug:\n",
    "                    print(f\"FORCED -> {required} (next required step)\")\n",
    "                action = required\n",
    "                if required == \"generate_sql\":\n",
    "                    args = {\"constraints\": constraints} if constraints else {}\n",
    "                elif required == \"repair_sql\":\n",
    "                    args = {\"error\": pending_repair_error or last_error or \"\"} if (pending_repair_error or last_error) else {}\n",
    "                else:\n",
    "                    args = {}\n",
    "                history[-1] = f\"Action: {required}[{json.dumps(args, ensure_ascii=False)}]\"\n",
    "\n",
    "        # If we already ran successfully, force finish to avoid extra tool calls.\n",
    "        if last_run and last_run.get(\"success\") and action != \"finish\":\n",
    "            trace.append({\"step\": step, \"forced_action\": \"finish\", \"requested_action\": action, \"reason\": \"already_successful_run\"})\n",
    "            log_decision(decision_log, step, \"force_finish\", \"already_successful_run\", {\"requested_action\": action})\n",
    "            if debug:\n",
    "                print(\"FORCED -> finish (run_sql already succeeded)\")\n",
    "            action = \"finish\"\n",
    "            args = {}\n",
    "            history[-1] = \"Action: finish[{}]\"\n",
    "\n",
    "        if action is None:\n",
    "            obs = {\"error\": \"No Action found. Respond with Action: tool[json_args].\"}\n",
    "            history.append(f\"Observation: {json.dumps(obs, ensure_ascii=False)}\")\n",
    "            trace.append(\n",
    "                {\n",
    "                    \"step\": step,\n",
    "                    \"attempted_action\": attempted_action,\n",
    "                    \"attempted_args\": attempted_args,\n",
    "                    \"action\": None,\n",
    "                    \"args\": {},\n",
    "                    \"observation\": obs,\n",
    "                    \"blocked\": True,\n",
    "                }\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        if action not in TOOLS:\n",
    "            obs = {\"error\": f\"Unknown action: {action}\"}\n",
    "            history.append(f\"Observation: {json.dumps(obs, ensure_ascii=False)}\")\n",
    "            trace.append(\n",
    "                {\n",
    "                    \"step\": step,\n",
    "                    \"attempted_action\": attempted_action,\n",
    "                    \"attempted_args\": attempted_args,\n",
    "                    \"action\": None,\n",
    "                    \"args\": {},\n",
    "                    \"observation\": obs,\n",
    "                    \"blocked\": True,\n",
    "                }\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        # Setup-only tools should not be executed inside the main loop.\n",
    "        if action in (\"get_schema\", \"link_schema\"):\n",
    "            obs = {\"error\": f\"{action} is setup-only and already executed.\"}\n",
    "            history.append(f\"Observation: {json.dumps(obs, ensure_ascii=False)}\")\n",
    "            trace.append(\n",
    "                {\n",
    "                    \"step\": step,\n",
    "                    \"attempted_action\": attempted_action,\n",
    "                    \"attempted_args\": attempted_args,\n",
    "                    \"action\": None,\n",
    "                    \"args\": {},\n",
    "                    \"observation\": obs,\n",
    "                    \"blocked\": True,\n",
    "                }\n",
    "            )\n",
    "            log_decision(decision_log, step, \"blocked_setup_action\", action, {\"attempted_action\": attempted_action})\n",
    "            if debug:\n",
    "                print(f\"BLOCKED setup action: {action}\")\n",
    "            continue\n",
    "\n",
    "        # Enforce: run_sql must succeed before finish.\n",
    "        if action == \"finish\":\n",
    "            # Rationale: finish is only allowed after a successful execution.\n",
    "            if not last_run or not last_run.get(\"success\"):\n",
    "                obs = {\"error\": \"Must call run_sql successfully before finish.\"}\n",
    "                history.append(f\"Observation: {json.dumps(obs, ensure_ascii=False)}\")\n",
    "                trace.append(\n",
    "                    {\n",
    "                        \"step\": step,\n",
    "                        \"attempted_action\": attempted_action,\n",
    "                        \"attempted_args\": attempted_args,\n",
    "                        \"action\": None,\n",
    "                        \"args\": {},\n",
    "                        \"observation\": obs,\n",
    "                        \"blocked\": True,\n",
    "                    }\n",
    "                )\n",
    "                if debug:\n",
    "                    print(\"FINISH blocked:\", obs[\"error\"])\n",
    "                continue\n",
    "            result = finish(answer=str(last_run.get(\"rows\", [])), sql=last_sql or \"\", provenance={\"trace\": trace})\n",
    "            trace.append(\n",
    "                {\n",
    "                    \"step\": step,\n",
    "                    \"attempted_action\": attempted_action,\n",
    "                    \"attempted_args\": attempted_args,\n",
    "                    \"action\": \"finish\",\n",
    "                    \"args\": {},\n",
    "                    \"observation\": result,\n",
    "                }\n",
    "            )\n",
    "            log_decision(decision_log, step, \"finish\", \"completed\", {\"sql\": result.get(\"sql\", \"\")})\n",
    "            if debug:\n",
    "                print(\"\\nFINISH -> returning final SQL\")\n",
    "                print(result.get(\"sql\", \"\"))\n",
    "            return result.get(\"sql\", \"\"), trace, decision_log\n",
    "\n",
    "        if debug:\n",
    "            expl = _TOOL_EXPLAIN.get(action, \"\")\n",
    "            if expl:\n",
    "                print(f\"\\nTool: {action} — {expl}\")\n",
    "            else:\n",
    "                print(f\"\\nTool: {action}\")\n",
    "\n",
    "        executed_action = action\n",
    "        blocked = False\n",
    "        auto_finish = False\n",
    "        auto_finish_payload = None\n",
    "\n",
    "        # Tool execution\n",
    "        if action == \"get_schema\":\n",
    "            obs = schema_text_full\n",
    "            schema_text_focus = schema_text_full\n",
    "            if debug:\n",
    "                print(\"\\nSchema loaded.\")\n",
    "        elif action == \"link_schema\":\n",
    "            # Rationale: prunes schema context to reduce wrong-table joins and overlong prompts.\n",
    "            max_tables = int(args.get(\"max_tables\", 6)) if str(args.get(\"max_tables\", \"\")).isdigit() else 6\n",
    "            res = link_schema(nlq, schema_text_full, max_tables=max_tables if USE_LINK_SCHEMA else 0)\n",
    "            res[\"enabled\"] = bool(USE_LINK_SCHEMA)\n",
    "            schema_text_focus = res.get(\"schema_text\") or schema_text_full\n",
    "            obs = res\n",
    "            if debug:\n",
    "                schema_preview = (res.get(\"schema_text\") or \"\").strip()\n",
    "                focus_lines = schema_preview.splitlines() if schema_preview else []\n",
    "                focus_tables = [ln.split(\"(\", 1)[0].strip() for ln in focus_lines if \"(\" in ln and \")\" in ln]\n",
    "                focus_tables = [t for t in focus_tables if t]\n",
    "                if focus_tables:\n",
    "                    print(\"\\nFocused tables:\", \", \".join(focus_tables))\n",
    "                else:\n",
    "                    print(\"\\nFocused tables: (none)\")\n",
    "        elif action == \"extract_constraints\":\n",
    "            # Rationale: structural cues (COUNT/GROUP BY/LIMIT) are frequent EX failure points.\n",
    "            res = extract_constraints(nlq)\n",
    "            constraints = res\n",
    "            last_constraints_ok = None\n",
    "            obs = res\n",
    "            log_decision(decision_log, step, \"extract_constraints\", \"heuristic extraction\", res)\n",
    "            if debug:\n",
    "                print(\"\\nRequirements extracted:\", res)\n",
    "        elif action == \"get_table_samples\":\n",
    "            table = args.get(\"table\")\n",
    "            n = int(args.get(\"n\", 3)) if str(args.get(\"n\", \"\")).isdigit() else 3\n",
    "            obs = get_table_samples(table, n=n)\n",
    "            if debug:\n",
    "                print(f\"\\nSample rows from {table!r} (n={n}):\")\n",
    "                try:\n",
    "                    print(_truncate_text(json.dumps(obs, ensure_ascii=False, default=str), max_chars=1200))\n",
    "                except Exception:\n",
    "                    print(_truncate_text(str(obs), max_chars=1200))\n",
    "        elif action == \"generate_sql\":\n",
    "            # Rationale: model generation step; guardrails immediately clean + normalize output.\n",
    "            constraints = args.get(\"constraints\") or constraints or {\"intent\": classify_intent(nlq)}\n",
    "            if debug:\n",
    "                print(\"\\nRequirements:\", constraints)\n",
    "            raw_sql = generate_sql(nlq, schema_text_focus, constraints)\n",
    "            log_decision(decision_log, step, \"generate_sql\", \"model generation\", {\"raw_sql\": raw_sql})\n",
    "            sql, reason, stages = _apply_guardrails(raw_sql, nlq, schema_text_full)\n",
    "            if debug:\n",
    "                print(\"\\nDraft SQL (raw):\")\n",
    "                print(_truncate_text(raw_sql, max_chars=2000))\n",
    "                if stages:\n",
    "                    print(\"\\nGuardrails effects:\")\n",
    "                    _print_guardrail_stage(\"clean_candidate\", raw_sql, stages.get(\"clean\"), reason=stages.get(\"clean_reason\"))\n",
    "                    if \"postprocess\" in stages:\n",
    "                        _print_guardrail_stage(\"guarded_postprocess\", stages.get(\"clean\"), stages.get(\"postprocess\"))\n",
    "                    if \"projection\" in stages:\n",
    "                        _print_guardrail_stage(\"projection_contract\", stages.get(\"postprocess\"), stages.get(\"projection\"))\n",
    "                    if \"casing\" in stages:\n",
    "                        _print_guardrail_stage(\"canonicalize_casing\", stages.get(\"projection\"), stages.get(\"casing\"))\n",
    "            if not sql:\n",
    "                obs = {\"error\": reason, \"raw_sql\": raw_sql, \"hint\": \"Output a single SELECT statement only.\"}\n",
    "                log_decision(decision_log, step, \"guardrails\", \"clean_reject\", {\"reason\": reason, \"raw_sql\": raw_sql}, status=\"reject\")\n",
    "                if clean_reject_retries < MAX_CLEAN_REJECT_RETRIES:\n",
    "                    pending_force_generate = reason\n",
    "                    clean_reject_retries += 1\n",
    "                if debug:\n",
    "                    print(\"\\nGuardrails: REJECT -\", reason)\n",
    "            else:\n",
    "                last_sql = sql\n",
    "                last_error = None\n",
    "                last_valid = None\n",
    "                last_constraints_ok = None\n",
    "                pending_repair_error = None\n",
    "                pending_force_generate = None\n",
    "                obs = {\"sql\": sql}\n",
    "                log_decision(decision_log, step, \"guardrails\", \"cleaned\", {\"cleaned_sql\": sql})\n",
    "                if debug:\n",
    "                    print(\"\\nSQL after guardrails:\")\n",
    "                    print(sql)\n",
    "        elif action == \"repair_sql\":\n",
    "            # Rationale: forced recovery when validation/execution fails.\n",
    "            if not last_sql:\n",
    "                obs = {\"error\": \"No SQL to repair. Call generate_sql first.\"}\n",
    "                blocked = True\n",
    "                executed_action = None\n",
    "            else:\n",
    "                err = args.get(\"error\") or last_error or \"\"\n",
    "                if debug:\n",
    "                    print(\"\\nPrevious SQL:\")\n",
    "                    print(last_sql)\n",
    "                raw_sql = repair_sql(nlq, last_sql, err, schema_text_full)\n",
    "                log_decision(decision_log, step, \"repair_sql\", \"model repair\", {\"error\": err, \"raw_sql\": raw_sql})\n",
    "                sql, reason, stages = _apply_guardrails(raw_sql, nlq, schema_text_full)\n",
    "                if debug:\n",
    "                    print(\"\\nError to fix:\", err)\n",
    "                    print(\"\\nRepair draft (raw):\")\n",
    "                    print(_truncate_text(raw_sql, max_chars=2000))\n",
    "                    if stages:\n",
    "                        print(\"\\nGuardrails effects:\")\n",
    "                        _print_guardrail_stage(\"clean_candidate\", raw_sql, stages.get(\"clean\"), reason=stages.get(\"clean_reason\"))\n",
    "                        if \"postprocess\" in stages:\n",
    "                            _print_guardrail_stage(\"guarded_postprocess\", stages.get(\"clean\"), stages.get(\"postprocess\"))\n",
    "                        if \"projection\" in stages:\n",
    "                            _print_guardrail_stage(\"projection_contract\", stages.get(\"postprocess\"), stages.get(\"projection\"))\n",
    "                        if \"casing\" in stages:\n",
    "                            _print_guardrail_stage(\"canonicalize_casing\", stages.get(\"projection\"), stages.get(\"casing\"))\n",
    "                if not sql:\n",
    "                    obs = {\"error\": reason, \"raw_sql\": raw_sql}\n",
    "                    log_decision(decision_log, step, \"guardrails\", \"clean_reject\", {\"reason\": reason, \"raw_sql\": raw_sql}, status=\"reject\")\n",
    "                    if debug:\n",
    "                        print(\"\\nGuardrails: REJECT -\", reason)\n",
    "                else:\n",
    "                    last_sql = sql\n",
    "                    last_valid = None\n",
    "                    last_constraints_ok = None\n",
    "                    pending_repair_error = None\n",
    "                    obs = {\"sql\": sql}\n",
    "                    log_decision(decision_log, step, \"guardrails\", \"cleaned\", {\"cleaned_sql\": sql})\n",
    "                    if debug:\n",
    "                        print(\"\\nSQL after guardrails:\")\n",
    "                        print(sql)\n",
    "        elif action == \"validate_sql\":\n",
    "            # Rationale: catch schema/format errors before hitting the database.\n",
    "            if not last_sql:\n",
    "                obs = {\"error\": \"No SQL to validate. Call generate_sql first.\"}\n",
    "                blocked = True\n",
    "                executed_action = None\n",
    "            else:\n",
    "                res = validate_sql(last_sql, schema_text_full)\n",
    "                if res.get(\"reason\") == \"no_schema\":\n",
    "                    res = {\"valid\": False, \"reason\": \"schema_missing\"}\n",
    "                obs = res\n",
    "                last_valid = bool(res.get(\"valid\"))\n",
    "                data = dict(res)\n",
    "                data[\"schema_text_len\"] = len(schema_text_full or \"\")\n",
    "                log_decision(decision_log, step, \"validate_sql\", res.get(\"reason\", \"\"), data, status=\"ok\" if last_valid else \"reject\")\n",
    "                if not last_valid:\n",
    "                    last_error = res.get(\"reason\")\n",
    "                    pending_repair_error = last_error\n",
    "                else:\n",
    "                    pending_repair_error = None\n",
    "            if debug:\n",
    "                if obs.get(\"error\"):\n",
    "                    print(\"\\nSQL check: blocked -\", obs.get(\"error\"))\n",
    "                elif obs.get(\"valid\"):\n",
    "                    print(\"\\nSQL check: PASS\")\n",
    "                else:\n",
    "                    print(\"\\nSQL check: FAIL -\", obs.get(\"reason\"))\n",
    "        elif action == \"validate_constraints\":\n",
    "            # Rationale: enforce NLQ-implied structure (aggregation, grouping, limits).\n",
    "            if not last_sql:\n",
    "                obs = {\"error\": \"No SQL to validate. Call generate_sql first.\"}\n",
    "                blocked = True\n",
    "                executed_action = None\n",
    "            elif not constraints:\n",
    "                obs = {\"error\": \"No constraints found. Call extract_constraints first.\"}\n",
    "                blocked = True\n",
    "                executed_action = None\n",
    "            else:\n",
    "                res = validate_constraints(last_sql, constraints)\n",
    "                obs = res\n",
    "                last_constraints_ok = bool(res.get(\"valid\"))\n",
    "                log_decision(decision_log, step, \"validate_constraints\", res.get(\"reason\", \"\"), res, status=\"ok\" if last_constraints_ok else \"reject\")\n",
    "                if not last_constraints_ok:\n",
    "                    last_error = res.get(\"reason\")\n",
    "                    pending_repair_error = last_error\n",
    "                else:\n",
    "                    pending_repair_error = None\n",
    "            if debug:\n",
    "                if obs.get(\"error\"):\n",
    "                    print(\"\\nShape check: blocked -\", obs.get(\"error\"))\n",
    "                elif obs.get(\"valid\"):\n",
    "                    print(\"\\nShape check: PASS\")\n",
    "                else:\n",
    "                    print(\"\\nShape check: FAIL -\", obs.get(\"reason\"))\n",
    "        elif action == \"run_sql\":\n",
    "            # Rationale: execution is the ReAct Observation; it tells the loop what failed.\n",
    "            if not last_sql:\n",
    "                obs = {\"error\": \"No SQL to run. Call generate_sql first.\"}\n",
    "                blocked = True\n",
    "                executed_action = None\n",
    "            elif last_valid is None:\n",
    "                obs = {\"error\": \"Must call validate_sql before run_sql.\"}\n",
    "                blocked = True\n",
    "                executed_action = None\n",
    "            elif last_valid is False:\n",
    "                obs = {\"error\": \"Validation failed. Call repair_sql.\"}\n",
    "                blocked = True\n",
    "                executed_action = None\n",
    "            elif last_constraints_ok is None:\n",
    "                obs = {\"error\": \"Must call validate_constraints before run_sql.\"}\n",
    "                blocked = True\n",
    "                executed_action = None\n",
    "            elif last_constraints_ok is False:\n",
    "                obs = {\"error\": \"Constraint validation failed. Call repair_sql.\"}\n",
    "                blocked = True\n",
    "                executed_action = None\n",
    "            else:\n",
    "                res = run_sql(last_sql)\n",
    "                log_decision(decision_log, step, \"run_sql\", \"execute\", {\"success\": res.get(\"success\"), \"rowcount\": res.get(\"rowcount\"), \"error\": res.get(\"error\")})\n",
    "                if res.get(\"success\"):\n",
    "                    ok, why = intent_constraints(nlq, last_sql)\n",
    "                    if not ok:\n",
    "                        res = {\"success\": False, \"error\": f\"Intent mismatch: {why}\"}\n",
    "                        log_decision(decision_log, step, \"intent_check\", why, {\"ok\": ok}, status=\"reject\")\n",
    "                    else:\n",
    "                        log_decision(decision_log, step, \"intent_check\", \"ok\", {\"ok\": ok})\n",
    "                        auto_finish = True\n",
    "                        auto_finish_payload = {\"answer\": str(res.get(\"rows\", [])), \"sql\": last_sql or \"\"}\n",
    "                obs = res\n",
    "                last_run = res\n",
    "                if not res.get(\"success\"):\n",
    "                    last_error = res.get(\"error\")\n",
    "                    pending_repair_error = last_error\n",
    "                else:\n",
    "                    pending_repair_error = None\n",
    "            if debug:\n",
    "                if obs.get(\"success\"):\n",
    "                    print(\"\\nRun: PASS (rows:\", obs.get(\"rowcount\"), \")\")\n",
    "                    rows = obs.get(\"rows\") or []\n",
    "                    if rows:\n",
    "                        preview = rows[: max(0, int(debug_rows_preview))]\n",
    "                        line = _truncate_text(json.dumps(preview, ensure_ascii=False, default=str), max_chars=1200)\n",
    "                        print(\"Rows preview:\", line)\n",
    "                else:\n",
    "                    print(\"\\nRun: FAIL -\", obs.get(\"error\"))\n",
    "        else:\n",
    "            obs = {\"error\": f\"Unhandled action: {action}\"}\n",
    "\n",
    "        history.append(f\"Observation: {json.dumps(obs, ensure_ascii=False, default=str)}\")\n",
    "        trace.append(\n",
    "            {\n",
    "                \"step\": step,\n",
    "                \"attempted_action\": attempted_action,\n",
    "                \"attempted_args\": attempted_args,\n",
    "                \"action\": executed_action,\n",
    "                \"args\": args if executed_action else {},\n",
    "                \"observation\": obs,\n",
    "                \"blocked\": blocked,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        if auto_finish and auto_finish_payload is not None:\n",
    "            result = finish(\n",
    "                answer=auto_finish_payload[\"answer\"],\n",
    "                sql=auto_finish_payload[\"sql\"],\n",
    "                provenance={\"trace\": trace},\n",
    "            )\n",
    "            trace.append(\n",
    "                {\n",
    "                    \"step\": step,\n",
    "                    \"attempted_action\": attempted_action,\n",
    "                    \"attempted_args\": attempted_args,\n",
    "                    \"action\": \"finish\",\n",
    "                    \"args\": {},\n",
    "                    \"observation\": result,\n",
    "                    \"forced_action\": \"finish\",\n",
    "                    \"reason\": \"auto_finish_after_success\",\n",
    "                }\n",
    "            )\n",
    "            log_decision(decision_log, step, \"finish\", \"auto_finish_after_success\", {\"sql\": result.get(\"sql\", \"\")})\n",
    "            if debug:\n",
    "                print(\"\\nAUTO-FINISH -> returning final SQL\")\n",
    "                print(result.get(\"sql\", \"\"))\n",
    "            return result.get(\"sql\", \"\"), trace, decision_log\n",
    "\n",
    "        if debug and float(debug_sleep_s) > 0:\n",
    "            time.sleep(float(debug_sleep_s))\n",
    "\n",
    "    # Fallback if the loop did not finish\n",
    "    fallback = None\n",
    "    if schema_summary:\n",
    "        fallback = vanilla_candidate(\n",
    "            nlq=nlq,\n",
    "            schema_summary=schema_summary,\n",
    "            tok=tok,\n",
    "            model=model,\n",
    "            exemplars=exemplars or [],\n",
    "        )\n",
    "    if fallback:\n",
    "        trace.append({\"step\": max_steps, \"action\": \"fallback\", \"sql\": fallback})\n",
    "        log_decision(decision_log, max_steps, \"fallback\", \"vanilla candidate\", {\"sql\": fallback})\n",
    "        return fallback, trace, decision_log\n",
    "    return last_sql or \"\", trace, decision_log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a77d6f",
   "metadata": {},
   "source": [
    "## EX Troubleshooting Checklist (VA high, EX low)\n",
    "\n",
    "- Projection drift → `enforce_projection_contract`\n",
    "- Intent mismatch → `intent_constraints`\n",
    "- Wrong tables/joins → check `link_schema`\n",
    "- Missing literals → check constraints + filters\n",
    "\n",
    "**Explain with**: `5_ITERATIVE_REFINEMENTS.md`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0cb3f3",
   "metadata": {},
   "source": [
    "### Quick sanity check (trace + decision log)\n",
    "\n",
    "**What this cell does**: runs a small slice and prints VA, intent checks, trace summary, and decisions.\n",
    "\n",
    "**Explain with**: `context.md` (trace fields), `EXAMINER_QA.md`\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "b8b3c4fd",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 7a) Interactive walkthrough: type an NLQ and watch the loop step-by-step\n",
    "DEMO_INTERACTIVE = True\n",
    "DEMO_DEFAULT_NLQ = \"Which customers are in France?\"\n",
    "DEMO_AUTO_ORDER = True  # keep the walkthrough linear (forces the next required step)\n",
    "DEMO_SLEEP_S = 0.8  # set 0 for fast\n",
    "DEMO_PROMPT_TAIL = 0  # set >0 to show the transcript tail the model sees\n",
    "SHOW_DECISIONS = False\n",
    "\n",
    "nlq = \"\"\n",
    "if DEMO_INTERACTIVE:\n",
    "    try:\n",
    "        nlq = input(\"Type a ClassicModels question (blank uses default): \").strip()\n",
    "    except Exception:\n",
    "        nlq = \"\"\n",
    "if not nlq:\n",
    "    nlq = DEMO_DEFAULT_NLQ\n",
    "\n",
    "pred, trace, decisions = react_sql(\n",
    "    nlq=nlq,\n",
    "    schema_summary=SCHEMA_SUMMARY,\n",
    "    exemplars=REACT_EXEMPLARS,\n",
    "    debug=True,\n",
    "    auto_order=DEMO_AUTO_ORDER,\n",
    "    debug_sleep_s=DEMO_SLEEP_S,\n",
    "    debug_prompt_tail_lines=DEMO_PROMPT_TAIL,\n",
    ")\n",
    "\n",
    "print(\"\\nFINAL SQL:\")\n",
    "print(pred)\n",
    "print(\"\\nTRACE SUMMARY:\", summarize_trace(trace))\n",
    "if SHOW_DECISIONS:\n",
    "    print(\"\\nDECISIONS:\\n\" + format_decision_log(decisions, max_items=40))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41c91f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) Quick sanity check on a few items\n",
    "from nl2sql.eval import execution_accuracy\n",
    "DEBUG_EX = False  # set True for a quick EX check (slower)\n",
    "DEBUG_TRACE = True\n",
    "for sample in test_set[:5]:\n",
    "    nlq = sample[\"nlq\"]\n",
    "    gold = sample[\"sql\"]\n",
    "    pred, trace, decisions = react_sql(\n",
    "        nlq=nlq,\n",
    "        schema_summary=SCHEMA_SUMMARY,\n",
    "        exemplars=REACT_EXEMPLARS,\n",
    "        auto_order=True,  # ensure ordered tool steps in sanity check\n",
    "    )\n",
    "    print(\"NLQ:\", nlq)\n",
    "    print(\"PRED:\", pred)\n",
    "    print(\"GOLD:\", gold)\n",
    "    if pred:\n",
    "        meta = runner.run(pred, capture_df=False)\n",
    "        print(\"VA:\", int(meta.success), \"ERR:\", meta.error)\n",
    "        ok, why = intent_constraints(nlq, pred)\n",
    "        print(\"INTENT:\", ok, why)\n",
    "    else:\n",
    "        print(\"VA:\", 0, \"ERR:\", \"no prediction\")\n",
    "        print(\"INTENT:\", False, \"no prediction\")\n",
    "    if DEBUG_EX and pred:\n",
    "        ex_ok, pred_err, gold_err = execution_accuracy(engine=engine, pred_sql=pred, gold_sql=gold)\n",
    "        print(\"EX:\", int(ex_ok), \"PRED_ERR:\", pred_err, \"GOLD_ERR:\", gold_err)\n",
    "    if DEBUG_TRACE and trace:\n",
    "        summary = summarize_trace(trace)\n",
    "        print(\"TRACE LEN:\", len(trace))\n",
    "        print(\"EXECUTED ACTIONS:\", summary.get(\"actions\"))\n",
    "        attempted = summary.get(\"attempted_actions\") or []\n",
    "        if attempted:\n",
    "            print(\"ATTEMPTED ACTIONS:\", attempted[-10:])\n",
    "        print(\"BLOCKED STEPS:\", summary.get(\"blocked_steps\"))\n",
    "        print(\"COMPLIANCE:\", summary.get(\"compliance_ok\"), summary.get(\"compliance_errors\"))\n",
    "        print(\"TRACE SUMMARY:\", summary)\n",
    "        print(\"DECISIONS:\\n\" + format_decision_log(decisions, max_items=12))\n",
    "        print(\"TRACE LAST:\", trace[-1])\n",
    "    else:\n",
    "        print(\"TRACE LEN:\", len(trace))\n",
    "    print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89984dc7",
   "metadata": {},
   "source": [
    "### Import TS evaluator\n",
    "\n",
    "**What this cell does**: loads the TS evaluator for semantic robustness across DB replicas.\n",
    "\n",
    "**Explain with**: `4_EVALUATION.md`, `REFERENCES.md#ref-zhong2020-ts`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c7a7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Test Suite Accuracy (TS) evaluation ===\n",
    "# Harness now lives in nl2sql.eval for reuse in scripts.\n",
    "from nl2sql.eval import test_suite_accuracy_for_item\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c61e8a",
   "metadata": {},
   "source": [
    "### Debug cost toggles\n",
    "\n",
    "**What this cell does**: sets small limits for fast iteration (TS replicas, rows, query count).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1ae08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Quick test toggles (set before full eval) ===\n",
    "# Use small values to sanity‑check TS/EX before full runs.\n",
    "QUICK_LIMIT = 20   # number of NLQs to evaluate (set None for full set)\n",
    "TS_N = 3           # number of TS DBs (set 10 for full TS)\n",
    "MAX_ROWS_TS = 500  # row cap per query in TS (raise for full)\n",
    "USE_LINK_SCHEMA = True  # set False to ablate schema linking\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11f9403",
   "metadata": {},
   "source": [
    "### Full evaluation (VA/EM/EX/TS)\n",
    "\n",
    "**What this cell does**: runs the full tool‑driven loop and saves JSON results with trace summaries.\n",
    "\n",
    "**Explain with**: `4_EVALUATION.md`, `LOGBOOK.md`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b771d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) Full agentic evaluation (VA/EX/EM/TS) over test_set\n",
    "import json\n",
    "from functools import lru_cache\n",
    "from pathlib import Path\n",
    "from sqlalchemy.engine import Engine\n",
    "from nl2sql.eval import execution_accuracy, test_suite_accuracy_for_item\n",
    "from nl2sql.postprocess import normalize_sql\n",
    "\n",
    "results = []\n",
    "TS_PREFIX = \"classicmodels_ts\"\n",
    "SUITE_DBS = [f\"{TS_PREFIX}_{i:02d}\" for i in range(1, TS_N + 1)]\n",
    "\n",
    "@lru_cache(maxsize=32)\n",
    "def make_engine_cached(db_name: str) -> Engine:\n",
    "    return make_engine(db_name)\n",
    "\n",
    "def make_engine_fn(db_name: str) -> Engine:\n",
    "    return make_engine_cached(db_name)\n",
    "\n",
    "LIMIT = QUICK_LIMIT  # override from quick toggles\n",
    "items = test_set[:LIMIT] if LIMIT else test_set\n",
    "\n",
    "# Per-item evaluation: generate SQL and compute VA/EM/EX/TS.\n",
    "for i, sample in enumerate(items, start=1):\n",
    "    nlq = sample[\"nlq\"]\n",
    "    gold_sql = sample[\"sql\"]\n",
    "    pred_sql, trace, decisions = react_sql(\n",
    "        nlq=nlq,\n",
    "        schema_summary=SCHEMA_SUMMARY,\n",
    "        exemplars=REACT_EXEMPLARS,\n",
    "    )\n",
    "    trace_summary = summarize_trace(trace)\n",
    "    decision_log = decisions\n",
    "\n",
    "    # EM is strict (normalized) string match; kept as a diagnostic signal.\n",
    "    em = int(normalize_sql(pred_sql) == normalize_sql(gold_sql))\n",
    "\n",
    "    # VA = executability of predicted SQL\n",
    "    va_meta = runner.run(pred_sql, capture_df=False) if pred_sql else None\n",
    "    va = int(bool(va_meta and va_meta.success))\n",
    "\n",
    "    # EX = execution accuracy on base DB (row equivalence)\n",
    "    ex = 0\n",
    "    pred_err = None\n",
    "    gold_err = None\n",
    "    if va:\n",
    "        ex_ok, pred_err, gold_err = execution_accuracy(engine=engine, pred_sql=pred_sql, gold_sql=gold_sql)\n",
    "        ex = int(ex_ok)\n",
    "\n",
    "    # TS = test-suite accuracy across replica DBs\n",
    "    # Note: test_suite_accuracy_for_item returns (ts_pass, debug_info).\n",
    "    ts = None\n",
    "    ts_debug = None\n",
    "    if va:\n",
    "        ts, ts_debug = test_suite_accuracy_for_item(\n",
    "            pred_sql=pred_sql,\n",
    "            gold_sql=gold_sql,\n",
    "            suite_db_names=SUITE_DBS,\n",
    "            make_engine_fn=make_engine_fn,\n",
    "            max_rows=MAX_ROWS_TS,\n",
    "        )\n",
    "\n",
    "    results.append(\n",
    "        {\n",
    "            \"nlq\": nlq,\n",
    "            \"gold_sql\": gold_sql,\n",
    "            \"pred_sql\": pred_sql,\n",
    "            \"va\": va,\n",
    "            \"em\": em,\n",
    "            \"ex\": ex,\n",
    "            \"ts\": ts,\n",
    "            \"ts_debug\": ts_debug,\n",
    "            \"pred_err\": pred_err,\n",
    "            \"gold_err\": gold_err,\n",
    "            \"trace\": trace,\n",
    "            \"trace_summary\": trace_summary,\n",
    "            \"decision_log\": decision_log,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    if i % 20 == 0 or i == len(items):\n",
    "        print(f\"Processed {i}/{len(items)}\")\n",
    "\n",
    "# Aggregate rates\n",
    "va_rate = sum(r[\"va\"] for r in results) / len(results)\n",
    "em_rate = sum(r[\"em\"] for r in results) / len(results)\n",
    "ex_rate = sum(r[\"ex\"] for r in results) / len(results)\n",
    "ts_values = [r[\"ts\"] for r in results if r.get(\"ts\") is not None]\n",
    "ts_rate = (sum(ts_values) / max(1, len(ts_values))) if ts_values else 0.0\n",
    "\n",
    "print(\"ReAct VA:\", round(va_rate, 3), \"EX:\", round(ex_rate, 3), \"EM:\", round(em_rate, 3), \"TS:\", round(ts_rate, 3))\n",
    "\n",
    "out = {\n",
    "    \"va_rate\": va_rate,\n",
    "    \"ex_rate\": ex_rate,\n",
    "    \"em_rate\": em_rate,\n",
    "    \"ts_rate\": ts_rate,\n",
    "    \"items\": results,\n",
    "}\n",
    "out_path = Path(\"results/agent/results_react_200.json\")\n",
    "out_path.write_text(json.dumps(out, indent=2, default=str))\n",
    "print(\"Saved to\", out_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
