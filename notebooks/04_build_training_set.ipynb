{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9faf33c",
   "metadata": {},
   "source": [
    "# Validate the QLoRA training set (ClassicModels)\n",
    "\n",
    "This notebook **does not generate** training data. Instead, it validates that an existing JSONL training set executes cleanly on the ClassicModels database and does **not** overlap the fixed 200-item benchmark test set.\n",
    "\n",
    "## Inputs\n",
    "- Benchmark test set (fixed): `data/classicmodels_test_200.json`\n",
    "- Training set (pre-generated): `data/train/classicmodels_train_200.jsonl`\n",
    "\n",
    "## Checks performed\n",
    "- **Train/test leakage**: rejects exact NLQ overlaps with the benchmark NLQs\n",
    "- **SELECT-only**: rejects non-SELECT statements\n",
    "- **Executability (VA)**: runs each SQL against the live DB to confirm it executes\n",
    "\n",
    "## Output\n",
    "- Validation report printed in notebook output and saved to `results/training_set_validation/validation_report.json`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dc6a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If running in Colab: install dependencies\n",
    "try:\n",
    "    import google.colab  # noqa: F401\n",
    "    !pip -q install -r requirements.txt\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from sqlalchemy import text\n",
    "\n",
    "from nl2sql.db import create_engine_with_connector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7c75b7",
   "metadata": {},
   "source": [
    "## 1) Configure DB connection\n",
    "\n",
    "This uses the same environment variables as the other notebooks:\n",
    "\n",
    "- `INSTANCE_CONNECTION_NAME` (e.g. `project:region:instance`)\n",
    "- `DB_USER`\n",
    "- `DB_PASS`\n",
    "- `DB_NAME` (usually `classicmodels`)\n",
    "\n",
    "If they are not set, the notebook will prompt you.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbb8b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "INSTANCE_CONNECTION_NAME = os.getenv('INSTANCE_CONNECTION_NAME')\n",
    "DB_USER = os.getenv('DB_USER')\n",
    "DB_PASS = os.getenv('DB_PASS')\n",
    "DB_NAME = os.getenv('DB_NAME') or 'classicmodels'\n",
    "\n",
    "if not INSTANCE_CONNECTION_NAME:\n",
    "    INSTANCE_CONNECTION_NAME = input('Enter INSTANCE_CONNECTION_NAME: ').strip()\n",
    "if not DB_USER:\n",
    "    DB_USER = input('Enter DB_USER: ').strip()\n",
    "if not DB_PASS:\n",
    "    DB_PASS = getpass('Enter DB_PASS: ')\n",
    "\n",
    "engine, connector = create_engine_with_connector(\n",
    "    instance_connection_name=INSTANCE_CONNECTION_NAME,\n",
    "    user=DB_USER,\n",
    "    password=DB_PASS,\n",
    "    db_name=DB_NAME,\n",
    ")\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text('SELECT 1')).fetchone()\n",
    "print('DB connection OK')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839f406b",
   "metadata": {},
   "source": [
    "## 2) Load benchmark + training set\n",
    "\n",
    "The benchmark is fixed at 200 items. The training set must be separate (no exact NLQ overlap).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ddacb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = Path('data/classicmodels_test_200.json')\n",
    "train_path = Path('data/train/classicmodels_train_200.jsonl')\n",
    "\n",
    "test_items = json.loads(test_path.read_text(encoding='utf-8'))\n",
    "test_nlqs = {x['nlq'].strip() for x in test_items}\n",
    "\n",
    "train_records = []\n",
    "for line in train_path.read_text(encoding='utf-8').splitlines():\n",
    "    line = line.strip()\n",
    "    if not line:\n",
    "        continue\n",
    "    train_records.append(json.loads(line))\n",
    "\n",
    "print('Test items:', len(test_items))\n",
    "print('Train items:', len(train_records))\n",
    "\n",
    "# Basic shape checks\n",
    "for i, r in enumerate(train_records[:5]):\n",
    "    assert 'nlq' in r and 'sql' in r, f'Missing keys at row {i}: {r}'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9a31c2",
   "metadata": {},
   "source": [
    "## 3) Leakage + safety checks\n",
    "\n",
    "- **Leakage** is defined here as an *exact NLQ string match* between train and test.\n",
    "- **Safety** is defined as `SELECT`-only.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f67ed0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap = []\n",
    "non_select = []\n",
    "deduped = []\n",
    "seen = set()\n",
    "\n",
    "for idx, r in enumerate(train_records):\n",
    "    nlq = str(r['nlq']).strip()\n",
    "    sql = str(r['sql']).strip()\n",
    "\n",
    "    if nlq in test_nlqs:\n",
    "        overlap.append((idx, nlq))\n",
    "        continue\n",
    "\n",
    "    if not sql.lower().lstrip().startswith('select'):\n",
    "        non_select.append((idx, nlq, sql[:120]))\n",
    "        continue\n",
    "\n",
    "    key = nlq\n",
    "    if key in seen:\n",
    "        continue\n",
    "    seen.add(key)\n",
    "    deduped.append({'nlq': nlq, 'sql': sql if sql.endswith(';') else sql + ';'})\n",
    "\n",
    "print('Exact NLQ overlaps with test:', len(overlap))\n",
    "print('Non-SELECT rows:', len(non_select))\n",
    "print('After NLQ-dedup:', len(deduped))\n",
    "\n",
    "if overlap[:5]:\n",
    "    print('First overlaps:')\n",
    "    for i, nlq in overlap[:5]:\n",
    "        print('  -', i, nlq)\n",
    "\n",
    "if non_select[:5]:\n",
    "    print('First non-SELECT rows:')\n",
    "    for i, nlq, sql_snip in non_select[:5]:\n",
    "        print('  -', i, nlq, '->', sql_snip)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533d9af2",
   "metadata": {},
   "source": [
    "## 4) Executability validation (VA)\n",
    "\n",
    "This runs each SQL query against the database. A query is considered executable if it runs without raising an exception.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5d93f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "failed = []\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    for idx, r in enumerate(deduped):\n",
    "        sql = r['sql']\n",
    "        try:\n",
    "            # Execute and fetch a tiny sample to force evaluation without pulling huge results.\n",
    "            res = conn.execute(text(sql))\n",
    "            res.fetchmany(1)\n",
    "        except Exception as e:\n",
    "            failed.append((idx, r['nlq'], sql, repr(e)))\n",
    "\n",
    "print('Executable (VA=True):', len(deduped) - len(failed), '/', len(deduped))\n",
    "print('Failed:', len(failed))\n",
    "\n",
    "if failed[:5]:\n",
    "    print('First failures:')\n",
    "    for i, nlq, sql, err in failed[:5]:\n",
    "        print('---')\n",
    "        print('row:', i)\n",
    "        print('nlq:', nlq)\n",
    "        print('sql:', sql)\n",
    "        print('err:', err)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9d585f",
   "metadata": {},
   "source": [
    "## 5) Next step\n",
    "\n",
    "If failures are **0**, proceed to `notebooks/05_qlora_train_eval.ipynb` to fine-tune + evaluate.\n",
    "\n",
    "If there are failures, fix the problematic rows in `data/train/classicmodels_train_200.jsonl` and re-run this notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051cfb21",
   "metadata": {},
   "source": [
    "## 6) Save validation artifacts (local + optional Drive)\n",
    "\n",
    "This exports a compact JSON report to the repo and, when running in Colab with Drive mounted, copies it to Drive so it survives runtime disconnects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a61fa71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timezone\n",
    "from pathlib import Path\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "report = {\n",
    "    \"timestamp_utc\": datetime.now(timezone.utc).strftime(\"%Y-%m-%dT%H:%M:%SZ\"),\n",
    "    \"test_items\": len(test_items),\n",
    "    \"train_items_raw\": len(train_records),\n",
    "    \"train_items_deduped\": len(deduped),\n",
    "    \"overlap_count\": len(overlap),\n",
    "    \"non_select_count\": len(non_select),\n",
    "    \"va_pass_count\": len(deduped) - len(failed),\n",
    "    \"va_fail_count\": len(failed),\n",
    "    \"sample_failures\": [\n",
    "        {\"row\": i, \"nlq\": nlq, \"sql\": sql, \"error\": err}\n",
    "        for i, nlq, sql, err in failed[:5]\n",
    "    ],\n",
    "}\n",
    "\n",
    "local_dir = Path(\"results/training_set_validation\")\n",
    "local_dir.mkdir(parents=True, exist_ok=True)\n",
    "local_report = local_dir / \"validation_report.json\"\n",
    "local_report.write_text(json.dumps(report, indent=2), encoding=\"utf-8\")\n",
    "print(f\"Saved local report: {local_report}\")\n",
    "\n",
    "# Optional Colab Drive backup\n",
    "if Path(\"/content/drive/MyDrive\").exists():\n",
    "    stamp = datetime.now(timezone.utc).strftime(\"%Y%m%d_%H%M%SZ\")\n",
    "    drive_dir = Path(\"/content/drive/MyDrive/nl2sql_persistent_runs/training_set_validation\") / stamp\n",
    "    drive_dir.mkdir(parents=True, exist_ok=True)\n",
    "    drive_report = drive_dir / \"validation_report.json\"\n",
    "    shutil.copy2(local_report, drive_report)\n",
    "    print(f\"Saved Drive backup: {drive_report}\")\n",
    "else:\n",
    "    print(\"Drive not detected at /content/drive/MyDrive (local save completed).\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
