{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cell 1 — Repo clone + clean workspace\n",
        "This cell resets /content and reclones the GitHub repo to guarantee the notebook is running the latest tracked code and data files. This is standard practice in Colab to avoid stale state across sessions (old notebooks, cached files, partial clones) and to make results reproducible"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os, shutil\n",
        "\n",
        "# Reset to a known-good directory\n",
        "os.chdir(\"/content\")\n",
        "\n",
        "# Remove any partial clone\n",
        "repo_dir = \"/content/NLtoSQL\"\n",
        "if os.path.exists(repo_dir):\n",
        "    shutil.rmtree(repo_dir)\n",
        "\n",
        "# Fresh clone\n",
        "!git clone https://github.com/MacKenzieOBrian/NLtoSQL.git \"$repo_dir\"\n",
        "os.chdir(repo_dir)\n",
        "\n",
        "# Sanity checks\n",
        "!git rev-parse --short HEAD\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cell 2 — GCP auth"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "try:\n",
        "    from google.colab import auth\n",
        "except ModuleNotFoundError:\n",
        "    auth = None\n",
        "\n",
        "if auth:\n",
        "    auth.authenticate_user()\n",
        "else:\n",
        "    print(\"Not running in Colab; ensure GCP auth via gcloud/ADC or service account if needed.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cell 3 — Project configuration (env vars / project id)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "\n",
        "project_id = \"modified-enigma-476414-h9\"  # TODO: change or move to env var in production\n",
        "os.environ[\"GOOGLE_CLOUD_PROJECT\"] = project_id\n",
        "\n",
        "print(\"GOOGLE_CLOUD_PROJECT set to:\", os.environ[\"GOOGLE_CLOUD_PROJECT\"])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cell 4 — Install dependencies from requirements.txt\n",
        "\n",
        "This cell installs pinned dependencies so the runtime matches the documented toolchain."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import sys\n",
        "# Prefer installing from pinned requirements.txt for reproducibility\n",
        "!{sys.executable} -m pip install --upgrade pip\n",
        "!{sys.executable} -m pip install -r requirements.txt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cell 5 — Imports & logging setup\n",
        "\n",
        "This cell centralises imports and initialises logging. It’s standard practice to make the execution environment explicit and to ensure later cells can emit consistent, timestamped debug information during DB and model evaluation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "import logging\n",
        "import json\n",
        "from datetime import datetime, timezone\n",
        "from typing import Any, Dict, Optional\n",
        "\n",
        "import pandas as pd\n",
        "import sqlalchemy\n",
        "from sqlalchemy import text\n",
        "from sqlalchemy.engine import Engine\n",
        "\n",
        "from google.cloud.sql.connector import Connector\n",
        "from google.api_core import retry\n",
        "\n",
        "import pymysql\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(\"nl2sql_db\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cell 6 — Connection parameters (prompt for secrets if missing)\n",
        "\n",
        "This cell collects DB connection details securely (e.g., using getpass) if they’re not already provided via environment variables. This is standard practice for notebooks: it prevents credentials being stored in plaintext while keeping the workflow runnable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from getpass import getpass\n",
        "\n",
        "INSTANCE_CONNECTION_NAME = os.getenv(\"INSTANCE_CONNECTION_NAME\")\n",
        "DB_USER = os.getenv(\"DB_USER\")\n",
        "DB_PASS = os.getenv(\"DB_PASS\")\n",
        "DB_NAME = os.getenv(\"DB_NAME\", \"classicmodels\")\n",
        "\n",
        "if not INSTANCE_CONNECTION_NAME:\n",
        "    INSTANCE_CONNECTION_NAME = input(\"Enter INSTANCE_CONNECTION_NAME: \").strip()\n",
        "\n",
        "if not DB_USER:\n",
        "    DB_USER = input(\"Enter DB_USER: \").strip()\n",
        "\n",
        "if not DB_PASS:\n",
        "    DB_PASS = getpass(\"Enter DB_PASS: \")\n",
        "\n",
        "print(\"Using DB:\", DB_NAME)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cell 7 — Cloud SQL connector + SQLAlchemy engine\n",
        "\n",
        "This cell builds a secure DB engine using the Cloud SQL Connector and SQLAlchemy’s creator pattern. It’s standard practice for cloud-hosted databases because it avoids exposing DB endpoints directly and provides a stable interface for executing queries and retrieving schema metadata."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from contextlib import contextmanager\n",
        "\n",
        "connector = Connector()\n",
        "\n",
        "def getconn():\n",
        "    \"\"\"SQLAlchemy creator hook using the Cloud SQL connector.\"\"\"\n",
        "    return connector.connect(\n",
        "        INSTANCE_CONNECTION_NAME,\n",
        "        \"pymysql\",\n",
        "        user=DB_USER,\n",
        "        password=DB_PASS,\n",
        "        db=DB_NAME,\n",
        "    )\n",
        "\n",
        "# Use a creator function so SQLAlchemy delegates connection creation to the connector\n",
        "engine: Engine = sqlalchemy.create_engine(\n",
        "    \"mysql+pymysql://\",\n",
        "    creator=getconn,\n",
        "    future=True\n",
        ")\n",
        "\n",
        "@contextmanager\n",
        "def safe_connection(engine: Engine):\n",
        "    \"\"\"\n",
        "    Context manager that yields a DB connection and ensures it gets closed.\n",
        "    \"\"\"\n",
        "    conn = None\n",
        "    try:\n",
        "        conn = engine.connect()\n",
        "        yield conn\n",
        "    finally:\n",
        "        if conn is not None:\n",
        "            conn.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cell 8 — Schema exploration helpers\n",
        "This cell defines functions to list tables and fetch column metadata from INFORMATION_SCHEMA. Schema introspection is standard in NL→SQL because models need explicit schema grounding; automating extraction avoids manual schema drift and keeps prompts aligned with the live database."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def list_tables(engine: Engine) -> list:\n",
        "    \"\"\"Return a list of table names in the current database.\"\"\"\n",
        "    with safe_connection(engine) as conn:\n",
        "        result = conn.execute(text(\"SHOW TABLES;\")).fetchall()\n",
        "    return [r[0] for r in result]\n",
        "\n",
        "def get_table_columns(engine: Engine, table_name: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Return a DataFrame of columns for a given table.\n",
        "    Includes column name, data type, nullability, and key info.\n",
        "    \"\"\"\n",
        "    query = text(\"\"\"\n",
        "        SELECT COLUMN_NAME, DATA_TYPE, IS_NULLABLE, COLUMN_KEY\n",
        "        FROM INFORMATION_SCHEMA.COLUMNS\n",
        "        WHERE TABLE_SCHEMA = :db AND TABLE_NAME = :table\n",
        "        ORDER BY ORDINAL_POSITION\n",
        "    \"\"\")\n",
        "    with safe_connection(engine) as conn:\n",
        "        df = pd.read_sql(query, conn, params={\"db\": DB_NAME, \"table\": table_name})\n",
        "    return df\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cell 9 — QueryRunner (read-only executor + logging)\n",
        "This cell defines a controlled SQL execution wrapper that blocks destructive statements and logs execution metadata. This is standard in text-to-SQL evaluation: it protects the database, supports VA (validity) measurement, and provides structured error traces for analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class QueryExecutionError(Exception):\n",
        "    pass\n",
        "\n",
        "def now_utc_iso() -> str:\n",
        "    return datetime.now(timezone.utc).isoformat().replace(\"+00:00\", \"Z\")\n",
        "\n",
        "class QueryRunner:\n",
        "    \"\"\"\n",
        "    Execute generated SQL safely against the engine, capture results and metadata,\n",
        "    and keep a history suitable for evaluation and error analysis.\n",
        "    \"\"\"\n",
        "    def __init__(self, engine: Engine, max_rows: int = 1000, forbidden_tokens=None):\n",
        "        self.engine = engine\n",
        "        self.max_rows = max_rows\n",
        "        self.history = []\n",
        "        self.forbidden_tokens = forbidden_tokens or [\n",
        "            \"drop \", \"delete \", \"truncate \", \"alter \", \"create \", \"update \", \"insert \"\n",
        "        ]\n",
        "\n",
        "    def _safety_check(self, sql: str) -> None:\n",
        "        \"\"\"Block obviously destructive statements.\"\"\"\n",
        "        lowered = (sql or \"\").strip().lower()\n",
        "        if not lowered:\n",
        "            raise QueryExecutionError(\"Empty SQL string\")\n",
        "        for token in self.forbidden_tokens:\n",
        "            if token in lowered:\n",
        "                raise QueryExecutionError(f\"Destructive SQL token detected: {token.strip()}\")\n",
        "\n",
        "    def run(\n",
        "        self,\n",
        "        sql: str,\n",
        "        params: Optional[Dict[str, Any]] = None,\n",
        "        capture_df: bool = True,\n",
        "    ) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Execute a SELECT-style query, returning metadata and an optional DataFrame preview.\n",
        "        \"\"\"\n",
        "        entry = {\n",
        "            \"sql\": sql,\n",
        "            \"params\": params,\n",
        "            \"timestamp\": now_utc_iso(),\n",
        "            \"success\": False,\n",
        "            \"rowcount\": 0,\n",
        "            \"exec_time_s\": None,\n",
        "            \"error\": None,\n",
        "            \"columns\": None,\n",
        "            \"result_preview\": None,\n",
        "        }\n",
        "        try:\n",
        "            self._safety_check(sql)\n",
        "            start = datetime.now(timezone.utc)\n",
        "\n",
        "            with safe_connection(self.engine) as conn:\n",
        "                result = conn.execute(sqlalchemy.text(sql), params or {})\n",
        "                rows = result.fetchall()\n",
        "                cols = list(result.keys())\n",
        "\n",
        "            end = datetime.now(timezone.utc)\n",
        "            exec_time = (end - start).total_seconds()\n",
        "\n",
        "            df = None\n",
        "            if capture_df:\n",
        "                df = pd.DataFrame(rows, columns=cols)\n",
        "                if len(df) > self.max_rows:\n",
        "                    df = df.iloc[: self.max_rows]\n",
        "\n",
        "            entry.update({\n",
        "                \"success\": True,\n",
        "                \"rowcount\": min(len(rows), self.max_rows),\n",
        "                \"exec_time_s\": exec_time,\n",
        "                \"columns\": cols,\n",
        "                \"result_preview\": df,\n",
        "            })\n",
        "        except Exception as e:\n",
        "            entry.update({\n",
        "                \"error\": str(e),\n",
        "                \"success\": False,\n",
        "            })\n",
        "        finally:\n",
        "            self.history.append(entry)\n",
        "        return entry\n",
        "\n",
        "    def last(self):\n",
        "        return self.history[-1] if self.history else None\n",
        "\n",
        "    def save_history(self, path: str):\n",
        "        \"\"\"Persist history (without DataFrames) to JSON for later analysis.\"\"\"\n",
        "        serializable = []\n",
        "        for h in self.history:\n",
        "            s = {k: v for k, v in h.items() if k != \"result_preview\"}\n",
        "            serializable.append(s)\n",
        "        with open(path, \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(serializable, f, indent=2, default=str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cell 10 — Smoke tests (DB connectivity + schema)\n",
        "This cell runs minimal “does it work” queries and prints schema samples. Smoke tests are standard practice to verify the experimental apparatus (DB access + schema + executor) before attributing downstream errors to the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def fetch_sample_customers(limit: int = 10) -> pd.DataFrame:\n",
        "    \"\"\"Quick sample query against the customers table.\"\"\"\n",
        "    q = text(\"SELECT customerNumber, customerName, country FROM customers LIMIT :limit;\")\n",
        "    with safe_connection(engine) as conn:\n",
        "        df = pd.read_sql(q, conn, params={\"limit\": limit})\n",
        "    return df\n",
        "\n",
        "try:\n",
        "    tables = list_tables(engine)\n",
        "    logger.info(\"Tables in classicmodels: %s\", tables)\n",
        "\n",
        "    sample_df = fetch_sample_customers(5)\n",
        "    display(sample_df)\n",
        "\n",
        "    # Optionally print each table's schema (comment out if too verbose)\n",
        "    for table_name in tables:\n",
        "        print(f\"\\nSchema for table: {table_name}\")\n",
        "        df_columns = get_table_columns(engine, table_name)\n",
        "        display(df_columns)\n",
        "\n",
        "except Exception as e:\n",
        "    logger.exception(\"Smoke test failed: %s\", e)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cell 11 — Load static NLQ–SQL test set\n",
        "This cell loads the benchmark dataset (classicmodels_test_200.json). Separating dataset loading is standard so evaluation is repeatable and the exact test items are fixed and version-controlled."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "with open(\"data/classicmodels_test_200.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    test_set = json.load(f)\n",
        "\n",
        "print(f\"Loaded {len(test_set)} test items from data/classicmodels_test_200.json\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cell 12 — Optional: validate gold SQL against the live DB\n",
        "This cell executes the gold queries to confirm they all run (e.g., 200/200). This is standard evaluation hygiene: it prevents false negatives in EX/VA caused by incorrect reference SQL or schema mismatches."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from typing import List, Tuple\n",
        "\n",
        "def validate_test_set(path: str = \"data/classicmodels_test_200.json\",\n",
        "                      limit: Optional[int] = None) -> Tuple[list, list]:\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        items = json.load(f)\n",
        "    if limit:\n",
        "        items = items[:limit]\n",
        "\n",
        "    qr_local = QueryRunner(engine, max_rows=200)\n",
        "    successes: List[int] = []\n",
        "    failures: List[Dict[str, Any]] = []\n",
        "\n",
        "    for idx, item in enumerate(items):\n",
        "        meta = qr_local.run(item[\"sql\"], capture_df=False)\n",
        "        if meta[\"success\"]:\n",
        "            successes.append(idx)\n",
        "        else:\n",
        "            failures.append({\n",
        "                \"index\": idx,\n",
        "                \"nlq\": item.get(\"nlq\"),\n",
        "                \"sql\": item.get(\"sql\"),\n",
        "                \"error\": meta[\"error\"],\n",
        "            })\n",
        "\n",
        "    print(f\"Ran {len(items)} queries. Success: {len(successes)}. Failures: {len(failures)}.\")\n",
        "    if failures:\n",
        "        print(\"Failures (first 5):\")\n",
        "        for f in failures[:5]:\n",
        "            print(f)\n",
        "    else:\n",
        "        print(\"All queries succeeded in this run.\")\n",
        "    return successes, failures\n",
        "\n",
        "# Uncomment to run a quick validation (e.g. on first 50)\n",
        "successes, failures = validate_test_set(limit=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cell 13 — Hugging Face authentication\n",
        "\n",
        "This cell authenticates to Hugging Face Hub for model access, especially for gated checkpoints."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cell 14 — Load model + deterministic smoke test\n",
        "This cell loads the LLM once, configures deterministic generation defaults for evaluation, and runs a trivial “OK” test to confirm inference works. Model-load and smoke-test separation is standard practice to ensure later NL→SQL failures are prompt/data issues rather than model/runtime issues.\n",
        "\n",
        "torch: runs the model on GPU and controls “no gradients” mode.\n",
        "\n",
        "*   torch: runs the model on GPU and controls “no gradients” mode.\n",
        "*   transformers: loads the tokenizer + model.\n",
        "*   BitsAndBytesConfig: tells Transformers how to load the model in 4‑bit\n",
        "\n",
        "\n",
        "# Model loading (try 4‑bit, else fallback)\n",
        "The try: block attempts 4‑bit NF4 loading (smaller memory, faster to fit on Colab GPUs).\n",
        "\n",
        "# Deterministic defaults\n",
        "do_sample=False means “don’t roll dice, always pick the most likely next token” (good for repeatable evaluation).\n",
        "\n",
        "num_beams=1 means no beam search (simple deterministic decoding).\n",
        "\n",
        "# Smoke test\n",
        "Builds a tiny chat conversation: system message + user asks for “OK”.\n",
        "\n",
        "\n",
        "*   apply_chat_template(...) formats it the way Llama‑3‑Instruct expects.\n",
        "* torch.no_grad() makes it inference-only (faster, less memory).\n",
        "* model.generate(...) produces up to 3 tokens.\n",
        "\n",
        "We slice out only the newly generated part and decode it, so it prints just OK.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "\n",
        "MODEL_ID = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
        "\n",
        "print(\"Loading tokenizer...\")\n",
        "tok = AutoTokenizer.from_pretrained(MODEL_ID, token=True)\n",
        "if tok.pad_token is None:\n",
        "    tok.pad_token = tok.eos_token\n",
        "\n",
        "# Try 4-bit loading\n",
        "try:\n",
        "    bnb_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_use_double_quant=True,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "    )\n",
        "    print(\"Attempting 4-bit quantized load...\")\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        MODEL_ID,\n",
        "        quantization_config=bnb_config,\n",
        "        torch_dtype=torch.bfloat16,\n",
        "        device_map=\"auto\",\n",
        "        token=True,\n",
        "    )\n",
        "except Exception as e:\n",
        "    print(\"4-bit load failed, falling back to full-precision load.\\nError:\")\n",
        "    print(e)\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        MODEL_ID,\n",
        "        torch_dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float32,\n",
        "        device_map=\"auto\" if torch.cuda.is_available() else None,\n",
        "        token=True,\n",
        "    )\n",
        "\n",
        "print(\"\\nModel loaded!\")\n",
        "print(\"Device:\", next(model.parameters()).device)\n",
        "\n",
        "# Deterministic defaults WITHOUT warnings\n",
        "model.generation_config.do_sample = False\n",
        "model.generation_config.num_beams = 1\n",
        "model.generation_config.temperature = 1.0\n",
        "model.generation_config.top_p = 1.0\n",
        "model.generation_config.top_k = 50\n",
        "\n",
        "# Deterministic smoke test (chat-format + decode only new tokens)\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Reply with only the word OK.\"},\n",
        "]\n",
        "input_ids = tok.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize=True,\n",
        "    add_generation_prompt=True,\n",
        "    return_tensors=\"pt\",\n",
        ").to(model.device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    out = model.generate(\n",
        "        input_ids,\n",
        "        max_new_tokens=3,\n",
        "        do_sample=False,\n",
        "        pad_token_id=tok.eos_token_id,\n",
        "    )\n",
        "\n",
        "gen_ids = out[0][input_ids.shape[-1]:]\n",
        "print(tok.decode(gen_ids, skip_special_tokens=True).strip())\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
