{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No-Model NL to SQL Dataflow Demo\n",
    "\n",
    "This notebook demonstrates the full project dataflow without loading any model weights.\n",
    "\n",
    "What it shows:\n",
    "1. Prompt and message construction.\n",
    "2. Schema-grounded few-shot context assembly.\n",
    "3. SQL extraction from noisy text.\n",
    "4. Raw SQL execution flow (no postprocessing/cleaning).\n",
    "5. Execution checks (VA / EM / EX) on a tiny local SQLite database.\n",
    "6. Retry-style candidate selection loop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "from sqlalchemy import text\n",
    "\n",
    "from nl2sql.core.prompting import SYSTEM_INSTRUCTIONS, make_few_shot_messages\n",
    "from nl2sql.core.llm import debug_extract_first_select\n",
    "from nl2sql.core.query_runner import QueryRunner\n",
    "from nl2sql.evaluation.eval import execution_accuracy\n",
    "\n",
    "print(\"Imports ready. No model loaded.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Pick a realistic question and show dataset context\n",
    "\n",
    "We use one NLQ from your benchmark for context, then run a local demo NLQ that can execute on a tiny in-memory SQLite DB.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_test_set() -> list[dict]:\n",
    "    candidates = [\n",
    "        Path(\"data/classicmodels_test_200.json\"),\n",
    "        Path(\"../data/classicmodels_test_200.json\"),\n",
    "    ]\n",
    "    for p in candidates:\n",
    "        if p.exists():\n",
    "            return json.loads(p.read_text(encoding=\"utf-8\"))\n",
    "    raise FileNotFoundError(\"Could not locate classicmodels_test_200.json\")\n",
    "\n",
    "\n",
    "benchmark = _load_test_set()\n",
    "benchmark_item = benchmark[0]\n",
    "\n",
    "demo_nlq = \"List all customer names in France\"\n",
    "demo_gold_sql = \"SELECT customerName FROM customers WHERE country = 'France';\"\n",
    "\n",
    "print(\"Benchmark sample NLQ:\", benchmark_item[\"nlq\"])\n",
    "print(\"Benchmark sample SQL:\", benchmark_item[\"sql\"])\n",
    "print(\"\\nLocal demo NLQ:\", demo_nlq)\n",
    "print(\"Local demo gold SQL:\", demo_gold_sql)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Build schema summary and few-shot messages\n",
    "\n",
    "This is the same message-building flow your real pipeline uses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCHEMA_SUMMARY_DEMO = (\n",
    "# demo schema is intentionally tiny/synthetic so each pipeline stage is easy to see.\n",
    "    \"Table customers (\\n\"\n",
    "    \"  customerNumber INT,\\n\"\n",
    "    \"  customerName TEXT,\\n\"\n",
    "    \"  contactLastName TEXT,\\n\"\n",
    "    \"  country TEXT,\\n\"\n",
    "    \"  creditLimit REAL\\n\"\n",
    "    \")\\n\"\n",
    "    \"Table orders (\\n\"\n",
    "    \"  orderNumber INT,\\n\"\n",
    "    \"  customerNumber INT,\\n\"\n",
    "    \"  orderDate TEXT,\\n\"\n",
    "    \"  status TEXT\\n\"\n",
    "    \")\"\n",
    ")\n",
    "\n",
    "exemplars = [\n",
    "    {\n",
    "        \"nlq\": \"List all customer names in Germany\",\n",
    "        \"sql\": \"SELECT customerName FROM customers WHERE country = 'Germany';\",\n",
    "    },\n",
    "    {\n",
    "        \"nlq\": \"Show customer names and credit limit for customers in France\",\n",
    "        \"sql\": \"SELECT customerName, creditLimit FROM customers WHERE country = 'France';\",\n",
    "    },\n",
    "]\n",
    "\n",
    "messages = make_few_shot_messages(\n",
    "    schema=SCHEMA_SUMMARY_DEMO,\n",
    "    exemplars=exemplars,\n",
    "    nlq=demo_nlq,\n",
    ")\n",
    "\n",
    "print(\"System prompt starts with:\")\n",
    "print(SYSTEM_INSTRUCTIONS.splitlines()[0])\n",
    "print(\"\\nMessage count:\", len(messages))\n",
    "for i, m in enumerate(messages, start=1):\n",
    "    snippet = str(m[\"content\"]).replace(\"\\n\", \" \")[:140]\n",
    "    print(f\"[{i}] {m['role']}: {snippet}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Add a tiny SQL normalizer for EM reporting\n",
    "\n",
    "This is only for text comparison. It does not edit generated SQL before execution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_sql_norm(sql: str) -> str:\n",
    "    # keep this tiny: lowercase + collapse whitespace + strip trailing semicolon\n",
    "    return \" \".join((sql or \"\").strip().rstrip(\";\").split()).lower()\n",
    "\n",
    "print(\"EM normalizer ready:\", simple_sql_norm(\"SELECT customerName FROM customers;\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Create a tiny local database (no cloud DB needed)\n",
    "\n",
    "This lets us demonstrate VA/EM/EX with real SQL execution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = sqlalchemy.create_engine(\"sqlite+pysqlite:///:memory:\", future=True)\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    conn.execute(text(\"\"\"\n",
    "        CREATE TABLE customers (\n",
    "            customerNumber INTEGER PRIMARY KEY,\n",
    "            customerName TEXT,\n",
    "            contactLastName TEXT,\n",
    "            country TEXT,\n",
    "            creditLimit REAL\n",
    "        )\n",
    "    \"\"\"))\n",
    "\n",
    "    conn.execute(text(\"\"\"\n",
    "        CREATE TABLE orders (\n",
    "            orderNumber INTEGER PRIMARY KEY,\n",
    "            customerNumber INTEGER,\n",
    "            orderDate TEXT,\n",
    "            status TEXT\n",
    "        )\n",
    "    \"\"\"))\n",
    "\n",
    "    conn.execute(text(\"\"\"\n",
    "        INSERT INTO customers (customerNumber, customerName, contactLastName, country, creditLimit) VALUES\n",
    "        (103, 'Atelier graphique', 'Schmitt', 'France', 21000.00),\n",
    "        (112, 'Signal Gift Stores', 'King', 'USA', 71800.00),\n",
    "        (119, 'La Rochelle Gifts', 'Labrune', 'France', 118200.00),\n",
    "        (121, 'Baane Mini Imports', 'Petersen', 'Denmark', 81700.00)\n",
    "    \"\"\"))\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    preview = pd.read_sql(\n",
    "        text(\"SELECT customerNumber, customerName, country FROM customers ORDER BY customerNumber\"),\n",
    "        conn,\n",
    "    )\n",
    "\n",
    "print(\"Local DB preview:\")\n",
    "display(preview)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Simulate raw model outputs and run extraction debug\n",
    "\n",
    "We include one broken candidate and one noisy but executable candidate.\n",
    "No SQL cleaning is applied after extraction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_generations = [\n",
    "    \"\"\"\n",
    "I think the answer is:\n",
    "SELECT customerName, customerNumber\n",
    "FROM customer\n",
    "WHERE country = 'France'\n",
    "ORDER BY customerName DESC\n",
    "LIMIT 5;\n",
    "\"\"\",\n",
    "    \"\"\"\n",
    "Here is SQL:\n",
    "```sql\n",
    "SELECT customerName, customerNumber\n",
    "FROM customers\n",
    "WHERE country = 'France'\n",
    "ORDER BY customerName DESC\n",
    "LIMIT 5;\n",
    "```\n",
    "\"\"\",\n",
    "]\n",
    "\n",
    "for i, raw in enumerate(raw_generations, start=1):\n",
    "    print(\"\\n\" + \"=\" * 90)\n",
    "    print(f\"RAW CANDIDATE {i}\")\n",
    "    print(raw.strip())\n",
    "\n",
    "    extract_debug = debug_extract_first_select(raw)\n",
    "    extracted_sql = extract_debug.get(\"selected_sql\") or raw\n",
    "\n",
    "    print(\"\\nExtraction candidates:\")\n",
    "    for cand in extract_debug.get(\"candidates\", []):\n",
    "        print(\n",
    "            \"- accepted=\", cand.get(\"accepted\"),\n",
    "            \"reject_reason=\", cand.get(\"reject_reason\"),\n",
    "            \"from_target=\", cand.get(\"from_target\"),\n",
    "        )\n",
    "        print(\"  sql:\", cand.get(\"candidate_sql\"))\n",
    "\n",
    "    print(\"\\nSelected SQL (sent directly to evaluator, no cleaning):\")\n",
    "    print(extracted_sql)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Evaluate candidates like a mini regen loop\n",
    "\n",
    "- VA: query executes\n",
    "- EM: simple normalized SQL text equals gold SQL\n",
    "- EX: execution result equals gold result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qr = QueryRunner(engine, max_rows=50)\n",
    "attempt_rows: list[dict] = []\n",
    "\n",
    "for i, raw in enumerate(raw_generations, start=1):\n",
    "    extract_debug = debug_extract_first_select(raw)\n",
    "    pred_sql = extract_debug.get(\"selected_sql\") or raw\n",
    "\n",
    "    va_meta = qr.run(pred_sql, capture_df=False)\n",
    "    em = simple_sql_norm(pred_sql) == simple_sql_norm(demo_gold_sql)\n",
    "    ex, ex_pred_err, ex_gold_err = execution_accuracy(\n",
    "        engine=engine,\n",
    "        pred_sql=pred_sql,\n",
    "        gold_sql=demo_gold_sql,\n",
    "    )\n",
    "\n",
    "    attempt_rows.append(\n",
    "        {\n",
    "            \"attempt\": i,\n",
    "            \"pred_sql\": pred_sql,\n",
    "            \"va\": int(bool(va_meta.success)),\n",
    "            \"em\": int(bool(em)),\n",
    "            \"ex\": int(bool(ex)),\n",
    "            \"error\": va_meta.error or ex_pred_err,\n",
    "            \"gold_error\": ex_gold_err,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    if bool(va_meta.success) and bool(ex):\n",
    "        break\n",
    "\n",
    "report_df = pd.DataFrame(attempt_rows)\n",
    "display(report_df)\n",
    "\n",
    "if not report_df.empty:\n",
    "    final_row = report_df.iloc[-1].to_dict()\n",
    "    print(\"Selected final attempt:\", final_row[\"attempt\"])\n",
    "    print(\"Selected SQL:\", final_row[\"pred_sql\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Explicit-field example in raw mode (no cleaning)\n",
    "\n",
    "This shows what happens when generated SQL is executable but does not follow requested field order.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explicit_nlq = \"List contact last name, customer name, and customer number for customers in France\"\n",
    "explicit_gold_sql = \"SELECT contactLastName, customerName, customerNumber FROM customers WHERE country = 'France';\"\n",
    "\n",
    "explicit_raw = \"\"\"\n",
    "SELECT customerName, creditLimit, customerNumber, contactLastName\n",
    "FROM customers\n",
    "WHERE country = 'France'\n",
    "ORDER BY customerName\n",
    "\"\"\"\n",
    "\n",
    "explicit_extract = debug_extract_first_select(explicit_raw)\n",
    "explicit_pred_sql = explicit_extract.get(\"selected_sql\") or explicit_raw\n",
    "\n",
    "print(\"NLQ:\", explicit_nlq)\n",
    "print(\"\\nRaw selected SQL (no cleaning):\")\n",
    "print(explicit_pred_sql)\n",
    "\n",
    "explicit_qr = QueryRunner(engine, max_rows=50)\n",
    "explicit_meta = explicit_qr.run(explicit_pred_sql, capture_df=False)\n",
    "explicit_em = simple_sql_norm(explicit_pred_sql) == simple_sql_norm(explicit_gold_sql)\n",
    "explicit_ex, explicit_pred_err, explicit_gold_err = execution_accuracy(\n",
    "    engine=engine,\n",
    "    pred_sql=explicit_pred_sql,\n",
    "    gold_sql=explicit_gold_sql,\n",
    ")\n",
    "\n",
    "print(\"\\nMetrics in raw mode:\")\n",
    "print(\n",
    "    {\n",
    "        \"va\": int(bool(explicit_meta.success)),\n",
    "        \"em\": int(bool(explicit_em)),\n",
    "        \"ex\": int(bool(explicit_ex)),\n",
    "        \"pred_error\": explicit_meta.error or explicit_pred_err,\n",
    "        \"gold_error\": explicit_gold_err,\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Done\n",
    "\n",
    "You can now present the architecture without loading model weights:\n",
    "- Prompting API\n",
    "- SQL extraction\n",
    "- Raw SQL execution gate and scoring loop\n",
    "- Raw explicit-field example (no cleaning layer)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
