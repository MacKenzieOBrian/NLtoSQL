{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64f2b652",
   "metadata": {},
   "source": [
    "# Agentic Evaluation (ReAct-style)\n",
    "\n",
    "This notebook adds a minimal ReAct-style loop for NL→SQL. It reuses the same benchmark (`data/classicmodels_test_200.json`) and metrics (VA/EX/EM; TS planned) to measure gains over prompt-only and QLoRA runs.\n",
    "\n",
    "Plan (step-by-step):\n",
    "1) Clone repo (Colab) + install deps\n",
    "2) Environment + DB connection\n",
    "3) Load schema summary + test set\n",
    "4) Load model (base or QLoRA adapters)\n",
    "5) Define ReAct prompt + loop (Thought → Action → Observation → Refinement)\n",
    "6) Run evaluation (VA/EX/EM) and save to `results/agent/…`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c44350",
   "metadata": {},
   "source": [
    "Docs I leaned on: HF Transformers quantization (https://huggingface.co/docs/transformers/main_classes/quantization), PEFT/TRL (https://huggingface.co/docs/peft/, https://huggingface.co/docs/trl/), Cloud SQL connector + SQLAlchemy creator (https://cloud.google.com/sql/docs/mysql/connect-run, https://docs.sqlalchemy.org/en/20/core/engines.html#custom-dbapi-connect), ReAct (https://arxiv.org/abs/2210.03629)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faade3c2",
   "metadata": {},
   "source": [
    "## Setup (run first, then restart)\n",
    "In a fresh Colab GPU runtime, run this one cell to clean preinstalls and pin the CUDA 12.1 torch/bitsandbytes/triton stack. When it finishes, **Runtime → Restart runtime**, then run the rest of the notebook from the clone cell onward without more restarts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79779a6",
   "metadata": {},
   "source": [
    "**Docs (setup):** HF Transformers quantization + BitsAndBytes (4-bit) https://huggingface.co/docs/transformers/main_classes/quantization, bnb https://github.com/TimDettmers/bitsandbytes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b144d3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%%bash\n",
    "set -e\n",
    "export PIP_DEFAULT_TIMEOUT=120\n",
    "\n",
    "# Clean conflicting preinstalls\n",
    "pip uninstall -y torch torchvision torchaudio bitsandbytes triton transformers accelerate peft trl datasets numpy pandas fsspec requests google-auth || true\n",
    "\n",
    "# Base deps\n",
    "pip install -q --no-cache-dir --force-reinstall   numpy==1.26.4 pandas==2.2.1 fsspec==2024.5.0 requests==2.31.0 google-auth==2.43.0\n",
    "\n",
    "# Torch + CUDA 12.1\n",
    "pip install -q --no-cache-dir --force-reinstall   torch==2.3.1+cu121 torchvision==0.18.1+cu121 torchaudio==2.3.1+cu121   --index-url https://download.pytorch.org/whl/cu121\n",
    "\n",
    "# bitsandbytes + triton + HF stack\n",
    "pip install -q --no-cache-dir --force-reinstall   bitsandbytes==0.43.3 triton==2.3.1   transformers==4.44.2 accelerate==0.33.0 peft==0.17.0 trl==0.9.6 datasets==2.20.0\n",
    "\n",
    "echo \"Setup complete. Restart runtime once, then run the rest of the notebook top-to-bottom.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133b0b11",
   "metadata": {},
   "source": [
    "Model load: HF 4-bit NF4 + BitsAndBytes; deterministic decoding. If adapters exist, we load them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47936fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0) Clone repo (Colab) + install deps\n",
    "import os\n",
    "try:\n",
    "    import google.colab  # noqa: F401\n",
    "    IN_COLAB = True\n",
    "except Exception:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    if not os.path.exists('/content/NLtoSQL'):\n",
    "        !git clone https://github.com/MacKenzieOBrian/NLtoSQL.git /content/NLtoSQL\n",
    "    %cd /content/NLtoSQL\n",
    "    !pip -q install -r requirements.txt\n",
    "    import torch, transformers, accelerate, peft\n",
    "    print('torch', torch.__version__, 'cuda', torch.cuda.is_available())\n",
    "else:\n",
    "    print('Not in Colab; using existing workspace')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24721f1",
   "metadata": {},
   "source": [
    "Prompt/eval: build prompts (system+schema+k exemplars), generate SQL, postprocess, and compute VA/EX/EM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5b7e43",
   "metadata": {},
   "source": [
    "**Ref:** Colab clone/install pattern; keeps notebooks thin and code in `nl2sql/`. Hugging Face/Colab standard workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20974344",
   "metadata": {},
   "source": [
    "### Reference notes (what this builds on)\n",
    "- DB access: Cloud SQL Connector + SQLAlchemy creator (GCP docs: https://cloud.google.com/sql/docs/mysql/connect-run) for secure pooled ClassicModels access.\n",
    "- Schema/prompting: uses repo helpers (`nl2sql.schema`, `prompting`) aligned with schema-grounded NL→SQL prompting (survey: https://arxiv.org/abs/2410.06011).\n",
    "- Model load: HF Transformers 4-bit NF4 with BitsAndBytes (quantization docs: https://huggingface.co/docs/transformers/main_classes/quantization), same pattern as QLoRA.\n",
    "- Agent loop: ReAct-style Thought→Action→Observation→Refinement, inspired by Yao et al. 2023 (https://arxiv.org/abs/2210.03629) and agentic NL→SQL in Ojuri et al. 2025.\n",
    "- Eval: repo harness (`nl2sql.eval`, `QueryRunner`) for VA/EX/EM; TS planned.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f75fce",
   "metadata": {},
   "source": [
    "## Optional: use gcloud ADC (without a key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523ff993",
   "metadata": {},
   "source": [
    "**Ref:** GCP ADC flow (docs: https://cloud.google.com/docs/authentication/provide-credentials-adc). Optional fallback if no service account JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af27263f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this only if you prefer gcloud-based ADC (no JSON key)\n",
    "try:\n",
    "    import google.colab  # noqa: F401\n",
    "    IN_COLAB = True\n",
    "except Exception:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    %pip install -q --upgrade google-auth google-auth-oauthlib\n",
    "    !gcloud auth application-default login\n",
    "else:\n",
    "    print(\"Not in Colab; skip gcloud auth.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21847187",
   "metadata": {},
   "source": [
    "**Ref:** Pinned CUDA12.1 torch/bitsandbytes/triton stack per HF/BnB guidance for 4-bit loads on Colab GPUs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5528bc3a",
   "metadata": {},
   "source": [
    "**Ref:** Cloud SQL Connector + SQLAlchemy creator (GCP MySQL docs: https://cloud.google.com/sql/docs/mysql/connect-run) for secure ClassicModels access."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e745f2",
   "metadata": {},
   "source": [
    "**Docs (auth/DB):** Cloud SQL connector pattern https://cloud.google.com/sql/docs/mysql/connect-run; SQLAlchemy creator hook https://docs.sqlalchemy.org/en/20/core/engines.html#custom-dbapi-connect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8d87f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1) Environment + DB\n",
    "import os\n",
    "from getpass import getpass\n",
    "from pathlib import Path\n",
    "\n",
    "from google.cloud.sql.connector import Connector\n",
    "from google.oauth2.service_account import Credentials\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.engine import Engine\n",
    "\n",
    "# Expected env vars (set these in a Colab cell):\n",
    "# GOOGLE_APPLICATION_CREDENTIALS=/content/sa.json\n",
    "# INSTANCE_CONNECTION_NAME, DB_USER, DB_PASS, DB_NAME\n",
    "INSTANCE_CONNECTION_NAME = os.getenv(\"INSTANCE_CONNECTION_NAME\")\n",
    "DB_USER = os.getenv(\"DB_USER\")\n",
    "DB_PASS = os.getenv(\"DB_PASS\")\n",
    "DB_NAME = os.getenv(\"DB_NAME\") or \"classicmodels\"\n",
    "GOOGLE_CREDS = os.getenv(\"GOOGLE_APPLICATION_CREDENTIALS\")\n",
    "\n",
    "if not INSTANCE_CONNECTION_NAME:\n",
    "    INSTANCE_CONNECTION_NAME = input(\"Enter INSTANCE_CONNECTION_NAME: \").strip()\n",
    "if not DB_USER:\n",
    "    DB_USER = input(\"Enter DB_USER: \").strip()\n",
    "if not DB_PASS:\n",
    "    DB_PASS = getpass(\"Enter DB_PASS: \")\n",
    "\n",
    "creds = None\n",
    "if GOOGLE_CREDS:\n",
    "    creds = Credentials.from_service_account_file(GOOGLE_CREDS)\n",
    "    print(f\"Using service account from {GOOGLE_CREDS}\")\n",
    "else:\n",
    "    print(\"Using default ADC (gcloud auth or Colab auth). If this fails, set GOOGLE_APPLICATION_CREDENTIALS.\")\n",
    "\n",
    "connector = Connector(credentials=creds)\n",
    "\n",
    "def getconn():\n",
    "    return connector.connect(\n",
    "        INSTANCE_CONNECTION_NAME,\n",
    "        \"pymysql\",\n",
    "        user=DB_USER,\n",
    "        password=DB_PASS,\n",
    "        db=DB_NAME,\n",
    "    )\n",
    "\n",
    "engine: Engine = create_engine(\n",
    "    \"mysql+pymysql://\",\n",
    "    creator=getconn,\n",
    "    future=True,\n",
    ")\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(\"SELECT 1\"))\n",
    "print(\"DB connection OK\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a583e16",
   "metadata": {},
   "source": [
    "**Ref:** Schema helper in `nl2sql.schema`; schema-grounded prompting per NL→SQL survey (https://arxiv.org/abs/2410.06011)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7620ff8",
   "metadata": {},
   "source": [
    "**Docs (schema prompts):** NL→SQL schema-grounded prompting survey https://arxiv.org/abs/2410.06011; Spider-style listings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1c88d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Load schema summary + test set (small slice for now)\n",
    "import json\n",
    "from nl2sql.schema import build_schema_summary\n",
    "\n",
    "SCHEMA_SUMMARY = build_schema_summary(engine, db_name=DB_NAME)\n",
    "\n",
    "test_path = Path(\"data/classicmodels_test_200.json\")\n",
    "full_set = json.loads(test_path.read_text(encoding=\"utf-8\"))\n",
    "# default to a small slice while debugging\n",
    "test_set = full_set[:5]\n",
    "print(\"Demo items:\", len(test_set))\n",
    "# For full run, switch to: test_set = full_set; print(\"Test items:\", len(test_set))\n",
    "\n",
    "TABLES = {line.split('(', 1)[0].strip() for line in SCHEMA_SUMMARY.splitlines() if '(' in line}\n",
    "TABLES_LOWER = {t.lower(): t for t in TABLES}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700fe5c2",
   "metadata": {},
   "source": [
    "**Ref:** HF Transformers 4-bit NF4 + BitsAndBytes (quantization docs: https://huggingface.co/docs/transformers/main_classes/quantization); adapters via PEFT."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd92a2b8",
   "metadata": {},
   "source": [
    "**Docs (model load):** HF 4-bit NF4 quantization https://huggingface.co/docs/transformers/main_classes/quantization; PEFT/QLoRA https://huggingface.co/docs/peft/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f38fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3) Load model (base or QLoRA adapters)\n",
    "import os\n",
    "from getpass import getpass\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from peft import PeftModel\n",
    "\n",
    "MODEL_ID = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "ADAPTER_PATH = os.getenv(\"ADAPTER_PATH\") or \"results/adapters/qlora_classicmodels\"  # set to None to use base model\n",
    "\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\") or os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "if not HF_TOKEN:\n",
    "    HF_TOKEN = getpass(\"Enter HF_TOKEN (https://huggingface.co/settings/tokens): \").strip()\n",
    "\n",
    "cc_major, cc_minor = torch.cuda.get_device_capability(0) if torch.cuda.is_available() else (0, 0)\n",
    "use_bf16 = cc_major >= 8\n",
    "compute_dtype = torch.bfloat16 if use_bf16 else torch.float16\n",
    "print(\"GPU:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\")\n",
    "print(\"Using bf16:\", use_bf16)\n",
    "print(\"Adapter path:\", ADAPTER_PATH)\n",
    "\n",
    "# Tokenizer\n",
    "tok = AutoTokenizer.from_pretrained(MODEL_ID, token=HF_TOKEN)\n",
    "if tok.pad_token is None:\n",
    "    tok.pad_token = tok.eos_token\n",
    "\n",
    "# Quantized base model\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    ")\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    quantization_config=bnb_config,\n",
    "    torch_dtype=compute_dtype,\n",
    "    device_map={\"\": 0} if torch.cuda.is_available() else None,\n",
    "    token=HF_TOKEN,\n",
    ")\n",
    "base_model.generation_config.do_sample = False\n",
    "base_model.generation_config.temperature = 1.0\n",
    "base_model.generation_config.top_p = 1.0\n",
    "\n",
    "# Load adapters if present locally; otherwise use base model\n",
    "adapter_dir = Path(ADAPTER_PATH) if ADAPTER_PATH else None\n",
    "if adapter_dir and adapter_dir.exists():\n",
    "    model = PeftModel.from_pretrained(base_model, adapter_dir, token=HF_TOKEN)\n",
    "    print(\"Loaded adapters from\", adapter_dir)\n",
    "else:\n",
    "    print(\"Adapter path missing; using base model only. Set ADAPTER_PATH to your local adapter folder or upload it to Colab.\")\n",
    "    model = base_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afb59ed",
   "metadata": {},
   "source": [
    "## Optional adapter sanity check (run before ReAct)\n",
    "Quick check to see if the loaded model/adapters produce valid SQL on a tiny slice. Uses the prompt harness (k=0/k=3) and executes the SQL to report VA/EX."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db24b08d",
   "metadata": {},
   "source": [
    "**Docs (prompt/eval):** ICL patterns https://arxiv.org/abs/2005.14165; execution-based metrics (VA/EX) https://aclanthology.org/2020.emnlp-main.29/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fbae86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nl2sql.prompting import make_few_shot_messages\n",
    "from nl2sql.llm import extract_first_select\n",
    "from nl2sql.postprocess import guarded_postprocess\n",
    "from nl2sql.query_runner import QueryRunner\n",
    "from nl2sql.eval import execution_accuracy\n",
    "\n",
    "runner_check = QueryRunner(engine)\n",
    "# reuse existing test_set (default small slice); pick 3 exemplars\n",
    "exemplars = test_set[:3]\n",
    "\n",
    "def run_quick_check(k: int = 0, limit: int = 3):\n",
    "    print(f\"Quick check k={k}\")\n",
    "    for sample in test_set[:limit]:\n",
    "        shots = exemplars if k > 0 else []\n",
    "        msgs = make_few_shot_messages(\n",
    "            schema=SCHEMA_SUMMARY,\n",
    "            exemplars=shots,\n",
    "            nlq=sample['nlq'],\n",
    "        )\n",
    "        prompt_preview = tok.apply_chat_template(msgs, tokenize=False, add_generation_prompt=True)\n",
    "        inputs = tok(prompt_preview, return_tensors=\"pt\").to(model.device)\n",
    "        out = model.generate(**inputs, max_new_tokens=256, do_sample=False)\n",
    "\n",
    "        # strip the prompt before decoding the generation\n",
    "        gen_ids = out[0][inputs.input_ids.shape[-1]:]\n",
    "        text = tok.decode(gen_ids, skip_special_tokens=True)\n",
    "\n",
    "        raw_sql = extract_first_select(text) or text\n",
    "        sql = guarded_postprocess(raw_sql, sample['nlq'])\n",
    "\n",
    "        meta = runner_check.run(sql, capture_df=False)\n",
    "        va = meta.success\n",
    "        ex_ok, _, _ = execution_accuracy(engine=engine, pred_sql=sql, gold_sql=sample['sql'])\n",
    "        print(f\"Q: {sample['nlq']}\n",
    "SQL: {sql}\n",
    "VA: {va} EX: {ex_ok}\n",
    "\")\n",
    "\n",
    "run_quick_check(k=0)\n",
    "run_quick_check(k=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d3d737",
   "metadata": {},
   "source": [
    "**Ref:** ReAct pattern (Yao et al. 2023: https://arxiv.org/abs/2210.03629) adapted for NL→SQL with `QueryRunner` as the Act step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d2d11f",
   "metadata": {},
   "source": [
    "**Docs (ReAct):** ReAct loop (Yao et al. 2023) https://arxiv.org/abs/2210.03629; safe Act via SELECT-only executor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84ff33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Helper imports (ReAct helpers live in nl2sql/agent_utils)\n",
    "from nl2sql.agent_utils import (\n",
    "    clean_candidate,\n",
    "    build_tabular_prompt,\n",
    "    vanilla_candidate,\n",
    "    classify_error,\n",
    "    error_hint,\n",
    "    semantic_score,\n",
    "    count_select_columns,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd0973b",
   "metadata": {},
   "source": [
    "### Agent status (for dissertation)\n",
    "Current loop = execution-guided reranker: sampled candidates, SELECT-only filter, semantic rerank, error-classified repair, deterministic few-shot fallback.\n",
    "Not yet full ReAct: we don’t enforce structured `Thought / Action: SCHEMA_LOOKUP[...] / Action: EXEC_SQL[...] / Observation: ... / FINISH[...]`, so the model isn’t forced to read and react to its own Observations.\n",
    "Planned upgrade (if time permits): add an explicit tool grammar and feed Observations back into the prompt so the model can revise after execution errors (Yao et al., 2023).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f13e02a",
   "metadata": {},
   "source": [
    "**Ref:** Repo eval (`nl2sql.eval`) for VA/EX/EM; execution-based metrics align with Ojuri et al. 2025 and EMNLP’20 TS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52889a3",
   "metadata": {},
   "source": [
    "**Docs (prompt/eval):** ICL patterns https://arxiv.org/abs/2005.14165; execution-based metrics (VA/EX) https://aclanthology.org/2020.emnlp-main.29/."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9001e3",
   "metadata": {},
   "source": [
    "## ReAct execution-guided pipeline (best version so far)\n",
    "These cells mirror the committed helper layer (`nl2sql/agent_utils.py`) and set up the current execution-guided reranker + evaluation harness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe76f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Schema summary + test set + QueryRunner\n",
    "import json\n",
    "from pathlib import Path\n",
    "from nl2sql.schema import build_schema_summary\n",
    "from nl2sql.query_runner import QueryRunner\n",
    "\n",
    "DB_NAME = os.getenv(\"DB_NAME\") or \"classicmodels\"\n",
    "\n",
    "SCHEMA_SUMMARY = build_schema_summary(engine, db_name=DB_NAME)\n",
    "test_path = Path(\"data/classicmodels_test_200.json\")\n",
    "full_set = json.loads(test_path.read_text(encoding=\"utf-8\"))\n",
    "test_set = full_set  # change to full_set[:20] when debugging\n",
    "\n",
    "print(\"Loaded test set size:\", len(test_set))\n",
    "runner = QueryRunner(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b07b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Agent utilities: semantic reranker, baseline candidate, error taxonomy\n",
    "from nl2sql.agent_utils import (\n",
    "    clean_candidate,\n",
    "    build_tabular_prompt,\n",
    "    vanilla_candidate,\n",
    "    classify_error,\n",
    "    error_hint,\n",
    "    semantic_score,\n",
    "    count_select_columns,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8952b8ec",
   "metadata": {},
   "source": [
    "## Staged Debugging Guide (read this first)\n",
    "\n",
    "This notebook uses **stages** to avoid over‑engineering before SQL is stable.\n",
    "\n",
    "**How to run:**\n",
    "1. Set `STAGE = 0` (in cell #6). Run cells in order.\n",
    "2. Use the quick sanity check (cell #8). If **PRED is empty**, stop and inspect trace summaries.\n",
    "3. Only move to the next stage after the current one is stable.\n",
    "\n",
    "**Stages**\n",
    "- **STAGE 0 — Minimal execution‑gated**: generate → extract SQL → execute → return first valid.\n",
    "- **STAGE 1 — + Clamps**: strip ORDER/LIMIT unless requested; trim projections for list queries.\n",
    "- **STAGE 2 — + Rerank & diversity**: tabular prompt + semantic score.\n",
    "- **STAGE 3 — + Repair**: one‑shot repair using DB error hints.\n",
    "\n",
    "**Where failures show up**\n",
    "- *Rejected: not a clean SELECT* → model output is noisy; check raw candidates.\n",
    "- *No clean candidates* → filters too strict or model not outputting SQL.\n",
    "- *ERROR: ...* → SQL parsed but failed execution; fix joins or columns.\n",
    "\n",
    "**Debug checklist**\n",
    "- Ensure cell #6 ran after any edits (defines STAGE + helper funcs).\n",
    "- Confirm `STAGE` in quick check output.\n",
    "- If `PRED` is empty at STAGE 0, temporarily bypass filters and inspect raw output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fed5d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Helper: staged controls + candidate generation + error-aware repair\n",
    "import re\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import StoppingCriteria, StoppingCriteriaList\n",
    "import sqlparse\n",
    "from sqlparse.sql import IdentifierList, Identifier\n",
    "from sqlparse.tokens import Keyword, DML\n",
    "\n",
    "from nl2sql.llm import extract_first_select\n",
    "from nl2sql.postprocess import guarded_postprocess\n",
    "import nl2sql.agent_utils as agent_utils_mod  # for monkey-patching cleaner\n",
    "\n",
    "transformers.logging.set_verbosity_error()\n",
    "if tok.pad_token is None:\n",
    "    tok.pad_token = tok.eos_token\n",
    "\n",
    "# ----- Stage controls -----\n",
    "STAGE = 1  # 0=minimal, 1=+clamps, 2=+rerank+tabular+sampling, 3=+repair\n",
    "USE_CLAMPS = STAGE >= 1\n",
    "USE_RERANK = STAGE >= 2\n",
    "USE_TABULAR_PROMPT = STAGE >= 2\n",
    "USE_SAMPLING = STAGE >= 2\n",
    "USE_REPAIR = STAGE >= 3\n",
    "\n",
    "# ----- Debug controls -----\n",
    "DEBUG = True\n",
    "DEBUG_RAW = False          # print raw candidates (noisy)\n",
    "DEBUG_REJECT_SAMPLE = 2\n",
    "\n",
    "# ---------- generation stop (first semicolon) ----------\n",
    "class StopOnSemicolon(StoppingCriteria):\n",
    "    def __init__(self, tokenizer):\n",
    "        self.tok = tokenizer\n",
    "        self.semi_id = tokenizer.encode(\";\", add_special_tokens=False)[-1]\n",
    "\n",
    "    def __call__(self, input_ids, scores, **kwargs):\n",
    "        return input_ids[0, -1].item() == self.semi_id\n",
    "\n",
    "# ---------- keyword normaliser ----------\n",
    "def _normalize_spaced_keywords(text: str) -> str:\n",
    "    keywords = [\n",
    "        \"select\", \"from\", \"where\", \"group\", \"by\", \"order\", \"limit\",\n",
    "        \"join\", \"inner\", \"left\", \"right\", \"on\", \"having\", \"distinct\",\n",
    "    ]\n",
    "    for kw in keywords:\n",
    "        pattern = r\"\b\" + r\"\\s*\".join(list(kw)) + r\"\b\"\n",
    "        text = re.sub(pattern, kw.upper(), text, flags=re.I)\n",
    "    return text\n",
    "\n",
    "# ---------- shared core cleaner (trim prompt echo, relaxed) ----------\n",
    "ECHO_CUTOFF_RE = re.compile(r\"(?is)\\b(show step|show output|output only|respond with|no markdown|no explanation|y/n)\\b\")\n",
    "\n",
    "def strip_prompt_echo(sql: str) -> str:\n",
    "    m = ECHO_CUTOFF_RE.search(sql or \"\")\n",
    "    if not m:\n",
    "        return sql\n",
    "    return (sql[:m.start()]).strip()\n",
    "\n",
    "def _clean_candidate_core(raw: str):\n",
    "    \"\"\"\n",
    "    Returns (sql_or_none, reason)\n",
    "    \"\"\"\n",
    "    if not raw:\n",
    "        return None, \"empty\"\n",
    "\n",
    "    raw = _normalize_spaced_keywords(raw)\n",
    "    sql = extract_first_select(raw) or raw\n",
    "    sql = sql.strip()\n",
    "\n",
    "    lower = sql.lower()\n",
    "    idx = lower.find(\"select\")\n",
    "    if idx == -1:\n",
    "        return None, \"no_select\"\n",
    "    sql = sql[idx:].strip()\n",
    "    lower = sql.lower()\n",
    "\n",
    "    # Trim common prompt-echo tails if present after SQL\n",
    "    for marker in [\n",
    "        \"output only sql\",\n",
    "        \"no explanation\",\n",
    "        \"no markdown\",\n",
    "        \"show output\",\n",
    "        \"y/n\",\n",
    "    ]:\n",
    "        pos = lower.find(marker)\n",
    "        if pos != -1:\n",
    "            sql = sql[:pos].strip()\n",
    "            lower = sql.lower()\n",
    "\n",
    "    # Cut at first semicolon to drop trailing chatter\n",
    "    if \";\" in sql:\n",
    "        sql = sql.split(\";\", 1)[0].strip()\n",
    "        lower = sql.lower()\n",
    "\n",
    "    # Strip prompt-echo tails that appear after SQL\n",
    "    sql = strip_prompt_echo(sql)\n",
    "    lower = sql.lower()\n",
    "\n",
    "    # Minimal junk filter (avoid rejecting useful SQL)\n",
    "    bad_phrases = (\"```\",)\n",
    "    if any(bp in lower for bp in bad_phrases):\n",
    "        return None, \"bad_phrase\"\n",
    "\n",
    "    if not lower.startswith(\"select\"):\n",
    "        return None, \"no_select\"\n",
    "\n",
    "    # Require FROM and block FROM dual\n",
    "    if not re.search(r\"(?is)\\bfrom\\b\", sql):\n",
    "        return None, \"no_from\"\n",
    "    if re.search(r\"(?is)\\bfrom\\s+dual\\b\", sql):\n",
    "        return None, \"from_dual\"\n",
    "    if re.search(r\"(?is)\\bgroup\\s+by\\s+null\\b\", sql):\n",
    "        return None, \"group_by_null\"\n",
    "\n",
    "    return sql + \";\", \"ok\"\n",
    "\n",
    "# Local cleaner for ReAct (returns reason)\n",
    "def clean_candidate(raw: str):\n",
    "    return _clean_candidate_core(raw)  # (sql, reason)\n",
    "\n",
    "# Monkey-patch agent_utils.clean_candidate so vanilla_candidate uses relaxed cleaner\n",
    "def _clean_candidate_for_agent_utils(raw: str):\n",
    "    sql, _ = _clean_candidate_core(raw)\n",
    "    return sql  # Optional[str]\n",
    "\n",
    "agent_utils_mod.clean_candidate = _clean_candidate_for_agent_utils\n",
    "\n",
    "# ---------- Lightweight guardrails / clamps ----------\n",
    "def _has_keyword(text: str, keywords) -> bool:\n",
    "    lt = (text or \"\").lower()\n",
    "    return any(k in lt for k in keywords)\n",
    "\n",
    "def strip_order_by_if_not_requested(sql: str, nlq: str) -> str:\n",
    "    if _has_keyword(nlq, [\"order\", \"sort\", \"top\", \"first\", \"highest\", \"lowest\", \"descending\", \"ascending\", \"limit\", \"rank\"]):\n",
    "        return sql\n",
    "    out = re.sub(r\"(?is)\\s+order\\s+by\\s+.*?(?=(\blimit\b|;|$))\", \"\", sql)\n",
    "    return out if out.endswith(\";\") else out + \";\"\n",
    "\n",
    "def trim_to_first_column(sql: str) -> str:\n",
    "    parsed = sqlparse.parse(sql)\n",
    "    if not parsed:\n",
    "        return sql\n",
    "    stmt = parsed[0]\n",
    "    new_tokens, seen_select, trimmed = [], False, False\n",
    "    for tok in stmt.tokens:\n",
    "        if tok.ttype is DML and tok.value.upper() == \"SELECT\":\n",
    "            seen_select = True\n",
    "            new_tokens.append(tok)\n",
    "            continue\n",
    "        if seen_select and isinstance(tok, IdentifierList) and not trimmed:\n",
    "            try:\n",
    "                first_ident = next(tok.get_identifiers())\n",
    "            except StopIteration:\n",
    "                new_tokens.append(tok)\n",
    "            else:\n",
    "                new_tokens.append(IdentifierList([first_ident]))\n",
    "                trimmed = True\n",
    "            continue\n",
    "        if seen_select and isinstance(tok, Identifier) and not trimmed:\n",
    "            new_tokens.append(tok)\n",
    "            trimmed = True\n",
    "            continue\n",
    "        new_tokens.append(tok)\n",
    "    cleaned = \"\".join(str(t) for t in new_tokens).strip()\n",
    "    return cleaned if cleaned.endswith(\";\") else cleaned + \";\"\n",
    "\n",
    "def strip_group_by_if_not_requested(sql: str, nlq: str) -> str:\n",
    "    nl = (nlq or \"\").lower()\n",
    "    if any(w in nl for w in [\"per \", \"by \", \"each\", \"group\"]):\n",
    "        return sql\n",
    "    if not any(w in nl for w in [\"count\", \"how many\", \"number of\"]):\n",
    "        return sql\n",
    "    out = re.sub(r\"(?is)\\s+group\\s+by\\s+[^;]+\", \"\", sql)\n",
    "    return out if out.endswith(\";\") else out + \";\"\n",
    "\n",
    "def ensure_group_key_in_select(sql: str, nlq: str) -> str:\n",
    "    nl = (nlq or \"\").lower()\n",
    "    if not (\"per \" in nl or \"by \" in nl):\n",
    "        return sql\n",
    "\n",
    "    s = sql.strip().rstrip(\";\")\n",
    "    gb = re.search(r\"(?is)\bgroup\\s+by\\s+([a-zA-Z0-9_\\.]+)\", s)\n",
    "    if not gb:\n",
    "        return sql\n",
    "    group_key = gb.group(1)\n",
    "\n",
    "    sel = re.search(r\"(?is)^\\s*select\\s+(.*?)\\s+from\\s+\", s)\n",
    "    if not sel:\n",
    "        return sql\n",
    "    select_part = sel.group(1)\n",
    "\n",
    "    if group_key.lower() in select_part.lower():\n",
    "        return sql\n",
    "\n",
    "    new_select = f\"{group_key}, {select_part}\"\n",
    "    out = re.sub(r\"(?is)^\\s*select\\s+(.*?)\\s+from\\s+\", f\"SELECT {new_select} FROM \", s, count=1)\n",
    "    return out + \";\"\n",
    "\n",
    "def apply_clamps(sql: str, nlq: str) -> str:\n",
    "    if not USE_CLAMPS:\n",
    "        return sql\n",
    "    sql = strip_order_by_if_not_requested(sql, nlq)\n",
    "    sql = strip_group_by_if_not_requested(sql, nlq)\n",
    "    if _has_keyword(nlq, [\"which\", \"who\", \"what\", \"list\", \"show\"]) and \" and \" not in (nlq or \"\").lower():\n",
    "        sql = trim_to_first_column(sql)\n",
    "    sql = ensure_group_key_in_select(sql, nlq)\n",
    "    return sql\n",
    "\n",
    "def canonicalize_table_casing(sql: str) -> str:\n",
    "    if not sql:\n",
    "        return sql\n",
    "    def repl(m):\n",
    "        tbl = m.group(2)\n",
    "        canon = TABLES_LOWER.get(tbl.lower(), tbl)\n",
    "        return m.group(1) + canon\n",
    "    return re.sub(r\"(?is)\\b(from|join)\\s+([a-zA-Z_][a-zA-Z0-9_]*)\\b\", repl, sql)\n",
    "\n",
    "# ---------- Prompts ----------\n",
    "def build_react_prompt(nlq: str, schema_text: str, history: list[dict], observation: str) -> str:\n",
    "    history_text = \"\n",
    "\n",
    "\".join(\n",
    "        f\"Thought/Action: {h.get('ta','')}\n",
    "Observation: {h.get('obs','')}\"\n",
    "        for h in history\n",
    "    ) or \"None yet.\"\n",
    "    return f\"\"\"\n",
    "You are an expert MySQL analyst.\n",
    "\n",
    "TASK:\n",
    "- Write exactly ONE valid MySQL SELECT statement.\n",
    "- Output only SQL (no explanation, no markdown).\n",
    "- The output must include a FROM clause.\n",
    "- Use only schema columns.\n",
    "- Use ORDER BY/LIMIT only if explicitly asked.\n",
    "\n",
    "Schema:\n",
    "{schema_text}\n",
    "\n",
    "Question:\n",
    "{nlq}\n",
    "\n",
    "Recent steps:\n",
    "{history_text}\n",
    "\n",
    "Last observation:\n",
    "{observation}\n",
    "\n",
    "Respond with only the final SQL statement.\n",
    "\"\"\".strip()\n",
    "\n",
    "def build_tabular_prompt(nlq: str, schema_text: str) -> str:\n",
    "    return f\"\"\"\n",
    "You are an expert SQL engineer. Think through tables and join keys, then output one SELECT.\n",
    "\n",
    "Schema:\n",
    "{schema_text}\n",
    "\n",
    "Question: {nlq}\n",
    "\n",
    "Output only the final SQL statement and nothing else.\n",
    "\"\"\".strip()\n",
    "\n",
    "def projection_guard(sql: str, nlq: str) -> str:\n",
    "    return guarded_postprocess(sql, nlq)\n",
    "\n",
    "# ---------- Candidate generation ----------\n",
    "def generate_candidates(prompt: str, num: int = 1):\n",
    "    do_sample = USE_SAMPLING\n",
    "    if not do_sample:\n",
    "        num = 1\n",
    "\n",
    "    # force SQL start\n",
    "    prompt = prompt.rstrip() + \"\n",
    "SELECT \"\n",
    "    inputs = tok(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    gen_kwargs = dict(max_new_tokens=128, do_sample=do_sample, num_return_sequences=num)\n",
    "    if do_sample:\n",
    "        gen_kwargs.update(dict(temperature=0.5, top_p=0.9))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = model.generate(**inputs, **gen_kwargs)\n",
    "\n",
    "    cands = []\n",
    "    for i in range(num):\n",
    "        gen_ids = out[i][inputs.input_ids.shape[-1]:]\n",
    "        gen = tok.decode(gen_ids, skip_special_tokens=True)\n",
    "        gen = _normalize_spaced_keywords(gen)\n",
    "        cands.append(\"SELECT \" + gen)\n",
    "    return cands\n",
    "\n",
    "# ---------- Error-aware repair ----------\n",
    "def repair_sql(nlq: str, bad_sql: str, error_msg: str, schema_text: str):\n",
    "    if not USE_REPAIR:\n",
    "        return None, {\"enabled\": False}\n",
    "    prompt = f\"\"\"\n",
    "You are an expert MySQL engineer.\n",
    "\n",
    "Schema:\n",
    "{schema_text}\n",
    "\n",
    "User question:\n",
    "{nlq}\n",
    "\n",
    "Invalid SQL:\n",
    "{bad_sql}\n",
    "\n",
    "Database error:\n",
    "{error_msg}\n",
    "\n",
    "Fix the SQL so it is valid MySQL and answers the question.\n",
    "Output ONLY the corrected SELECT statement.\n",
    "\"\"\".strip()\n",
    "    fixes = generate_candidates(prompt, num=1)\n",
    "    if not fixes:\n",
    "        return None, {\"enabled\": True, \"status\": \"no_fix_generated\"}\n",
    "\n",
    "    raw_fix = fixes[0]\n",
    "    sql = extract_first_select(raw_fix) or raw_fix\n",
    "    sql = sql.strip()\n",
    "    if not sql.lower().startswith(\"select\"):\n",
    "        return None, {\"enabled\": True, \"status\": \"fix_not_select\", \"raw_fix\": raw_fix}\n",
    "\n",
    "    sql = sql if sql.endswith(\";\") else sql + \";\"\n",
    "    sql = projection_guard(sql, nlq)\n",
    "    sql = apply_clamps(sql, nlq)\n",
    "\n",
    "    try:\n",
    "        meta = runner.run(sql)\n",
    "        return (sql if meta.success else None), {\n",
    "            \"enabled\": True,\n",
    "            \"status\": \"exec_ok\" if meta.success else \"exec_fail\",\n",
    "            \"raw_fix\": raw_fix,\n",
    "            \"fixed_sql\": sql,\n",
    "            \"exec_error\": meta.error,\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return None, {\n",
    "            \"enabled\": True,\n",
    "            \"status\": \"exception\",\n",
    "            \"raw_fix\": raw_fix,\n",
    "            \"fixed_sql\": sql,\n",
    "            \"exc\": str(e),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f604abb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) ReAct definition (STAGE-gated)\n",
    "# STAGE 0 uses minimal execution-gated decoding.\n",
    "# STAGE >=1 enables the full ReAct-style pipeline.\n",
    "\n",
    "# small structured logger for trace\n",
    "def _log(history, **kwargs):\n",
    "    def _trim(x, n=500):\n",
    "        if x is None:\n",
    "            return None\n",
    "        s = str(x)\n",
    "        return s if len(s) <= n else s[:n] + \"…\"\n",
    "    history.append({k: _trim(v) for k, v in kwargs.items()})\n",
    "\n",
    "from nl2sql.llm import extract_first_select\n",
    "\n",
    "\n",
    "def _minimal_sql(raw: str):\n",
    "    raw = _normalize_spaced_keywords(raw or \"\")\n",
    "    sql = extract_first_select(raw)\n",
    "    if not sql:\n",
    "        return None\n",
    "    sql = sql.split(\";\", 1)[0].strip() + \";\"\n",
    "    return sql\n",
    "\n",
    "\n",
    "def _react_sql_minimal(\n",
    "    nlq: str,\n",
    "    schema_text: str,\n",
    "    schema_summary,\n",
    "    max_steps: int = 3,\n",
    "    num_cands: int = 1,\n",
    "    exemplars=None,\n",
    "):\n",
    "    history = []\n",
    "    observation = \"Start.\"\n",
    "\n",
    "    for _ in range(max_steps):\n",
    "        prompt = build_react_prompt(nlq, schema_text, history, observation)\n",
    "        raw = generate_candidates(prompt, num=1)[0]\n",
    "\n",
    "        sql = _minimal_sql(raw)\n",
    "        if not sql:\n",
    "            history.append({\"ta\": raw, \"obs\": \"Rejected: no SELECT found\"})\n",
    "            observation = \"No SELECT\"\n",
    "            continue\n",
    "\n",
    "        sql = projection_guard(sql, nlq)\n",
    "        try:\n",
    "            meta = runner.run(sql)\n",
    "            if meta.success:\n",
    "                history.append({\"ta\": sql, \"obs\": \"SUCCESS\"})\n",
    "                return sql, history\n",
    "            history.append({\"ta\": sql, \"obs\": f\"ERROR: {meta.error or 'exec fail'}\"})\n",
    "        except Exception as e:\n",
    "            history.append({\"ta\": sql, \"obs\": f\"ERROR: {e}\"})\n",
    "\n",
    "    history.append({\"ta\": \"\", \"obs\": \"No valid SQL found\"})\n",
    "    return \"\", history\n",
    "\n",
    "\n",
    "def _react_sql_full(\n",
    "    nlq: str,\n",
    "    schema_text: str,\n",
    "    schema_summary,\n",
    "    max_steps: int = 3,\n",
    "    num_cands: int = 4,\n",
    "    exemplars=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    ReAct-inspired execution-guided agent:\n",
    "    - multi-candidate generation\n",
    "    - strict SELECT-only filtering\n",
    "    - clamping + guarded postprocess\n",
    "    - execution-based gating\n",
    "    - semantic reranking\n",
    "    - optional one-step repair\n",
    "    - deterministic few-shot baseline fallback\n",
    "    \"\"\"\n",
    "    history: list[dict] = []\n",
    "    observation = \"Start.\"\n",
    "    final_sql = None\n",
    "\n",
    "    for step in range(max_steps):\n",
    "        prompt_main = build_react_prompt(nlq, schema_text, history, observation)\n",
    "        prompt_tab = build_tabular_prompt(nlq, schema_text)\n",
    "\n",
    "        raw_cands = []\n",
    "        raw_cands += generate_candidates(prompt_main, num=max(1, num_cands // 2))\n",
    "        raw_cands += generate_candidates(prompt_tab, num=num_cands - len(raw_cands))\n",
    "\n",
    "        candidates = []\n",
    "        for raw in raw_cands:\n",
    "            sql, reason = clean_candidate(raw)\n",
    "            if not sql:\n",
    "                _log(history, step=step, phase=\"clean\", raw=raw, reason=reason)\n",
    "                continue\n",
    "            sql_pp = projection_guard(sql, nlq)\n",
    "            sql_pp = canonicalize_table_casing(sql_pp)\n",
    "            sql_pp = apply_clamps(sql_pp, nlq)\n",
    "            candidates.append((raw, sql, sql_pp))\n",
    "            _log(history, step=step, phase=\"candidate\", raw=raw, cleaned=sql, post=sql_pp)\n",
    "\n",
    "        last_error = None\n",
    "        best_score = float(\"-inf\")\n",
    "        best_sql = None\n",
    "\n",
    "        for raw, sql_clean, sql_exec in candidates:\n",
    "            try:\n",
    "                meta = runner.run(sql_exec, capture_df=False)\n",
    "                _log(history, step=step, phase=\"exec\", sql=sql_exec, success=meta.success, error=meta.error)\n",
    "                if not meta.success:\n",
    "                    raise ValueError(meta.error or \"exec fail\")\n",
    "\n",
    "                s_sem = semantic_score(nlq, sql_exec)\n",
    "                if USE_RERANK and s_sem < 1.0:\n",
    "                    _log(history, step=step, phase=\"accept_gate\", sql=sql_exec, score=s_sem, decision=\"reject\")\n",
    "                    continue\n",
    "                s_cols = count_select_columns(sql_exec)\n",
    "                total_score = s_sem - 0.5 * s_cols\n",
    "\n",
    "                if total_score > best_score:\n",
    "                    best_score = total_score\n",
    "                    best_sql = sql_exec\n",
    "\n",
    "            except Exception as e:\n",
    "                last_error = str(e)\n",
    "                _log(history, step=step, phase=\"exec_exception\", sql=sql_exec, exc=last_error)\n",
    "\n",
    "                repaired, repinfo = repair_sql(nlq, sql_exec, last_error, schema_text)\n",
    "                _log(history, step=step, phase=\"repair\", bad_sql=sql_exec, error=last_error,\n",
    "                     rep_status=repinfo.get(\"status\"), raw_fix=repinfo.get(\"raw_fix\"),\n",
    "                     fixed_sql=repinfo.get(\"fixed_sql\"), rep_exec_error=repinfo.get(\"exec_error\") or repinfo.get(\"exc\"))\n",
    "\n",
    "                if repaired:\n",
    "                    s_sem2 = semantic_score(nlq, repaired)\n",
    "                    if USE_RERANK and s_sem2 < 1.0:\n",
    "                        _log(history, step=step, phase=\"repair_reject\", sql=repaired, score=s_sem2, decision=\"reject\")\n",
    "                    else:\n",
    "                        best_sql = repaired\n",
    "                        break\n",
    "                continue\n",
    "\n",
    "        if best_sql is None and last_error:\n",
    "            kind = classify_error(last_error)\n",
    "            hint = error_hint(kind, last_error)\n",
    "            observation = f\"{last_error} — {hint}\"\n",
    "            history.append({\"ta\": \"\", \"obs\": observation})\n",
    "            continue\n",
    "\n",
    "        if best_sql is None:\n",
    "            observation = \"All candidates failed execution\"\n",
    "            history.append({\"ta\": \"\", \"obs\": observation})\n",
    "            continue\n",
    "\n",
    "        observation = \"SUCCESS\"\n",
    "        final_sql = best_sql\n",
    "        history.append({\"ta\": best_sql, \"obs\": observation})\n",
    "        break\n",
    "\n",
    "    if final_sql:\n",
    "        return final_sql, history\n",
    "\n",
    "    fallback = vanilla_candidate(\n",
    "        nlq=nlq,\n",
    "        schema_summary=schema_summary,\n",
    "        tok=tok,\n",
    "        model=model,\n",
    "        exemplars=exemplars or test_set[:3],\n",
    "    )\n",
    "    if fallback:\n",
    "        history.append({\"ta\": fallback, \"obs\": \"Baseline fallback after no successful candidate\"})\n",
    "        return fallback, history\n",
    "\n",
    "    history.append({\"ta\": \"\", \"obs\": \"No valid SQL found (including baseline fallback)\"})\n",
    "    return \"\", history\n",
    "\n",
    "\n",
    "# Dispatch based on stage\n",
    "if STAGE == 0:\n",
    "    print(\"STAGE 0: using minimal execution-gated react_sql\")\n",
    "    react_sql = _react_sql_minimal\n",
    "else:\n",
    "    print(\"STAGE >=1: using full ReAct-style react_sql\")\n",
    "    react_sql = _react_sql_full\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41c91f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) Quick sanity check on a few items\n",
    "schema_text = SCHEMA_SUMMARY\n",
    "for sample in test_set[:5]:\n",
    "    nlq = sample[\"nlq\"]\n",
    "    gold = sample[\"sql\"]\n",
    "    pred, trace = react_sql(\n",
    "        nlq=nlq,\n",
    "        schema_text=schema_text,\n",
    "        schema_summary=SCHEMA_SUMMARY,\n",
    "        max_steps=3,\n",
    "        num_cands=4,\n",
    "        exemplars=test_set[:3],\n",
    "    )\n",
    "    print(\"NLQ:\", nlq)\n",
    "    print(\"PRED:\", pred)\n",
    "    print(\"GOLD:\", gold)\n",
    "    print(\"TRACE LEN:\", len(trace))\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 3 Interpretation (29 Jan 2026)\n",
    "\n",
    "- **Valid SQL stability:** Stage 3 generally returns executable SQL; remaining issues are **projection bloat** (extra columns), and **unnecessary ORDER BY/GROUP BY**.\n",
    "- **Metric impact:** These are EM regressions more than EX regressions. Use clamps + final normalization to keep outputs canonical.\n",
    "- **Trace logging upgrade:** The ReAct loop now logs **raw → cleaned → post‑clamp → exec error → repair attempt**, so failures can be attributed to generation vs cleaning vs execution vs repair.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b771d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9) Full ReAct-style evaluation (VA/EX/EM) over test_set\n",
    "from nl2sql.eval import execution_accuracy\n",
    "results = []\n",
    "LIMIT = None  # set to e.g. 20 for a quick slice\n",
    "items = test_set[:LIMIT] if LIMIT else test_set\n",
    "schema_text = SCHEMA_SUMMARY\n",
    "\n",
    "for i, sample in enumerate(items, start=1):\n",
    "    nlq = sample[\"nlq\"]\n",
    "    gold_sql = sample[\"sql\"]\n",
    "\n",
    "    pred_sql, trace = react_sql(\n",
    "        nlq=nlq,\n",
    "        schema_text=schema_text,\n",
    "        schema_summary=SCHEMA_SUMMARY,\n",
    "        max_steps=3,\n",
    "        num_cands=4,\n",
    "        exemplars=test_set[:3],\n",
    "    )\n",
    "\n",
    "    pred_clean = pred_sql.strip().rstrip(\";\").lower()\n",
    "    gold_clean = gold_sql.strip().rstrip(\";\").lower()\n",
    "    em = int(pred_clean == gold_clean)\n",
    "    va = ex = 0\n",
    "\n",
    "    try:\n",
    "        meta = runner.run(pred_sql)\n",
    "        va = int(meta.success)\n",
    "        if meta.success:\n",
    "            ex_ok, _, _ = execution_accuracy(engine=engine, pred_sql=pred_sql, gold_sql=gold_sql)\n",
    "            ex = int(ex_ok)\n",
    "    except Exception:\n",
    "        va = 0\n",
    "        ex = 0\n",
    "\n",
    "    results.append({\n",
    "        \"nlq\": nlq,\n",
    "        \"gold_sql\": gold_sql,\n",
    "        \"pred_sql\": pred_sql,\n",
    "        \"va\": va,\n",
    "        \"em\": em,\n",
    "        \"ex\": ex,\n",
    "        \"trace\": trace,\n",
    "    })\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        print(f\"Processed {i}/{len(items)}\")\n",
    "\n",
    "va_rate = sum(r[\"va\"] for r in results) / len(results)\n",
    "ex_rate = sum(r[\"ex\"] for r in results) / len(results)\n",
    "em_rate = sum(r[\"em\"] for r in results) / len(results)\n",
    "print(\"ReAct VA:\", va_rate, \"EX:\", ex_rate, \"EM:\", em_rate)\n",
    "\n",
    "Path(\"results/agent\").mkdir(parents=True, exist_ok=True)\n",
    "save_path = Path(\"results/agent/results_react_200.json\")\n",
    "save_path.write_text(\n",
    "    json.dumps({\n",
    "        \"va_rate\": va_rate,\n",
    "        \"ex_rate\": ex_rate,\n",
    "        \"em_rate\": em_rate,\n",
    "        \"items\": results,\n",
    "    }, ensure_ascii=False, indent=2),\n",
    "    encoding=\"utf-8\",\n",
    ")\n",
    "print(\"Saved to\", save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}