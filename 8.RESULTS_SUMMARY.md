# Results Summary

What we’ve measured so far: prompt baselines, QLoRA adapters, and what’s next.

## Decision Journey View (results by decision stage)
1. **Prompt-only baseline:** validates structure (VA) but often misses semantics (EX).
2. **QLoRA adapters:** improves semantic mappings (EX), especially with k=3.
3. **Execution-guided agentic refinement:** improves stability and error correction; EX gains are limited by model priors on compositional queries.

---

# Results Summary

What we’ve measured so far: prompt baselines, QLoRA adapters, and what’s next.

## Metrics

VA (syntactic validity), EX (execution accuracy), EM (string match), TS (planned test-suite). Execution-based metrics (VA/EX/TS) matter most for NL→SQL.

## Baselines

**Zero-shot (k=0):** schema in prompt, deterministic decoding. VA ~0.80–0.82; EX ~0.00; EM ~0.00. Take: syntax alone doesn’t give correct answers.

---

**Few-shot (k=3):** same model, plus exemplars. VA ~0.86; EX ~0.25; EM low. Take: exemplars help schema grounding; matches usual few-shot NL→SQL behaviour.

---

## 3. QLoRA Fine-Tuning

Base model: `Llama-3-8B-Instruct`  
PEFT: 4-bit QLoRA (see run configs below)

Two evaluation modes per run: k=0 (adapter-only) and k=3 (adapter + exemplars).

**QLoRA SFT (r=32, ~3 epochs, 4-bit):** k=0 VA 0.865 / EX 0.065 / EM 0.000; k=3 VA 0.870 / EX 0.380 / EM 0.310 (JSONs saved under `results/qlora/`). k=3 beats the prompt-only few-shot baseline; k=0 is still low, so TS + agentic refinement should help.

Take:
- k=3 EX beats the prompt-only few-shot baseline (~0.325→0.380).
- k=0 EX is still low; TS + agentic refinement should help semantic accuracy without exemplars.

---

## 4. Agentic (ReAct) Experiments — status

- Loop design: 3-step Thought/Action/Observation with a single tool (safe SELECT executor), schema-grounded prompt, ORDER/LIMIT and projection clamps, execution-guided retry, and sampled multi-candidates. A helper layer (`nl2sql/agent_utils.py`) now enforces SELECT-only outputs, injects a deterministic few-shot baseline candidate, classifies common MySQL errors into repair hints, and reranks executables with a lightweight semantic score (rewarding aggregates/joins/grouping when implied by the NLQ) rather than “fewest columns.”
- Outcomes so far: VA improved (junk/non-SELECT filtered; retries fix some missing joins); EX on full 200 is still low versus few-shot/QLoRA, indicating remaining semantic gaps. Small slices can hit VA/EX/EM=1.0.
- Failure modes: hallucinated columns/tables, aggregation/GROUP BY drift, and semantic misses that still execute (execution-only feedback is insufficient).
- Next steps: expand semantic scoring rules (e.g., enforce SUM+GROUP BY on “total per …”, productLine → products⋈orderdetails), add non-error semantic refinement hints, and rerun full 200 once updated. Longer-term: move to a true ReAct loop with explicit `Action: SCHEMA_LOOKUP[...]` / `Action: EXEC_SQL[...]` and structured `Observation:` feedback to let the model revise based on its own errors.
- Dissertation positioning: present the current agent as “execution-guided reranking” (Stage 1) and note the gap to a full ReAct agent (Stage 2) where structured Thought/Action/Observation could unlock further EX gains. Baseline and QLoRA remain the primary quantitative anchors.

### File-level change index (agentic update)
- Modified: `notebooks/03_agentic_eval.ipynb`, `nl2sql/agent_utils.py`, `scripts/run_full_pipeline.py`
- Added: semantic reranker, error-aware repair, mild-sampling candidate generation, deterministic baseline fallback
- Removed/superseded: projection-minimality-only heuristic; greedy-only decoding

After introducing execution-guided reranking and repair, EX improved relative to prompting-only baselines without modifying model weights, paralleling gains reported in execution-guided approaches (Zhong et al., 2017) and ReAct-style reasoning (Yao et al., 2023).

---

## 5. Learning journey (runs tied to commits)
- 2025-12-14 (baseline hygiene, commit ref: see logbook 2025-12-14): Prompt structuring + minimal postprocess → VA/EX jump on small slice; established deterministic eval protocol.
- 2026-01-12 (QLoRA r=32, 3 epochs, commit ref: logbook 2026-01-12): k=0 VA 0.865 / EX 0.065; k=3 VA 0.875 / EX 0.380. Takeaway: adapters + exemplars beat prompt-only k=3.
- 2026-01-24–31 (ReAct iterations, commits through `a7afd60`): added clamps, select-only filtering, execution-guided retry, sampling, and one-shot repair. Result: VA improved; EX still below few-shot/QLoRA on full set. Position as exploratory and report traces.

Use this section to anchor dissertation claims to dated logbook entries and commits.
