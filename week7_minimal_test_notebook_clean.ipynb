{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b5d82ff",
   "metadata": {
    "id": "8b5d82ff"
   },
   "source": [
    "# 1. GCP Auth (optional for Colab)\n",
    "\n",
    "If you're in Colab, this will show a login prompt.\n",
    "\n",
    "If you're running locally (VS Code / Jupyter), you can ignore the message and rely on gcloud / ADC / service accounts instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AUgQLgEkOKjR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AUgQLgEkOKjR",
    "outputId": "87ac2dbd-412b-4bb9-d972-239c7cc2d0ed"
   },
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "\n",
    "# Reset to a known-good directory\n",
    "os.chdir(\"/content\")\n",
    "\n",
    "# Remove any partial clone\n",
    "repo_dir = \"/content/NLtoSQL\"\n",
    "if os.path.exists(repo_dir):\n",
    "    shutil.rmtree(repo_dir)\n",
    "\n",
    "# Fresh clone\n",
    "!git clone https://github.com/MacKenzieOBrian/NLtoSQL.git \"$repo_dir\"\n",
    "os.chdir(repo_dir)\n",
    "\n",
    "# Sanity checks\n",
    "!git rev-parse --short HEAD\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de0879d",
   "metadata": {
    "id": "5de0879d"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import auth\n",
    "except ModuleNotFoundError:\n",
    "    auth = None\n",
    "\n",
    "if auth:\n",
    "    auth.authenticate_user()\n",
    "else:\n",
    "    print(\"Not running in Colab; ensure GCP auth via gcloud/ADC or service account if needed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42845b0",
   "metadata": {
    "id": "c42845b0"
   },
   "source": [
    "# 2. Project configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cf85fc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "67cf85fc",
    "outputId": "65551e9d-cc4d-406c-ee1a-a93b58d0e3ea"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "project_id = \"modified-enigma-476414-h9\"  # TODO: change or move to env var in production\n",
    "os.environ[\"GOOGLE_CLOUD_PROJECT\"] = project_id\n",
    "\n",
    "print(\"GOOGLE_CLOUD_PROJECT set to:\", os.environ[\"GOOGLE_CLOUD_PROJECT\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98191e1b",
   "metadata": {
    "id": "98191e1b"
   },
   "source": [
    "# 3. Install dependencies\n",
    "\n",
    "If you've already installed from requirements.txt in this environment, you can comment this out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597edacf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "597edacf",
    "outputId": "b62bc265-1252-4299-e1c3-0e98fecc670a"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "# Prefer installing from pinned requirements.txt for reproducibility\n",
    "!{sys.executable} -m pip install --upgrade pip\n",
    "!{sys.executable} -m pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a59fec6",
   "metadata": {
    "id": "1a59fec6"
   },
   "source": [
    "#4. Imports & logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c814f6b",
   "metadata": {
    "id": "9c814f6b"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import json\n",
    "from datetime import datetime, timezone\n",
    "from typing import Any, Dict, Optional\n",
    "\n",
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "from sqlalchemy import text\n",
    "from sqlalchemy.engine import Engine\n",
    "\n",
    "from google.cloud.sql.connector import Connector\n",
    "from google.api_core import retry\n",
    "\n",
    "import pymysql\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(\"nl2sql_db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c470662b",
   "metadata": {
    "id": "c470662b"
   },
   "source": [
    "# 5. Connection parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615caadd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "615caadd",
    "outputId": "5d8f3e4a-1ff9-4083-a4b0-ac89cbad16b2"
   },
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "INSTANCE_CONNECTION_NAME = os.getenv(\"INSTANCE_CONNECTION_NAME\")\n",
    "DB_USER = os.getenv(\"DB_USER\")\n",
    "DB_PASS = os.getenv(\"DB_PASS\")\n",
    "DB_NAME = os.getenv(\"DB_NAME\", \"classicmodels\")\n",
    "\n",
    "if not INSTANCE_CONNECTION_NAME:\n",
    "    INSTANCE_CONNECTION_NAME = input(\"Enter INSTANCE_CONNECTION_NAME: \").strip()\n",
    "\n",
    "if not DB_USER:\n",
    "    DB_USER = input(\"Enter DB_USER: \").strip()\n",
    "\n",
    "if not DB_PASS:\n",
    "    DB_PASS = getpass(\"Enter DB_PASS: \")\n",
    "\n",
    "print(\"Using DB:\", DB_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460e3ebd",
   "metadata": {
    "id": "460e3ebd"
   },
   "source": [
    "# 6. Cloud SQL connector + engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e357f1",
   "metadata": {
    "id": "36e357f1"
   },
   "outputs": [],
   "source": [
    "from contextlib import contextmanager\n",
    "\n",
    "connector = Connector()\n",
    "\n",
    "def getconn():\n",
    "    \"\"\"SQLAlchemy creator hook using the Cloud SQL connector.\"\"\"\n",
    "    return connector.connect(\n",
    "        INSTANCE_CONNECTION_NAME,\n",
    "        \"pymysql\",\n",
    "        user=DB_USER,\n",
    "        password=DB_PASS,\n",
    "        db=DB_NAME,\n",
    "    )\n",
    "\n",
    "# Use a creator function so SQLAlchemy delegates connection creation to the connector\n",
    "engine: Engine = sqlalchemy.create_engine(\n",
    "    \"mysql+pymysql://\",\n",
    "    creator=getconn,\n",
    "    future=True\n",
    ")\n",
    "\n",
    "@contextmanager\n",
    "def safe_connection(engine: Engine):\n",
    "    \"\"\"\n",
    "    Context manager that yields a DB connection and ensures it gets closed.\n",
    "    \"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = engine.connect()\n",
    "        yield conn\n",
    "    finally:\n",
    "        if conn is not None:\n",
    "            conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19d19d7",
   "metadata": {
    "id": "c19d19d7"
   },
   "source": [
    "# 7. Schema exploration helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777e17cc",
   "metadata": {
    "id": "777e17cc"
   },
   "outputs": [],
   "source": [
    "def list_tables(engine: Engine) -> list:\n",
    "    \"\"\"Return a list of table names in the current database.\"\"\"\n",
    "    with safe_connection(engine) as conn:\n",
    "        result = conn.execute(text(\"SHOW TABLES;\")).fetchall()\n",
    "    return [r[0] for r in result]\n",
    "\n",
    "def get_table_columns(engine: Engine, table_name: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Return a DataFrame of columns for a given table.\n",
    "    Includes column name, data type, nullability, and key info.\n",
    "    \"\"\"\n",
    "    query = text(\"\"\"\n",
    "        SELECT COLUMN_NAME, DATA_TYPE, IS_NULLABLE, COLUMN_KEY\n",
    "        FROM INFORMATION_SCHEMA.COLUMNS\n",
    "        WHERE TABLE_SCHEMA = :db AND TABLE_NAME = :table\n",
    "        ORDER BY ORDINAL_POSITION\n",
    "    \"\"\")\n",
    "    with safe_connection(engine) as conn:\n",
    "        df = pd.read_sql(query, conn, params={\"db\": DB_NAME, \"table\": table_name})\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ad4a14",
   "metadata": {
    "id": "a0ad4a14"
   },
   "source": [
    "# 8. QueryRunner (read-only executor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6956eebe",
   "metadata": {
    "id": "6956eebe"
   },
   "outputs": [],
   "source": [
    "class QueryExecutionError(Exception):\n",
    "    pass\n",
    "\n",
    "def now_utc_iso() -> str:\n",
    "    return datetime.now(timezone.utc).isoformat().replace(\"+00:00\", \"Z\")\n",
    "\n",
    "class QueryRunner:\n",
    "    \"\"\"\n",
    "    Execute generated SQL safely against the engine, capture results and metadata,\n",
    "    and keep a history suitable for evaluation and error analysis.\n",
    "    \"\"\"\n",
    "    def __init__(self, engine: Engine, max_rows: int = 1000, forbidden_tokens=None):\n",
    "        self.engine = engine\n",
    "        self.max_rows = max_rows\n",
    "        self.history = []\n",
    "        self.forbidden_tokens = forbidden_tokens or [\n",
    "            \"drop \", \"delete \", \"truncate \", \"alter \", \"create \", \"update \", \"insert \"\n",
    "        ]\n",
    "\n",
    "    def _safety_check(self, sql: str) -> None:\n",
    "        \"\"\"Block obviously destructive statements.\"\"\"\n",
    "        lowered = (sql or \"\").strip().lower()\n",
    "        if not lowered:\n",
    "            raise QueryExecutionError(\"Empty SQL string\")\n",
    "        for token in self.forbidden_tokens:\n",
    "            if token in lowered:\n",
    "                raise QueryExecutionError(f\"Destructive SQL token detected: {token.strip()}\")\n",
    "\n",
    "    def run(\n",
    "        self,\n",
    "        sql: str,\n",
    "        params: Optional[Dict[str, Any]] = None,\n",
    "        capture_df: bool = True,\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Execute a SELECT-style query, returning metadata and an optional DataFrame preview.\n",
    "        \"\"\"\n",
    "        entry = {\n",
    "            \"sql\": sql,\n",
    "            \"params\": params,\n",
    "            \"timestamp\": now_utc_iso(),\n",
    "            \"success\": False,\n",
    "            \"rowcount\": 0,\n",
    "            \"exec_time_s\": None,\n",
    "            \"error\": None,\n",
    "            \"columns\": None,\n",
    "            \"result_preview\": None,\n",
    "        }\n",
    "        try:\n",
    "            self._safety_check(sql)\n",
    "            start = datetime.now(timezone.utc)\n",
    "\n",
    "            with safe_connection(self.engine) as conn:\n",
    "                result = conn.execute(sqlalchemy.text(sql), params or {})\n",
    "                rows = result.fetchall()\n",
    "                cols = list(result.keys())\n",
    "\n",
    "            end = datetime.now(timezone.utc)\n",
    "            exec_time = (end - start).total_seconds()\n",
    "\n",
    "            df = None\n",
    "            if capture_df:\n",
    "                df = pd.DataFrame(rows, columns=cols)\n",
    "                if len(df) > self.max_rows:\n",
    "                    df = df.iloc[: self.max_rows]\n",
    "\n",
    "            entry.update({\n",
    "                \"success\": True,\n",
    "                \"rowcount\": min(len(rows), self.max_rows),\n",
    "                \"exec_time_s\": exec_time,\n",
    "                \"columns\": cols,\n",
    "                \"result_preview\": df,\n",
    "            })\n",
    "        except Exception as e:\n",
    "            entry.update({\n",
    "                \"error\": str(e),\n",
    "                \"success\": False,\n",
    "            })\n",
    "        finally:\n",
    "            self.history.append(entry)\n",
    "        return entry\n",
    "\n",
    "    def last(self):\n",
    "        return self.history[-1] if self.history else None\n",
    "\n",
    "    def save_history(self, path: str):\n",
    "        \"\"\"Persist history (without DataFrames) to JSON for later analysis.\"\"\"\n",
    "        serializable = []\n",
    "        for h in self.history:\n",
    "            s = {k: v for k, v in h.items() if k != \"result_preview\"}\n",
    "            serializable.append(s)\n",
    "        with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(serializable, f, indent=2, default=str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e296f6e4",
   "metadata": {
    "id": "e296f6e4"
   },
   "source": [
    "# 9. Smoke tests (DB connectivity + schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f9f164",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "c6f9f164",
    "outputId": "02a162e3-a86c-481f-c06f-a5ccd5a303cb"
   },
   "outputs": [],
   "source": [
    "def fetch_sample_customers(limit: int = 10) -> pd.DataFrame:\n",
    "    \"\"\"Quick sample query against the customers table.\"\"\"\n",
    "    q = text(\"SELECT customerNumber, customerName, country FROM customers LIMIT :limit;\")\n",
    "    with safe_connection(engine) as conn:\n",
    "        df = pd.read_sql(q, conn, params={\"limit\": limit})\n",
    "    return df\n",
    "\n",
    "try:\n",
    "    tables = list_tables(engine)\n",
    "    logger.info(\"Tables in classicmodels: %s\", tables)\n",
    "\n",
    "    sample_df = fetch_sample_customers(5)\n",
    "    display(sample_df)\n",
    "\n",
    "    # Optionally print each table's schema (comment out if too verbose)\n",
    "    for table_name in tables:\n",
    "        print(f\"\\nSchema for table: {table_name}\")\n",
    "        df_columns = get_table_columns(engine, table_name)\n",
    "        display(df_columns)\n",
    "\n",
    "except Exception as e:\n",
    "    logger.exception(\"Smoke test failed: %s\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428221bd",
   "metadata": {
    "id": "428221bd"
   },
   "source": [
    "# 10. Load static NLQ-SQL test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cb08aa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "e7cb08aa",
    "outputId": "a64ea264-a259-47ca-c6b1-1ab7a77a7843"
   },
   "outputs": [],
   "source": [
    "with open(\"data/classicmodels_test_200.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    test_set = json.load(f)\n",
    "\n",
    "print(f\"Loaded {len(test_set)} test items from data/classicmodels_test_200.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6211d4d",
   "metadata": {
    "id": "c6211d4d"
   },
   "source": [
    "# 11. Optional: validate test SQL against the live DB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2672f7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "be2672f7",
    "outputId": "9aeef66c-366e-459c-9bfc-a46f04d60cd2"
   },
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "def validate_test_set(path: str = \"data/classicmodels_test_200.json\",\n",
    "                      limit: Optional[int] = None) -> Tuple[list, list]:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        items = json.load(f)\n",
    "    if limit:\n",
    "        items = items[:limit]\n",
    "\n",
    "    qr_local = QueryRunner(engine, max_rows=200)\n",
    "    successes: List[int] = []\n",
    "    failures: List[Dict[str, Any]] = []\n",
    "\n",
    "    for idx, item in enumerate(items):\n",
    "        meta = qr_local.run(item[\"sql\"], capture_df=False)\n",
    "        if meta[\"success\"]:\n",
    "            successes.append(idx)\n",
    "        else:\n",
    "            failures.append({\n",
    "                \"index\": idx,\n",
    "                \"nlq\": item.get(\"nlq\"),\n",
    "                \"sql\": item.get(\"sql\"),\n",
    "                \"error\": meta[\"error\"],\n",
    "            })\n",
    "\n",
    "    print(f\"Ran {len(items)} queries. Success: {len(successes)}. Failures: {len(failures)}.\")\n",
    "    if failures:\n",
    "        print(\"Failures (first 5):\")\n",
    "        for f in failures[:5]:\n",
    "            print(f)\n",
    "    else:\n",
    "        print(\"All queries succeeded in this run.\")\n",
    "    return successes, failures\n",
    "\n",
    "# Uncomment to run a quick validation (e.g. on first 50)\n",
    "successes, failures = validate_test_set(limit=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AH1thxi9Ek83",
   "metadata": {
    "id": "AH1thxi9Ek83"
   },
   "source": [
    "# 12. Hugging Face authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "P9PdQ3KDFAnc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17,
     "referenced_widgets": [
      "c8692a251dd1459d8646adf68f809aeb",
      "20cb86dfc81e4c5e9452255b730dbb09",
      "aafbeda376794ff8bfd51d50e51a9254",
      "4591e913a9f34665aabe20666c1d329e",
      "581e291c1990457c91ab925017490278",
      "5f387e031159470db9bc181690e14409",
      "26489d13e0df4080a34ed86aea776d10",
      "98d911d29f094a45bc922de1dbbbe881",
      "eaadf193401f4061b23309432a67c997",
      "dc30a8c175a644f1bdabcf901050fd03",
      "c964069f8a5149fd83657c043c5d5dff",
      "a1f5fc0dafff408a89d37f47458bb35e",
      "e3e0f144bea84cc5a70a71854da95613",
      "1d461cb1d5324239a32ee36cc32e5d6b",
      "ae3b06677bfd4bc4a93b1b0822af7c51",
      "6caa2b3fc8584d5f8c2e64d93fe6d221",
      "ac91ed6355da49e882b422e4ee29aa45",
      "269bdc92d0084bd4a927ece665b4f8c1",
      "1566506f6bdf4743a15ada1587bd2c57",
      "08822f2f6ba24c2eb6e29cf6e874868d"
     ]
    },
    "id": "P9PdQ3KDFAnc",
    "outputId": "807e0f38-b250-4361-f29a-4534a27fe290"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9RdMzhclEujw",
   "metadata": {
    "id": "9RdMzhclEujw"
   },
   "source": [
    "# 13. Load Llama-3-8B-Instruct (4-bit where possible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3L5hJItXExYg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 908,
     "referenced_widgets": [
      "d4a40e16cefb4446818e734b0e135193",
      "f2102206dcd948c5bc44e53c8ce51d13",
      "0ee00c6e21fe4076a0f5b3cdf0214729",
      "ed1121a5e91b4c47907b5fd99c5f6226",
      "8b760b673e8e42cb8fcc6a20050a7bac",
      "c31e5c8d26b2484681b4a96ec5372442",
      "38f77499c7cf43e5ad2a13870bd3e86b",
      "ea6260c6afe749ec8770eda7e07ddec8",
      "b32a50085a1a412680066dda2b5d95b3",
      "fdfe9c5aebc84b0e9be88267bf22fa54",
      "c5ee1ff170cd4bbba3f2db0882731ce0",
      "f07cc37ab20a47a9abb1b8f894e66949",
      "9f1a539641b7483b8416984454d685df",
      "f2bb3b0a8e1049bd91478cf349a2a9cd",
      "0f22c12e824b4214a36a6530b05a762a",
      "7a048ec906f646fb9b04cef3395f74d5",
      "17844833b17c47c192361fd11cacca67",
      "0c6d89ca41134ea6b2f65d9c7f5e538f",
      "d27811f643af4133b7ec3e77fbc92209",
      "b5073205feca4dfeba219bdd3c4e7b93",
      "b9df3b599d714de48a19bc8d48de0694",
      "4094ecd1350e457b9be2e087f5e8b764",
      "8cbfd0497db84ceea69d60b7ff7820d6",
      "bc6ac05f157748c6ba4a6e8ec92b29a3",
      "b26912465e4f4dd2bc175e190ae52f45",
      "ad5332bc05a04a52a84580d525d5f711",
      "719a33ad24d5407a9d8f676e1ef55369",
      "b9130eb658c2465bba44cec92862f409",
      "fdfc7571932549d79accdd6ac5abffbc",
      "efe4c867aa4843d4b00e3d37b3711432",
      "b388eb32ef1b46979f02295e54deda73",
      "b2b42f807d224cd5b826dac74bfb32d5",
      "a045a148f90b4e2ca919ec934ecc0bfa",
      "cc6690b228eb4df798e76874b14d2d6f",
      "6a0cee807970471baa50aed3bee85fb5",
      "1fa7b70e975d4b029d2e488e9bb3553e",
      "6d58ea8d339e4876a06078fd5b840642",
      "00d0565898a4457697162cefa052d9ca",
      "e0e8be256dec44e09ec08efb81e00d80",
      "655a311964bd479ba98ea04126161ed2",
      "5342413c52a74672be72e10701e073b3",
      "ded9479ec98b4e87aefb04b680db36a2",
      "18a49a89070646159dd7a7981a52017e",
      "d6f1a131be7e4faf8f0a108e1838d1b7",
      "219d9052bb6a432b9e167ef65a1c2efc",
      "f8dee13f49ac4cb686932e99b0fce120",
      "47dcc7b872cd4c08bba135c128d9765d",
      "a7181cc5824f4d22afde36d1f2a1dc82",
      "17fd455adcd04ad4bfd13b8d8989ae13",
      "66828b071766437195af66cb155d0b60",
      "28cabf20a30740258f86c24b198669a8",
      "e922b5bc8c3843b2bce25bc5f6635476",
      "6c5615cb0e27431e86635940b77f1280",
      "f18c315ffa9244e2bcae7a8b7fc9563d",
      "abb649f13d0048b288f903d13095655b",
      "afe695d3a5364a21a4a8c5a9c2bcdd7e",
      "17a901dbd7f3482db83fac6abcc31a3f",
      "fed8a0f0d97a4f9e8f9717846a36f740",
      "2cc84aeabc0746d5a5bd805420b54182",
      "6c5a9fd576074475be95a5e1aa73d3df",
      "7bc9c908d335496b933460f211811c50",
      "3563f92b449040aa8fcc83dea0917faf",
      "bdc2de80c420495eba54f9063e594d8d",
      "c2b5a9246c6f48fa9ecc272c09b0ee7c",
      "f1c7cfdd292940e6b64ba6c569e0c1b6",
      "ca71f2c3eba64102a26ffa1ba07c6233",
      "683001b6c50d4b62a4a4de57326ba415",
      "81ba71dc9f6c474e9da82459e2a60a79",
      "804816114bfa4283a3bb2cceee2b99f9",
      "63f66aa577b04ec681e008b6fe3e73a5",
      "6a2ef3d35ff1430caeb354f5a7ac4604",
      "b22716dda9a44c59afd1efa85bacbae2",
      "ed31478cd15d4aafb93e3048a6e734d4",
      "4a4a7b528cec4e7bb57acee793b89ead",
      "c66a4117b3fc43d0ad56fb4045f0d7c9",
      "59557f5955b345018135d404a7e75392",
      "56c9200fe5e7416fa31c4fa34eab8ef4",
      "e1f4fae481ed49389dfc4de31fd010c3",
      "86107ca56cab46bbba97294ea2f0d5ac",
      "25b5eb113d104c82ade2a48a94aeab8f",
      "b0d9b32bc7b24923b563ca7960778f6b",
      "7b72cb8efec841edbf255a8e0dea8e81",
      "be9f0becb051459584e51abaa246dd85",
      "eed7e71be1ab4d188a6af540dfe67b32",
      "dcbbf50b206246bbb51d0b53ae4825a3",
      "bbae3ccb356a4e2daaaa23a3b73d0322",
      "e6912662f77848f69e354863fe209ad4",
      "326c99cf992348dabc9d98ee30a1321f",
      "909ca799b42f4f9c9403e60454f19670",
      "25de2b4e77284df78922d5ea2550b2a0",
      "3b42d1127a334298ac55238ad3ed015e",
      "57262f393aa141e6abf1613280ed5333",
      "1d9b399306e640be9c5fa518c3794feb",
      "2c643dbd0fa941548e4e447cba57870e",
      "3fc30b1cf1954a0aafa1c68e5fdc6a1a",
      "a90c94dc699541b1b5929093e7574665",
      "1d4d1ff8437a4b009684d94d1e03ce51",
      "70e43ef9a1954321bfa0a84ecf752dfa",
      "dcf66eea0dc643d98025b2de0881a5a9",
      "de68c62a4d744ee3bed99fb5d2fcd918",
      "122b3cf83e4245eeb850eeb9779c521d",
      "daa714a939f740c7b407abeef8e327e5",
      "743489005f544508b0de7f1265ad69fa",
      "c94f4360073b485e8f4feb99bff2f6e6",
      "7bb7440609304b4eaf804e35e0e4ef0e",
      "48a87d2443844a62a1f71424243ca207",
      "bf321b3f5b944af9ac5635199add8234",
      "bbeb2b14c3234c4eb31460aa0fa8af5e",
      "340011e221a345d4a1adddcf38304689",
      "a52e079e87b54e7fa05d2a23506f3c0a",
      "74f6f214fa334df5b22dd92d41339825",
      "3e5ec2eb85774fc09258f242a0f70b7a",
      "a74587081f984aa09460b7b829d4935e",
      "b29224fe513c47508bd24aa525c5b126",
      "eb4e2ae31df74584aafc26ab8a0f168e",
      "420c4f9a5b7e46c893b1eb6709018dc7",
      "0c9be6a1e2eb4a9daba33e533da8d853",
      "629e390f57f34a5da8079fa381e04d30",
      "395ddf9ee4d441bc9a842d7b9aa9c6d3",
      "c36ecb153a56431bb50f257e232548c2",
      "f1696cc83d8c4b7892d302ccbc48765e",
      "3cb49fdaf7654545beabc89492069fce",
      "2bca0eb10c2b4e499c016a8717f52614",
      "89ed6948c9674a7aa665f71ace7c2d44",
      "133a066f38074da5aa99703e4cfec954",
      "05f12efaf83e476eae759dbffca625b3",
      "38c56f3a0692439793df09ca9a616de9",
      "adc5afd8c54549758a8509bf2b46d614",
      "516e3ef872a74193838c5378512bf5bd",
      "7fcd86babb8743589a253f4f8f023475",
      "790116fae2c5454b9908c94a3d9ead57",
      "c3155af9ef784725a7cc54cbf903b8ef"
     ]
    },
    "id": "3L5hJItXExYg",
    "outputId": "c9c8208c-3f73-4a8c-deaf-10aae33e08ba"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "print(\"Loading tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "    token=True  # uses your notebook_login() token\n",
    ")\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "tok = tokenizer  # shorthand\n",
    "\n",
    "# Try 4-bit loading\n",
    "try:\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    )\n",
    "    print(\"Attempting 4-bit quantized load...\")\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        \"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "        quantization_config=bnb_config,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        device_map=\"auto\",\n",
    "        token=True,\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(\"4-bit load failed, falling back to full-precision load.\\nError:\")\n",
    "    print(e)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        \"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "        torch_dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float32,\n",
    "        device_map=\"auto\" if torch.cuda.is_available() else None,\n",
    "        token=True,\n",
    "    )\n",
    "\n",
    "print(\"\\nModel loaded!\")\n",
    "print(\"Device:\", next(model.parameters()).device)\n",
    "\n",
    "# Deterministic smoke test\n",
    "inp = tok(\"Reply with only the word OK.\", return_tensors=\"pt\").to(model.device)\n",
    "out = model.generate(\n",
    "    **inp,\n",
    "    max_new_tokens=3,\n",
    "    do_sample=False,          # deterministic\n",
    "    temperature=None,\n",
    "    top_p=None,\n",
    "    pad_token_id=tok.eos_token_id,\n",
    ")\n",
    "print(tok.decode(out[0], skip_special_tokens=True))\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
