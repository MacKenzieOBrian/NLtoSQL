{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64f2b652",
   "metadata": {},
   "source": [
    "# Agentic Evaluation (Tool-Driven ReAct Loop)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef67421",
   "metadata": {},
   "source": [
    "### Setup (Colab only)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b144d3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%%bash\n",
    "set -e\n",
    "export PIP_DEFAULT_TIMEOUT=120\n",
    "\n",
    "# Clean conflicting preinstalls\n",
    "pip uninstall -y torch torchvision torchaudio bitsandbytes triton transformers accelerate peft trl datasets numpy pandas fsspec requests google-auth || true\n",
    "\n",
    "# Base deps\n",
    "pip install -q --no-cache-dir --force-reinstall   numpy==1.26.4 pandas==2.2.1 fsspec==2024.5.0 requests==2.31.0 google-auth==2.43.0\n",
    "\n",
    "# Torch + CUDA 12.1\n",
    "pip install -q --no-cache-dir --force-reinstall   torch==2.3.1+cu121 torchvision==0.18.1+cu121 torchaudio==2.3.1+cu121   --index-url https://download.pytorch.org/whl/cu121\n",
    "\n",
    "# bitsandbytes + triton + HF stack\n",
    "pip install -q --no-cache-dir --force-reinstall   bitsandbytes==0.43.3 triton==2.3.1   transformers==4.44.2 accelerate==0.33.0 peft==0.17.0 trl==0.9.6 datasets==2.20.0\n",
    "\n",
    "echo \"Setup complete. Restart runtime once, then run the rest of the notebook top-to-bottom.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26b6008",
   "metadata": {},
   "source": [
    "### Repo setup (Colab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47936fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0) Clone repo (Colab) + install deps\n",
    "import os\n",
    "os.environ[\"TRANSFORMERS_NO_TF\"] = \"1\"\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "try:\n",
    "    import google.colab  # noqa: F401\n",
    "    IN_COLAB = True\n",
    "except Exception:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    if not os.path.exists('/content/NLtoSQL'):\n",
    "        !git clone https://github.com/MacKenzieOBrian/NLtoSQL.git /content/NLtoSQL\n",
    "    %cd /content/NLtoSQL\n",
    "    !pip -q install -r requirements.txt\n",
    "    import torch, transformers, accelerate, peft\n",
    "    print('torch', torch.__version__, 'cuda', torch.cuda.is_available())\n",
    "else:\n",
    "    print('Not in Colab; using existing workspace')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f58d00e",
   "metadata": {},
   "source": [
    "### Optional: ADC auth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af27263f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this only if you prefer gcloud-based ADC (no JSON key)\n",
    "try:\n",
    "    import google.colab  # noqa: F401\n",
    "    IN_COLAB = True\n",
    "except Exception:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    %pip install -q --upgrade google-auth google-auth-oauthlib\n",
    "    !gcloud auth application-default login\n",
    "else:\n",
    "    print(\"Not in Colab; skip gcloud auth.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada87478",
   "metadata": {},
   "source": [
    "### DB connection + QueryRunner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8d87f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Environment + DB\n",
    "from getpass import getpass\n",
    "\n",
    "from sqlalchemy import text\n",
    "\n",
    "from nl2sql.db import create_engine_with_connector, safe_connection\n",
    "\n",
    "# Expected env vars (set these in a Colab cell):\n",
    "# INSTANCE_CONNECTION_NAME, DB_USER, DB_PASS, DB_NAME\n",
    "INSTANCE_CONNECTION_NAME = os.getenv(\"INSTANCE_CONNECTION_NAME\")\n",
    "DB_USER = os.getenv(\"DB_USER\")\n",
    "DB_PASS = os.getenv(\"DB_PASS\")\n",
    "DB_NAME = os.getenv(\"DB_NAME\") or \"classicmodels\"\n",
    "\n",
    "if not INSTANCE_CONNECTION_NAME:\n",
    "    INSTANCE_CONNECTION_NAME = input(\"Enter INSTANCE_CONNECTION_NAME: \").strip()\n",
    "if not DB_USER:\n",
    "    DB_USER = input(\"Enter DB_USER: \").strip()\n",
    "if not DB_PASS:\n",
    "    DB_PASS = getpass(\"Enter DB_PASS: \")\n",
    "\n",
    "# Canonical engine builder (shared with scripts + other notebooks).\n",
    "# Uses Cloud SQL Connector under the hood and ADC for credentials.\n",
    "engine, connector = create_engine_with_connector(\n",
    "    instance_connection_name=INSTANCE_CONNECTION_NAME,\n",
    "    user=DB_USER,\n",
    "    password=DB_PASS,\n",
    "    db_name=DB_NAME,\n",
    ")\n",
    "\n",
    "with safe_connection(engine) as conn:\n",
    "    conn.execute(text(\"SELECT 1\"))\n",
    "print(\"DB connection OK\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f9a6fb",
   "metadata": {},
   "source": [
    "### TS engine factory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f477e976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1b) Engine factory for TS (multiple DB names)\n",
    "\n",
    "import sqlalchemy\n",
    "from sqlalchemy.engine import Engine\n",
    "\n",
    "\n",
    "def make_engine(db_name: str) -> Engine:\n",
    "    \"\"\"Create a new engine bound to a specific TS replica DB name.\n",
    "\n",
    "    TS (test-suite accuracy) executes the same (gold, pred) SQL across multiple\n",
    "    replica databases (classicmodels_ts_XX). We keep separate engines so each\n",
    "    replica is evaluated independently.\n",
    "    \"\"\"\n",
    "\n",
    "    def getconn_for_db():\n",
    "        return connector.connect(\n",
    "            INSTANCE_CONNECTION_NAME,\n",
    "            \"pymysql\",\n",
    "            user=DB_USER,\n",
    "            password=DB_PASS,\n",
    "            db=db_name,\n",
    "        )\n",
    "\n",
    "    return sqlalchemy.create_engine(\"mysql+pymysql://\", creator=getconn_for_db, future=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6cfbfc",
   "metadata": {},
   "source": [
    "### Schema summary + test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1c88d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Schema summary + test set + QueryRunner\n",
    "import json\n",
    "from pathlib import Path\n",
    "from nl2sql.schema import build_schema_summary\n",
    "from nl2sql.query_runner import QueryRunner\n",
    "\n",
    "DB_NAME = globals().get(\"DB_NAME\") or os.getenv(\"DB_NAME\") or \"classicmodels\"\n",
    "SCHEMA_SUMMARY = build_schema_summary(engine, db_name=DB_NAME)\n",
    "test_path = Path(\"data/classicmodels_test_200.json\")\n",
    "full_set = json.loads(test_path.read_text(encoding=\"utf-8\"))\n",
    "test_set = full_set  # slice later via QUICK_LIMIT\n",
    "print(\"Loaded test set size:\", len(test_set))\n",
    "\n",
    "# Small exemplar set (seeded to encourage join behavior).\n",
    "join_exemplars = [it for it in full_set if \"office\" in it[\"nlq\"].lower()]\n",
    "REACT_EXEMPLARS = []\n",
    "if join_exemplars:\n",
    "    REACT_EXEMPLARS.append(join_exemplars[0])\n",
    "for it in full_set:\n",
    "    if it not in REACT_EXEMPLARS:\n",
    "        REACT_EXEMPLARS.append(it)\n",
    "    if len(REACT_EXEMPLARS) >= 3:\n",
    "        break\n",
    "print(\"Exemplars:\", [e[\"nlq\"] for e in REACT_EXEMPLARS])\n",
    "\n",
    "runner = QueryRunner(engine)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b3611c",
   "metadata": {},
   "source": [
    "### Load model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f38fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3) Load model (base or QLoRA adapters)\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from peft import PeftModel\n",
    "\n",
    "MODEL_ID = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "ADAPTER_PATH = os.getenv(\"ADAPTER_PATH\") or \"results/adapters/qlora_classicmodels\"  # set to None to use base model\n",
    "\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\") or os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "if not HF_TOKEN:\n",
    "    HF_TOKEN = getpass(\"Enter HF_TOKEN (https://huggingface.co/settings/tokens): \").strip()\n",
    "\n",
    "cc_major, cc_minor = torch.cuda.get_device_capability(0) if torch.cuda.is_available() else (0, 0)\n",
    "use_bf16 = cc_major >= 8\n",
    "compute_dtype = torch.bfloat16 if use_bf16 else torch.float16\n",
    "print(\"GPU:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\")\n",
    "print(\"Using bf16:\", use_bf16)\n",
    "print(\"Adapter path:\", ADAPTER_PATH)\n",
    "\n",
    "# Tokenizer\n",
    "tok = AutoTokenizer.from_pretrained(MODEL_ID, token=HF_TOKEN)\n",
    "if tok.pad_token is None:\n",
    "    tok.pad_token = tok.eos_token\n",
    "\n",
    "# Quantized base model\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    ")\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    quantization_config=bnb_config,\n",
    "    torch_dtype=compute_dtype,\n",
    "    device_map={\"\": 0} if torch.cuda.is_available() else None,\n",
    "    token=HF_TOKEN,\n",
    ")\n",
    "base_model.generation_config.do_sample = False\n",
    "base_model.generation_config.temperature = 1.0\n",
    "base_model.generation_config.top_p = 1.0\n",
    "\n",
    "# Load adapters if present locally; otherwise use base model\n",
    "adapter_dir = Path(ADAPTER_PATH) if ADAPTER_PATH else None\n",
    "if adapter_dir and adapter_dir.exists():\n",
    "    model = PeftModel.from_pretrained(base_model, adapter_dir, token=HF_TOKEN)\n",
    "    print(\"Loaded adapters from\", adapter_dir)\n",
    "else:\n",
    "    print(\"Adapter path missing; using base model only. Set ADAPTER_PATH to your local adapter folder or upload it to Colab.\")\n",
    "    model = base_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7065790e",
   "metadata": {},
   "source": [
    "### Optional: smoke check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fbae86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nl2sql.prompting import make_few_shot_messages\n",
    "from nl2sql.llm import extract_first_select\n",
    "from nl2sql.postprocess import guarded_postprocess\n",
    "from nl2sql.eval import execution_accuracy\n",
    "\n",
    "runner_check = QueryRunner(engine)\n",
    "# reuse existing test_set (default small slice); pick 3 exemplars\n",
    "exemplars = test_set[:3]\n",
    "\n",
    "def run_quick_check(k: int = 0, limit: int = 3):\n",
    "    print(f\"Quick check k={k}\")\n",
    "    for sample in test_set[:limit]:\n",
    "        shots = exemplars if k > 0 else []\n",
    "        msgs = make_few_shot_messages(\n",
    "            schema=SCHEMA_SUMMARY,\n",
    "            exemplars=shots,\n",
    "            nlq=sample['nlq'],\n",
    "        )\n",
    "        prompt_preview = tok.apply_chat_template(msgs, tokenize=False, add_generation_prompt=True)\n",
    "        inputs = tok(prompt_preview, return_tensors=\"pt\").to(model.device)\n",
    "        out = model.generate(**inputs, max_new_tokens=256, do_sample=False)\n",
    "\n",
    "        # strip the prompt before decoding the generation\n",
    "        gen_ids = out[0][inputs.input_ids.shape[-1]:]\n",
    "        text = tok.decode(gen_ids, skip_special_tokens=True)\n",
    "\n",
    "        raw_sql = extract_first_select(text) or text\n",
    "        sql = guarded_postprocess(raw_sql, sample['nlq'])\n",
    "\n",
    "        meta = runner_check.run(sql, capture_df=False)\n",
    "        va = meta.success\n",
    "        ex_ok, _, _ = execution_accuracy(engine=engine, pred_sql=sql, gold_sql=sample['sql'])\n",
    "        err = meta.error\n",
    "        print(f\"Q: {sample['nlq']}\\nSQL: {sql}\\nVA: {va} EX: {ex_ok}\")\n",
    "        if not va:\n",
    "            print(f\"ERR: {err}\")\n",
    "        print()\n",
    "\n",
    "run_quick_check(k=0)\n",
    "run_quick_check(k=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524f4b1f",
   "metadata": {},
   "source": [
    "### Guardrails imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b07b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Agent utilities + guardrails\n",
    "from nl2sql.agent_utils import (\n",
    "    intent_constraints,\n",
    "    semantic_score,\n",
    "    classify_intent,\n",
    "    clean_candidate_with_reason,\n",
    "    vanilla_candidate,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8952b8ec",
   "metadata": {},
   "source": [
    "## Tool-Driven ReAct Loop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d555900",
   "metadata": {},
   "source": [
    "### Define ReAct loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fed5d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Tool-driven ReAct loop (explicit Thought/Action/Observation)\n",
    "import re\n",
    "import time\n",
    "from nl2sql.prompts import REACT_SYSTEM_PROMPT\n",
    "from nl2sql.agent_tools import (\n",
    "    AgentContext,\n",
    "# Note: SQL generation uses a fixed 128-token cap in agent_tools.generate_sql/repair_sql.\n",
    "    set_agent_context,\n",
    "    get_schema,\n",
    "    schema_to_text,\n",
    "    link_schema,\n",
    "    generate_sql,\n",
    "    extract_constraints,\n",
    "    validate_sql,\n",
    "    validate_constraints,\n",
    "    run_sql,\n",
    "    repair_sql,\n",
    "    finish,\n",
    ")\n",
    "\n",
    "# Tool rationale (why each tool exists):\n",
    "# - get_schema: ground the model in real tables/columns to avoid hallucinations.\n",
    "# - schema_to_text: convert schema to a readable prompt format (stable context).\n",
    "# - link_schema: prune schema to likely tables and expose link_debug (scores/value hints) for auditability.\n",
    "# - extract_constraints: pull structure cues (COUNT/GROUP BY/LIMIT) + value/location hints for light value-linking.\n",
    "# - generate_sql: model proposes a candidate given the focused schema + constraints.\n",
    "# - validate_sql: fail fast on non-SELECT or unknown table/column before execution.\n",
    "# - validate_constraints: enforce required structure and value/location hints (prevents \"runs but wrong\" SQL).\n",
    "# - run_sql: execution feedback signal (oracle-style) that drives repair.\n",
    "# - repair_sql: use the most recent error to fix SQL (execution-guided recovery).\n",
    "# - finish: return only after successful run (auto-finish after intent check).\n",
    "\n",
    "TOOLS = {\n",
    "    \"get_schema\": get_schema,\n",
    "    \"schema_to_text\": schema_to_text,\n",
    "    \"link_schema\": link_schema,\n",
    "    \"extract_constraints\": extract_constraints,\n",
    "    \"generate_sql\": generate_sql,\n",
    "    \"validate_sql\": validate_sql,\n",
    "    \"validate_constraints\": validate_constraints,\n",
    "    \"run_sql\": run_sql,\n",
    "    \"repair_sql\": repair_sql,\n",
    "    \"finish\": finish,\n",
    "}\n",
    "\n",
    "def _debug_event(step: int, phase: str, info: dict) -> None:\n",
    "    print(f\"[DBG] step {step} | {phase} | {info}\")\n",
    "\n",
    "\n",
    "def _summarize_sql(sql: str | None) -> str:\n",
    "    if not sql:\n",
    "        return \"<empty>\"\n",
    "    s = \" \".join(str(sql).split())\n",
    "    return s if len(s) <= 240 else s[:240] + \"...\"\n",
    "\n",
    "\n",
    "\n",
    "# Configure tool context (single source for engine/model/runner)\n",
    "# Note: tools are stateful; this binds engine/model/runner once for the loop.\n",
    "set_agent_context(\n",
    "    AgentContext(\n",
    "        engine=engine,\n",
    "        db_name=DB_NAME,\n",
    "        model=model,\n",
    "        tok=tok,\n",
    "        runner=runner,\n",
    "        max_new_tokens=128,\n",
    "    )\n",
    ")\n",
    "\n",
    "# ReAct loop hyperparameters (tuned for stability + cost)\n",
    "# - REACT_MAX_STEPS: bound loop length for auditability\n",
    "# - REACT_MAX_NEW_TOKENS: cap per-step generation to avoid run-on text\n",
    "# - REACT_DO_SAMPLE: deterministic by default for reproducibility\n",
    "# - REACT_TEMPERATURE / REACT_TOP_P: sampling controls if enabled\n",
    "# - USE_LINK_SCHEMA: prune schema to reduce wrong joins\n",
    "# - MAX_CLEAN_REJECT_RETRIES: allow one regenerate after guardrails reject\n",
    "REACT_MAX_STEPS = 8\n",
    "REACT_MAX_NEW_TOKENS = 256\n",
    "REACT_DO_SAMPLE = False\n",
    "REACT_TEMPERATURE = 0.2\n",
    "REACT_TOP_P = 0.9\n",
    "USE_LINK_SCHEMA = True  # can be overridden by quick-test toggles later\n",
    "MAX_CLEAN_REJECT_RETRIES = 1  # force one re-generate if guardrails return empty\n",
    "REACT_RERANK_CANDS = 3  # number of SQL candidates to generate for reranking\n",
    "REACT_RERANK_DO_SAMPLE = True  # enable sampling when reranking\n",
    "REACT_RERANK_TEMPERATURE = 0.3\n",
    "REACT_RERANK_TOP_P = 0.9\n",
    "\n",
    "# Parse model Action lines like: Action: tool_name[json_args]\n",
    "# Important: models sometimes emit multiple Action blocks in one response.\n",
    "# We parse all Action lines and take the last as the model's final decision.\n",
    "_ACTION_RE = re.compile(\n",
    "    r'^\\s*Action:\\s*([a-zA-Z_][a-zA-Z0-9_]*)\\s*\\[(.*?)\\]\\s*$',\n",
    "    re.IGNORECASE | re.MULTILINE | re.DOTALL,\n",
    ")\n",
    "\n",
    "\n",
    "def _call_react_llm(history: str) -> str:\n",
    "    # Rationale: run the model with the ReAct system prompt + running history.\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": REACT_SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": history},\n",
    "    ]\n",
    "    input_ids = tok.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=True,\n",
    "        add_generation_prompt=True,\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(model.device)\n",
    "    # Some tokenizers share pad/eos ids, which prevents generate() from inferring an\n",
    "    # attention mask reliably. Our prompts are not padded, so an all-ones mask is valid.\n",
    "    attention_mask = torch.ones_like(input_ids)\n",
    "\n",
    "    gen_kwargs = {\n",
    "        \"max_new_tokens\": REACT_MAX_NEW_TOKENS,\n",
    "        \"do_sample\": REACT_DO_SAMPLE,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"pad_token_id\": getattr(tok, \"pad_token_id\", getattr(tok, \"eos_token_id\", None)),\n",
    "        \"eos_token_id\": getattr(tok, \"eos_token_id\", None),\n",
    "    }\n",
    "    if REACT_DO_SAMPLE:\n",
    "        gen_kwargs.update({\"temperature\": REACT_TEMPERATURE, \"top_p\": REACT_TOP_P})\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = model.generate(input_ids, **gen_kwargs)\n",
    "\n",
    "    gen_ids = out[0][input_ids.shape[-1] :]\n",
    "    gen_text = tok.decode(gen_ids, skip_special_tokens=True)\n",
    "    return gen_text.strip()\n",
    "\n",
    "\n",
    "def _normalize_llm_text(text: str) -> str:\n",
    "    # Rationale: models sometimes wrap actions in code fences or add trailing prose.\n",
    "    # We strip common wrappers so Action parsing is stable.\n",
    "    t = (text or \"\").replace(\"```json\", \"```\").replace(\"```sql\", \"```\")\n",
    "    t = re.sub(r\"```(.*?)```\", r\"\\1\", t, flags=re.DOTALL)\n",
    "    return t.strip()\n",
    "\n",
    "\n",
    "def _parse_action(text: str) -> tuple[str | None, dict]:\n",
    "    # Rationale: extract the last Action so we follow the most recent tool choice.\n",
    "    text = _normalize_llm_text(text)\n",
    "    matches = list(_ACTION_RE.finditer(text))\n",
    "    if not matches:\n",
    "        return None, {}\n",
    "    m = matches[-1]\n",
    "    name = m.group(1).strip()\n",
    "    raw_args = (m.group(2) or \"\").strip()\n",
    "    if not raw_args:\n",
    "        return name, {}\n",
    "    try:\n",
    "        parsed = json.loads(raw_args)\n",
    "    except Exception:\n",
    "        return name, {}\n",
    "    return name, parsed if isinstance(parsed, dict) else {}\n",
    "\n",
    "\n",
    "def _canonicalize_table_casing(sql: str, schema_text: str) -> str:\n",
    "    # Rationale: normalize table casing to match schema for clearer traces.\n",
    "    if not sql or not schema_text:\n",
    "        return sql\n",
    "    tables = []\n",
    "    for line in schema_text.splitlines():\n",
    "        if \"(\" in line and \")\" in line:\n",
    "            tables.append(line.split(\"(\", 1)[0].strip())\n",
    "    out = sql\n",
    "    for t in tables:\n",
    "        out = re.sub(rf\"\\b{re.escape(t)}\\b\", t, out, flags=re.IGNORECASE)\n",
    "    return out\n",
    "\n",
    "\n",
    "def _print_guardrail_stage(label: str, before: str, after: str, *, reason: str | None = None, max_chars: int = 320, show_unchanged: bool = False) -> None:\n",
    "    # Rationale: explain what each guardrail changed (if anything).\n",
    "    before = \"\" if before is None else str(before)\n",
    "    after = \"\" if after is None else str(after)\n",
    "    if reason and not after:\n",
    "        print(f\"{label}: reject ({reason})\")\n",
    "        return\n",
    "    if before.strip() == after.strip():\n",
    "        if show_unchanged:\n",
    "            print(f\"{label}: unchanged\")\n",
    "        return\n",
    "    print(f\"{label}: changed\")\n",
    "    print(\"  before:\", _truncate_text(before, max_chars=max_chars))\n",
    "    print(\"  after: \", _truncate_text(after, max_chars=max_chars))\n",
    "\n",
    "\n",
    "def _apply_guardrails(raw_sql: str, nlq: str, schema_text: str) -> tuple[str, str | None, dict]:\n",
    "    # Rationale: deterministic cleanup before validation/execution to keep behavior explainable.\n",
    "    stages: dict = {\"raw\": raw_sql}\n",
    "    sql, reason = clean_candidate_with_reason(raw_sql)\n",
    "    stages[\"clean\"] = sql\n",
    "    stages[\"clean_reason\"] = reason\n",
    "    if not sql:\n",
    "        return \"\", f\"clean_reject:{reason}\", stages\n",
    "    post = guarded_postprocess(sql, nlq)\n",
    "    stages[\"postprocess\"] = post\n",
    "    canon = _canonicalize_table_casing(post, schema_text)\n",
    "    stages[\"casing\"] = canon\n",
    "    return canon, None, stages\n",
    "\n",
    "\n",
    "def _rerank_candidates(nlq: str, schema_text: str, constraints: dict, cands: list[str]) -> tuple[str, dict]:\n",
    "    \"\"\"Pick the best candidate by validate_sql -> validate_constraints -> semantic_score.\"\"\"\n",
    "    scored = []\n",
    "    for sql in cands:\n",
    "        if not sql:\n",
    "            scored.append((False, False, -1e9, sql, \"empty\"))\n",
    "            continue\n",
    "        v = validate_sql(sql, schema_text)\n",
    "        ok_sql = bool(v.get(\"valid\"))\n",
    "        if not ok_sql:\n",
    "            scored.append((False, False, -1e9, sql, \"validate_sql:\" + str(v.get(\"reason\"))))\n",
    "            continue\n",
    "        c_ok = True\n",
    "        if constraints:\n",
    "            c = validate_constraints(sql, constraints)\n",
    "            c_ok = bool(c.get(\"valid\"))\n",
    "            if not c_ok:\n",
    "                scored.append((True, False, -1e9, sql, \"validate_constraints:\" + str(c.get(\"reason\"))))\n",
    "                continue\n",
    "        s = semantic_score(nlq, sql)\n",
    "        scored.append((True, c_ok, s, sql, \"ok\"))\n",
    "    scored.sort(key=lambda x: (x[0], x[1], x[2]), reverse=True)\n",
    "    best = scored[0] if scored else (False, False, -1e9, \"\", \"empty\")\n",
    "    return best[3], {\"ranked\": scored[:5]}\n",
    "\n",
    "def log_decision(decisions: list[dict], step: int, decision: str, reason: str, data: dict | None = None, status: str = \"ok\") -> dict:\n",
    "    entry = {\"step\": step, \"decision\": decision, \"reason\": reason, \"status\": status}\n",
    "    if data is not None:\n",
    "        entry[\"data\"] = data\n",
    "    decisions.append(entry)\n",
    "    return entry\n",
    "\n",
    "\n",
    "def format_decision_log(decisions: list[dict], max_items: int | None = 20) -> str:\n",
    "    if not decisions:\n",
    "        return \"(no decisions logged)\"\n",
    "    out: list[str] = []\n",
    "    limit = max_items or len(decisions)\n",
    "    for d in decisions[:limit]:\n",
    "        line = f\"[step {d.get('step')}] {d.get('decision')} â€” {d.get('reason')} ({d.get('status')})\"\n",
    "        out.append(line)\n",
    "        data = d.get(\"data\")\n",
    "        if data is not None:\n",
    "            try:\n",
    "                snippet = json.dumps(data, ensure_ascii=False)\n",
    "            except Exception:\n",
    "                snippet = str(data)\n",
    "            if len(snippet) > 400:\n",
    "                snippet = snippet[:397] + \"...\"\n",
    "            out.append(f\"  data: {snippet}\")\n",
    "    return \"\\n\".join(out)\n",
    "\n",
    "\n",
    "def summarize_trace(trace: list[dict]) -> dict:\n",
    "    actions = [t.get(\"action\") for t in trace if t.get(\"action\")]\n",
    "    attempted = [t.get(\"attempted_action\") for t in trace if t.get(\"attempted_action\") is not None]\n",
    "    blocked_steps = sum(1 for t in trace if t.get(\"blocked\"))\n",
    "    forced_repairs = [t for t in trace if t.get(\"forced_action\") == \"repair_sql\"]\n",
    "    repair_count = sum(1 for t in trace if t.get(\"action\") == \"repair_sql\")\n",
    "    errors: list[str] = []\n",
    "    for i, a in enumerate(actions):\n",
    "        if a == \"generate_sql\" and \"extract_constraints\" not in actions[:i]:\n",
    "            errors.append(\"generate_without_constraints\")\n",
    "        if a == \"run_sql\" and \"validate_sql\" not in actions[:i]:\n",
    "            errors.append(\"run_without_validate\")\n",
    "        if a == \"run_sql\" and \"validate_constraints\" not in actions[:i]:\n",
    "            errors.append(\"run_without_validate_constraints\")\n",
    "        if a == \"finish\" and \"run_sql\" not in actions[:i]:\n",
    "            errors.append(\"finish_without_run\")\n",
    "    compliance_ok = len(errors) == 0\n",
    "    return {\n",
    "        \"actions\": actions,\n",
    "        \"attempted_actions\": attempted,\n",
    "        \"blocked_steps\": blocked_steps,\n",
    "        \"repairs\": repair_count,\n",
    "        \"forced_repairs\": len(forced_repairs),\n",
    "        \"compliance_ok\": compliance_ok,\n",
    "        \"compliance_errors\": errors,\n",
    "    }\n",
    "\n",
    "\n",
    "def _truncate_text(s: str, max_chars: int = 1200) -> str:\n",
    "    if s is None:\n",
    "        return \"\"\n",
    "    s = str(s)\n",
    "    if max_chars <= 0 or len(s) <= max_chars:\n",
    "        return s\n",
    "    return s[: max_chars - 3] + \"...\"\n",
    "\n",
    "\n",
    "def _print_prompt_tail(prompt: str, *, tail_lines: int = 30, max_line_chars: int = 200) -> None:\n",
    "    if not prompt:\n",
    "        print(\"(empty prompt)\")\n",
    "        return\n",
    "    lines = prompt.splitlines()\n",
    "    tail = lines[-max(1, int(tail_lines)) :]\n",
    "    for ln in tail:\n",
    "        if max_line_chars and len(ln) > max_line_chars:\n",
    "            ln = ln[: max_line_chars - 3] + \"...\"\n",
    "        print(ln)\n",
    "\n",
    "\n",
    "_TOOL_EXPLAIN: dict[str, str] = {\n",
    "    \"get_schema\": \"Look up the database tables/columns (ground truth).\",\n",
    "    \"link_schema\": \"Focus on the most relevant tables/columns for this question (debug shows link scores + value hints).\",\n",
    "    \"extract_constraints\": \"Infer structural needs (COUNT, GROUP BY, LIMIT, DISTINCT, etc.).\",\n",
    "    \"generate_sql\": \"Draft a SQL query for the question.\",\n",
    "    \"validate_sql\": \"Check the SQL is safe/valid (single SELECT + known schema refs).\",\n",
    "    \"validate_constraints\": \"Check the SQL matches the question's required structure.\",\n",
    "    \"run_sql\": \"Run the SQL against the DB and observe results/errors.\",\n",
    "    \"repair_sql\": \"Fix the SQL using the latest error feedback.\",\n",
    "    \"finish\": \"Return the final SQL (only after a successful run).\",\n",
    "}\n",
    "\n",
    "\n",
    "def _extract_last_thought(text: str) -> str:\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    for line in reversed(text.splitlines()):\n",
    "        if line.strip().lower().startswith(\"thought:\"):\n",
    "            return line.split(\":\", 1)[1].strip()\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def _friendly_progress(\n",
    "    *,\n",
    "    constraints: dict | None,\n",
    "    last_sql: str | None,\n",
    "    last_valid: bool | None,\n",
    "    last_constraints_ok: bool | None,\n",
    "    last_run: dict | None,\n",
    ") -> str:\n",
    "    parts = []\n",
    "    parts.append(\"constraints: \" + (\"done\" if constraints else \"pending\"))\n",
    "    parts.append(\"sql draft: \" + (\"done\" if last_sql else \"pending\"))\n",
    "    if last_valid is None:\n",
    "        parts.append(\"sql check: pending\")\n",
    "    else:\n",
    "        parts.append(\"sql check: \" + (\"pass\" if last_valid else \"fail\"))\n",
    "    if last_constraints_ok is None:\n",
    "        parts.append(\"shape check: pending\")\n",
    "    else:\n",
    "        parts.append(\"shape check: \" + (\"pass\" if last_constraints_ok else \"fail\"))\n",
    "    if last_run is None:\n",
    "        parts.append(\"run: pending\")\n",
    "    else:\n",
    "        parts.append(\"run: \" + (\"pass\" if last_run.get(\"success\") else \"fail\"))\n",
    "    return \" | \".join(parts)\n",
    "\n",
    "\n",
    "\n",
    "def react_sql(\n",
    "    *,\n",
    "    nlq: str,\n",
    "    schema_text: str | None = None,\n",
    "    schema_summary: str | None = None,\n",
    "    exemplars: list[dict] | None = None,\n",
    "    max_steps: int = REACT_MAX_STEPS,\n",
    "    debug: bool = False,\n",
    "    debug_sleep_s: float = 0.0,\n",
    "    debug_prompt_tail_lines: int = 0,\n",
    "    debug_rows_preview: int = 3,\n",
    "    auto_order: bool = False,  # If True, force the next required tool step (demo-friendly).\n",
    ") -> tuple[str, list[dict], list[dict]]:\n",
    "    trace: list[dict] = []\n",
    "    history: list[str] = []\n",
    "    decision_log: list[dict] = []\n",
    "\n",
    "    schema = get_schema()\n",
    "    schema_text_full = schema_to_text(schema)\n",
    "    schema_text_focus = schema_text_full\n",
    "\n",
    "    schema_tables = [line.split(\"(\", 1)[0].strip() for line in schema_text_full.splitlines() if \"(\" in line]\n",
    "\n",
    "    # Trace bootstrap (required): user question + get_schema + link_schema\n",
    "    history.append(f\"User question: {nlq}\")\n",
    "    history.append(\"Action: get_schema[{}]\")\n",
    "    history.append(f\"Observation: {schema_text_full}\")\n",
    "    log_decision(decision_log, -1, \"get_schema\", \"loaded schema\", {\"tables\": schema_tables})\n",
    "\n",
    "    link_obs = link_schema(nlq, schema_text_full, max_tables=6 if USE_LINK_SCHEMA else 0)\n",
    "    link_debug = link_obs.get(\"link_debug\") or {}\n",
    "    schema_text_focus = link_obs.get(\"schema_text\") or schema_text_full\n",
    "    history.append('Action: link_schema[{\"max_tables\": 6}]')\n",
    "    history.append(f\"Observation: {schema_text_focus}\")\n",
    "    log_decision(decision_log, -1, \"link_schema\", \"prune schema context\", link_obs)\n",
    "\n",
    "    if debug:\n",
    "        print(\"=\" * 80)\n",
    "        print(\"ReAct walkthrough (tool-driven NL->SQL)\")\n",
    "        print(\"NLQ:\", nlq)\n",
    "        print(\"What you'll see: a small set of tools run in order until the SQL executes.\")\n",
    "        print(\"Order: schema -> focus -> requirements -> draft -> checks -> run -> finish\")\n",
    "        print()\n",
    "        print(\"[Bootstrap]\")\n",
    "        print(f\"- schema tables: {len(schema_tables)}\")\n",
    "        focus_lines = schema_text_focus.splitlines()\n",
    "        print(f\"- link_schema enabled: {bool(USE_LINK_SCHEMA)} | changed: {bool(link_obs.get('changed'))} | focus lines: {len(focus_lines)}\")\n",
    "        if link_debug:\n",
    "            value_hints = link_debug.get(\"value_hints\") or []\n",
    "            if value_hints:\n",
    "                print(\"- value hints:\", \", \".join(value_hints))\n",
    "            value_columns = link_debug.get(\"value_columns\") or []\n",
    "            if value_columns:\n",
    "                print(\"- value columns:\", \", \".join(value_columns))\n",
    "            selected_tables = link_debug.get(\"selected_tables\") or []\n",
    "            if selected_tables:\n",
    "                print(\"- selected tables:\", \", \".join(selected_tables))\n",
    "            location_tables = link_debug.get(\"location_tables\") or []\n",
    "            if location_tables:\n",
    "                print(\"- location tables:\", \", \".join(location_tables))\n",
    "            table_scores = link_debug.get(\"table_scores\") or {}\n",
    "            table_reasons = link_debug.get(\"table_reasons\") or {}\n",
    "            if table_scores:\n",
    "                top_tables = sorted(table_scores.items(), key=lambda kv: (-kv[1], kv[0]))[:3]\n",
    "                score_bits = []\n",
    "                for t, s in top_tables:\n",
    "                    reasons = \", \".join(table_reasons.get(t, []))\n",
    "                    if reasons:\n",
    "                        score_bits.append(f\"{t}({s:.1f}; {reasons})\")\n",
    "                    else:\n",
    "                        score_bits.append(f\"{t}({s:.1f})\")\n",
    "                print(\"- top link scores:\", \"; \".join(score_bits))\n",
    "                print(\"- score basis: hint(+3), table overlap(+2), column overlap(+1 each, capped), location boost(+1.5)\")\n",
    "                col_scores = link_debug.get(\"column_scores\") or {}\n",
    "                sel_cols = link_debug.get(\"selected_columns\") or {}\n",
    "                if col_scores:\n",
    "                    top_col_bits = []\n",
    "                    for t, scores in col_scores.items():\n",
    "                        top_cols = sorted(scores.items(), key=lambda kv: (-kv[1], kv[0]))[:3]\n",
    "                        top_cols = [f\"{c}({s:.1f})\" for c, s in top_cols]\n",
    "                        if top_cols:\n",
    "                            top_col_bits.append(f\"{t}: \" + \", \".join(top_cols))\n",
    "                        if len(top_col_bits) >= 2:\n",
    "                            break\n",
    "                    if top_col_bits:\n",
    "                        print(\"- top column scores:\", \"; \".join(top_col_bits))\n",
    "                if sel_cols:\n",
    "                    shown = []\n",
    "                    for t, cols in sel_cols.items():\n",
    "                        shown.append(f\"{t}: {', '.join(cols[:6])}\")\n",
    "                        if len(shown) >= 2:\n",
    "                            break\n",
    "                    if shown:\n",
    "                        print(\"- selected columns (sample):\", \"; \".join(shown))\n",
    "\n",
    "        if focus_lines:\n",
    "            focus_tables = [ln.split(\"(\", 1)[0].strip() for ln in focus_lines if \"(\" in ln and \")\" in ln]\n",
    "            focus_tables = [t for t in focus_tables if t]\n",
    "            if focus_tables:\n",
    "                print(\"- focused tables:\", \", \".join(focus_tables))\n",
    "            join_hint_lines = [ln for ln in focus_lines if ln.lower().startswith(\"join hints:\")]\n",
    "            if join_hint_lines:\n",
    "                print(\"- join hints included: yes\")\n",
    "        print(\"=\" * 80)\n",
    "\n",
    "    last_sql: str | None = None\n",
    "    last_error: str | None = None\n",
    "    last_run: dict | None = None\n",
    "    last_valid: bool | None = None\n",
    "    last_constraints_ok: bool | None = None\n",
    "    constraints: dict | None = None\n",
    "    pending_repair_error: str | None = None\n",
    "    pending_force_generate: str | None = None\n",
    "    clean_reject_retries = 0\n",
    "\n",
    "    for step in range(max_steps):\n",
    "        prompt = \"\\n\".join(history)\n",
    "\n",
    "        if debug:\n",
    "            print(\"\\n\" + \"-\" * 80)\n",
    "            print(f\"STEP {step} / {max_steps - 1}\")\n",
    "            print(\n",
    "                _friendly_progress(\n",
    "                    constraints=constraints,\n",
    "                    last_sql=last_sql,\n",
    "                    last_valid=last_valid,\n",
    "                    last_constraints_ok=last_constraints_ok,\n",
    "                    last_run=last_run,\n",
    "                )\n",
    "            )\n",
    "            if debug_prompt_tail_lines and int(debug_prompt_tail_lines) > 0:\n",
    "                print(\"\\nTranscript tail (what the LLM sees):\")\n",
    "                _print_prompt_tail(prompt, tail_lines=int(debug_prompt_tail_lines))\n",
    "\n",
    "        llm_out = _call_react_llm(prompt)\n",
    "        trace.append({\"step\": step, \"llm\": llm_out})\n",
    "\n",
    "        action, args = _parse_action(llm_out)\n",
    "        if not isinstance(args, dict):\n",
    "            args = {}\n",
    "        attempted_action = action\n",
    "        attempted_args = dict(args)\n",
    "        history.append(llm_out.strip())\n",
    "\n",
    "        if debug:\n",
    "            thought = _extract_last_thought(llm_out)\n",
    "            if thought:\n",
    "                print(\"\\nModel thought:\", _truncate_text(thought, max_chars=240))\n",
    "            print(\"Model action:\", action)\n",
    "\n",
    "        # If we have a pending validation/execution error, force a repair action.\n",
    "        if pending_repair_error and action != \"repair_sql\":\n",
    "            trace.append({\"step\": step, \"forced_action\": \"repair_sql\", \"requested_action\": action, \"reason\": pending_repair_error})\n",
    "            log_decision(decision_log, step, \"force_repair\", pending_repair_error, {\"requested_action\": action})\n",
    "            action = \"repair_sql\"\n",
    "            args = {\"error\": pending_repair_error, \"forced\": True}\n",
    "            history[-1] = f\"Action: repair_sql[{json.dumps(args, ensure_ascii=False)}]\"\n",
    "            if debug:\n",
    "                print(f\"FORCED -> repair_sql (reason: {pending_repair_error})\")\n",
    "\n",
    "        # If guardrails returned empty SQL, force one regenerate.\n",
    "        if pending_force_generate and action != \"generate_sql\":\n",
    "            trace.append({\"step\": step, \"forced_action\": \"generate_sql\", \"requested_action\": action, \"reason\": pending_force_generate})\n",
    "            log_decision(decision_log, step, \"force_generate_sql\", pending_force_generate, {\"requested_action\": action})\n",
    "            action = \"generate_sql\"\n",
    "            args = {\"constraints\": constraints} if constraints else {}\n",
    "            history[-1] = f\"Action: generate_sql[{json.dumps(args, ensure_ascii=False)}]\"\n",
    "            pending_force_generate = None\n",
    "            if debug:\n",
    "                print(\"FORCED -> generate_sql (one retry after guardrail reject)\")\n",
    "\n",
    "        if constraints is None and action not in (\"extract_constraints\", \"repair_sql\"):\n",
    "            trace.append({\"step\": step, \"forced_action\": \"extract_constraints\", \"requested_action\": action, \"reason\": \"constraints_missing\"})\n",
    "            log_decision(decision_log, step, \"force_extract_constraints\", \"constraints_missing\", {\"requested_action\": action})\n",
    "            action = \"extract_constraints\"\n",
    "            args = {}\n",
    "            history[-1] = \"Action: extract_constraints[{}]\"\n",
    "            if debug:\n",
    "                print(\"FORCED -> extract_constraints (constraints missing)\")\n",
    "\n",
    "        # If the model tries to jump ahead (run_sql/finish), redirect to the next required step.\n",
    "        # This avoids burning the step budget on blocked actions and keeps traces easier to read.\n",
    "        if not auto_order and action in (\"run_sql\", \"finish\"):\n",
    "            if pending_repair_error:\n",
    "                required = \"repair_sql\"\n",
    "            elif pending_force_generate:\n",
    "                required = \"generate_sql\"\n",
    "            elif constraints is None:\n",
    "                required = \"extract_constraints\"\n",
    "            elif last_sql is None:\n",
    "                required = \"generate_sql\"\n",
    "            elif last_valid is None:\n",
    "                required = \"validate_sql\"\n",
    "            elif last_valid is False:\n",
    "                required = \"repair_sql\"\n",
    "            elif last_constraints_ok is None:\n",
    "                required = \"validate_constraints\"\n",
    "            elif last_constraints_ok is False:\n",
    "                required = \"repair_sql\"\n",
    "            elif not last_run or not last_run.get(\"success\"):\n",
    "                required = \"run_sql\"\n",
    "            else:\n",
    "                required = \"finish\"\n",
    "\n",
    "            if action != required:\n",
    "                trace.append({\"step\": step, \"forced_action\": required, \"requested_action\": action, \"reason\": \"controller_order\"})\n",
    "                log_decision(decision_log, step, \"force_order\", \"controller_order\", {\"requested_action\": action, \"required_action\": required})\n",
    "                if debug:\n",
    "                    print(f\"FORCED -> {required} (required before {action})\")\n",
    "                action = required\n",
    "                if required == \"generate_sql\":\n",
    "                    args = {\"constraints\": constraints} if constraints else {}\n",
    "                elif required == \"repair_sql\":\n",
    "                    args = {\"error\": pending_repair_error or last_error or \"\"} if (pending_repair_error or last_error) else {}\n",
    "                else:\n",
    "                    args = {}\n",
    "                history[-1] = f\"Action: {required}[{json.dumps(args, ensure_ascii=False)}]\"\n",
    "\n",
    "        # Demo-friendly strict ordering: force the next required step based on state.\n",
    "        # This keeps walkthroughs understandable even when the model proposes out-of-order actions.\n",
    "        if auto_order:\n",
    "            required: str\n",
    "            if pending_repair_error:\n",
    "                required = \"repair_sql\"\n",
    "            elif pending_force_generate:\n",
    "                required = \"generate_sql\"\n",
    "            elif constraints is None:\n",
    "                required = \"extract_constraints\"\n",
    "            elif last_sql is None:\n",
    "                required = \"generate_sql\"\n",
    "            elif last_valid is None:\n",
    "                required = \"validate_sql\"\n",
    "            elif last_valid is False:\n",
    "                required = \"repair_sql\"\n",
    "            elif last_constraints_ok is None:\n",
    "                required = \"validate_constraints\"\n",
    "            elif last_constraints_ok is False:\n",
    "                required = \"repair_sql\"\n",
    "            elif not last_run or not last_run.get(\"success\"):\n",
    "                required = \"run_sql\"\n",
    "            else:\n",
    "                required = \"finish\"\n",
    "\n",
    "            if action != required:\n",
    "                trace.append({\"step\": step, \"forced_action\": required, \"requested_action\": action, \"reason\": \"auto_order\"})\n",
    "                log_decision(decision_log, step, \"force_order\", \"auto_order\", {\"requested_action\": action, \"required_action\": required})\n",
    "                if debug:\n",
    "                    print(f\"FORCED -> {required} (next required step)\")\n",
    "                action = required\n",
    "                if required == \"generate_sql\":\n",
    "                    args = {\"constraints\": constraints} if constraints else {}\n",
    "                elif required == \"repair_sql\":\n",
    "                    args = {\"error\": pending_repair_error or last_error or \"\"} if (pending_repair_error or last_error) else {}\n",
    "                else:\n",
    "                    args = {}\n",
    "                history[-1] = f\"Action: {required}[{json.dumps(args, ensure_ascii=False)}]\"\n",
    "\n",
    "        # If we already ran successfully, force finish to avoid extra tool calls.\n",
    "        if last_run and last_run.get(\"success\") and action != \"finish\":\n",
    "            trace.append({\"step\": step, \"forced_action\": \"finish\", \"requested_action\": action, \"reason\": \"already_successful_run\"})\n",
    "            log_decision(decision_log, step, \"force_finish\", \"already_successful_run\", {\"requested_action\": action})\n",
    "            if debug:\n",
    "                print(\"FORCED -> finish (run_sql already succeeded)\")\n",
    "            action = \"finish\"\n",
    "            args = {}\n",
    "            history[-1] = \"Action: finish[{}]\"\n",
    "\n",
    "        if action is None:\n",
    "            obs = {\"error\": \"No Action found. Respond with Action: tool[json_args].\"}\n",
    "            history.append(f\"Observation: {json.dumps(obs, ensure_ascii=False)}\")\n",
    "            trace.append(\n",
    "                {\n",
    "                    \"step\": step,\n",
    "                    \"attempted_action\": attempted_action,\n",
    "                    \"attempted_args\": attempted_args,\n",
    "                    \"action\": None,\n",
    "                    \"args\": {},\n",
    "                    \"observation\": obs,\n",
    "                    \"blocked\": True,\n",
    "                }\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        if action not in TOOLS:\n",
    "            obs = {\"error\": f\"Unknown action: {action}\"}\n",
    "            history.append(f\"Observation: {json.dumps(obs, ensure_ascii=False)}\")\n",
    "            trace.append(\n",
    "                {\n",
    "                    \"step\": step,\n",
    "                    \"attempted_action\": attempted_action,\n",
    "                    \"attempted_args\": attempted_args,\n",
    "                    \"action\": None,\n",
    "                    \"args\": {},\n",
    "                    \"observation\": obs,\n",
    "                    \"blocked\": True,\n",
    "                }\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        # Setup-only tools should not be executed inside the main loop.\n",
    "        if action in (\"get_schema\", \"link_schema\"):\n",
    "            obs = {\"error\": f\"{action} is setup-only and already executed.\"}\n",
    "            history.append(f\"Observation: {json.dumps(obs, ensure_ascii=False)}\")\n",
    "            trace.append(\n",
    "                {\n",
    "                    \"step\": step,\n",
    "                    \"attempted_action\": attempted_action,\n",
    "                    \"attempted_args\": attempted_args,\n",
    "                    \"action\": None,\n",
    "                    \"args\": {},\n",
    "                    \"observation\": obs,\n",
    "                    \"blocked\": True,\n",
    "                }\n",
    "            )\n",
    "            log_decision(decision_log, step, \"blocked_setup_action\", action, {\"attempted_action\": attempted_action})\n",
    "            if debug:\n",
    "                print(f\"BLOCKED setup action: {action}\")\n",
    "            continue\n",
    "\n",
    "        # Enforce: run_sql must succeed before finish.\n",
    "        if action == \"finish\":\n",
    "            # Rationale: finish is only allowed after a successful execution.\n",
    "            if not last_run or not last_run.get(\"success\"):\n",
    "                obs = {\"error\": \"Must call run_sql successfully before finish.\"}\n",
    "                history.append(f\"Observation: {json.dumps(obs, ensure_ascii=False)}\")\n",
    "                trace.append(\n",
    "                    {\n",
    "                        \"step\": step,\n",
    "                        \"attempted_action\": attempted_action,\n",
    "                        \"attempted_args\": attempted_args,\n",
    "                        \"action\": None,\n",
    "                        \"args\": {},\n",
    "                        \"observation\": obs,\n",
    "                        \"blocked\": True,\n",
    "                    }\n",
    "                )\n",
    "                if debug:\n",
    "                    print(\"FINISH blocked:\", obs[\"error\"])\n",
    "                continue\n",
    "            result = finish(answer=str(last_run.get(\"rows\", [])), sql=last_sql or \"\", provenance={\"trace\": trace})\n",
    "            trace.append(\n",
    "                {\n",
    "                    \"step\": step,\n",
    "                    \"attempted_action\": attempted_action,\n",
    "                    \"attempted_args\": attempted_args,\n",
    "                    \"action\": \"finish\",\n",
    "                    \"args\": {},\n",
    "                    \"observation\": result,\n",
    "                }\n",
    "            )\n",
    "            log_decision(decision_log, step, \"finish\", \"completed\", {\"sql\": result.get(\"sql\", \"\")})\n",
    "            if debug:\n",
    "                print(\"\\nFINISH -> returning final SQL\")\n",
    "                print(result.get(\"sql\", \"\"))\n",
    "            return result.get(\"sql\", \"\"), trace, decision_log\n",
    "\n",
    "        if debug:\n",
    "            expl = _TOOL_EXPLAIN.get(action, \"\")\n",
    "            if expl:\n",
    "                print(f\"\\nTool: {action} â€” {expl}\")\n",
    "            else:\n",
    "                print(f\"\\nTool: {action}\")\n",
    "\n",
    "        executed_action = action\n",
    "        blocked = False\n",
    "        auto_finish = False\n",
    "        auto_finish_payload = None\n",
    "\n",
    "        # Tool execution\n",
    "        if action == \"get_schema\":\n",
    "            obs = schema_text_full\n",
    "            schema_text_focus = schema_text_full\n",
    "            if debug:\n",
    "                print(\"\\nSchema loaded.\")\n",
    "        elif action == \"link_schema\":\n",
    "            # Rationale: prunes schema context to reduce wrong-table joins and overlong prompts.\n",
    "            max_tables = int(args.get(\"max_tables\", 6)) if str(args.get(\"max_tables\", \"\")).isdigit() else 6\n",
    "            res = link_schema(nlq, schema_text_full, max_tables=max_tables if USE_LINK_SCHEMA else 0)\n",
    "            res[\"enabled\"] = bool(USE_LINK_SCHEMA)\n",
    "            schema_text_focus = res.get(\"schema_text\") or schema_text_full\n",
    "            obs = res\n",
    "            if debug:\n",
    "                link_debug = res.get(\"link_debug\") or {}\n",
    "                if link_debug:\n",
    "                    print()\n",
    "                    value_hints = link_debug.get(\"value_hints\") or []\n",
    "                    if value_hints:\n",
    "                        print(\"Value hints:\", \", \".join(value_hints))\n",
    "                    selected_tables = link_debug.get(\"selected_tables\") or []\n",
    "                    if selected_tables:\n",
    "                        print(\"Selected tables:\", \", \".join(selected_tables))\n",
    "                    location_tables = link_debug.get(\"location_tables\") or []\n",
    "                    if location_tables:\n",
    "                        print(\"Location tables:\", \", \".join(location_tables))\n",
    "                    table_scores = link_debug.get(\"table_scores\") or {}\n",
    "                    table_reasons = link_debug.get(\"table_reasons\") or {}\n",
    "                    if table_scores:\n",
    "                        top_tables = sorted(table_scores.items(), key=lambda kv: (-kv[1], kv[0]))[:3]\n",
    "                        score_bits = []\n",
    "                        for t, s in top_tables:\n",
    "                            reasons = \", \".join(table_reasons.get(t, []))\n",
    "                            if reasons:\n",
    "                                score_bits.append(f\"{t}({s:.1f}; {reasons})\")\n",
    "                            else:\n",
    "                                score_bits.append(f\"{t}({s:.1f})\")\n",
    "                        print(\"Top link scores:\", \"; \".join(score_bits))\n",
    "                        print(\"Score basis: hint(+3), table overlap(+2), column overlap(+1 each, capped), location boost(+1.5)\")\n",
    "                schema_preview = (res.get(\"schema_text\") or \"\").strip()\n",
    "                focus_lines = schema_preview.splitlines() if schema_preview else []\n",
    "                focus_tables = [ln.split(\"(\", 1)[0].strip() for ln in focus_lines if \"(\" in ln and \")\" in ln]\n",
    "                focus_tables = [t for t in focus_tables if t]\n",
    "                if focus_tables:\n",
    "                    print()\n",
    "                    print(\"Focused tables:\", \", \".join(focus_tables))\n",
    "                else:\n",
    "                    print()\n",
    "                    print(\"Focused tables: (none)\")\n",
    "\n",
    "\n",
    "        elif action == \"extract_constraints\":\n",
    "            # Rationale: structural cues (COUNT/GROUP BY/LIMIT) are frequent EX failure points.\n",
    "            res = extract_constraints(nlq)\n",
    "            if debug:\n",
    "                _debug_event(step, \"constraints\", {\"agg\": res.get(\"agg\"), \"needs_group_by\": res.get(\"needs_group_by\"), \"needs_order_by\": res.get(\"needs_order_by\"), \"limit\": res.get(\"limit\"), \"distinct\": res.get(\"distinct\"), \"value_hints\": res.get(\"value_hints\"), \"value_columns\": res.get(\"value_columns\"), \"explicit_fields\": res.get(\"explicit_fields\")})\n",
    "            constraints = res\n",
    "            last_constraints_ok = None\n",
    "            obs = res\n",
    "            log_decision(decision_log, step, \"extract_constraints\", \"heuristic extraction\", res)\n",
    "            if debug:\n",
    "                print(\"\\nRequirements extracted:\", res)\n",
    "        elif action == \"generate_sql\":\n",
    "            # Rationale: model generation step; guardrails immediately clean + normalize output.\n",
    "            cand = args.get(\"constraints\")\n",
    "            if isinstance(cand, dict):\n",
    "                constraints = cand\n",
    "            elif cand is not None and debug:\n",
    "                print(\"\\nIgnoring non-dict constraints from model: \", cand)\n",
    "            constraints = constraints or {\"intent\": classify_intent(nlq)}\n",
    "            if debug:\n",
    "                print(\"\\nRequirements:\", constraints)\n",
    "            if REACT_RERANK_CANDS and REACT_RERANK_CANDS > 1:\n",
    "                raw_list = generate_sql(\n",
    "                    nlq,\n",
    "                    schema_text_focus,\n",
    "                    constraints,\n",
    "                    num_cands=REACT_RERANK_CANDS,\n",
    "                    do_sample=REACT_RERANK_DO_SAMPLE,\n",
    "                    temperature=REACT_RERANK_TEMPERATURE,\n",
    "                    top_p=REACT_RERANK_TOP_P,\n",
    "                )\n",
    "                raw_list = raw_list if isinstance(raw_list, list) else [raw_list]\n",
    "                raw_sql, rerank_debug = _rerank_candidates(nlq, schema_text_full, constraints, raw_list)\n",
    "                if debug:\n",
    "                    _debug_event(step, \"rerank\", {\"cands\": len(raw_list), \"picked\": _summarize_sql(raw_sql)})\n",
    "            else:\n",
    "                raw_sql = generate_sql(nlq, schema_text_focus, constraints)\n",
    "                rerank_debug = None\n",
    "            log_decision(decision_log, step, \"generate_sql\", \"model generation\", {\"raw_sql\": raw_sql, \"rerank\": rerank_debug})\n",
    "            sql, reason, stages = _apply_guardrails(raw_sql, nlq, schema_text_full)\n",
    "            if debug:\n",
    "                print(\"\\nDraft SQL (raw):\")\n",
    "                print(_truncate_text(raw_sql, max_chars=2000))\n",
    "                if stages:\n",
    "                    print(\"\\nGuardrails effects:\")\n",
    "                    _print_guardrail_stage(\"clean_candidate\", raw_sql, stages.get(\"clean\"), reason=stages.get(\"clean_reason\"))\n",
    "                    if \"postprocess\" in stages:\n",
    "                        _print_guardrail_stage(\"guarded_postprocess\", stages.get(\"clean\"), stages.get(\"postprocess\"))\n",
    "                    if \"casing\" in stages:\n",
    "                        _print_guardrail_stage(\"canonicalize_casing\", stages.get(\"postprocess\"), stages.get(\"casing\"))\n",
    "            if not sql:\n",
    "                obs = {\"error\": reason, \"raw_sql\": raw_sql, \"hint\": \"Output a single SELECT statement only.\"}\n",
    "                log_decision(decision_log, step, \"guardrails\", \"clean_reject\", {\"reason\": reason, \"raw_sql\": raw_sql}, status=\"reject\")\n",
    "                if clean_reject_retries < MAX_CLEAN_REJECT_RETRIES:\n",
    "                    pending_force_generate = reason\n",
    "                    clean_reject_retries += 1\n",
    "                if debug:\n",
    "                    print(\"\\nGuardrails: REJECT -\", reason)\n",
    "            else:\n",
    "                last_sql = sql\n",
    "                last_error = None\n",
    "                last_valid = None\n",
    "                last_constraints_ok = None\n",
    "                pending_repair_error = None\n",
    "                pending_force_generate = None\n",
    "                obs = {\"sql\": sql}\n",
    "                log_decision(decision_log, step, \"guardrails\", \"cleaned\", {\"cleaned_sql\": sql})\n",
    "                if debug:\n",
    "                    print(\"\\nSQL after guardrails:\")\n",
    "                    print(sql)\n",
    "        elif action == \"repair_sql\":\n",
    "            # Rationale: forced recovery when validation/execution fails.\n",
    "            if not last_sql:\n",
    "                obs = {\"error\": \"No SQL to repair. Call generate_sql first.\"}\n",
    "                blocked = True\n",
    "                executed_action = None\n",
    "            else:\n",
    "                err = args.get(\"error\") or last_error or \"\"\n",
    "                if debug:\n",
    "                    print(\"\\nPrevious SQL:\")\n",
    "                    print(last_sql)\n",
    "                raw_sql = repair_sql(nlq, last_sql, err, schema_text_full)\n",
    "                log_decision(decision_log, step, \"repair_sql\", \"model repair\", {\"error\": err, \"raw_sql\": raw_sql})\n",
    "                sql, reason, stages = _apply_guardrails(raw_sql, nlq, schema_text_full)\n",
    "                if debug:\n",
    "                    print(\"\\nError to fix:\", err)\n",
    "                    print(\"\\nRepair draft (raw):\")\n",
    "                    print(_truncate_text(raw_sql, max_chars=2000))\n",
    "                    if stages:\n",
    "                        print(\"\\nGuardrails effects:\")\n",
    "                        _print_guardrail_stage(\"clean_candidate\", raw_sql, stages.get(\"clean\"), reason=stages.get(\"clean_reason\"))\n",
    "                        if \"postprocess\" in stages:\n",
    "                            _print_guardrail_stage(\"guarded_postprocess\", stages.get(\"clean\"), stages.get(\"postprocess\"))\n",
    "                        if \"casing\" in stages:\n",
    "                            _print_guardrail_stage(\"canonicalize_casing\", stages.get(\"postprocess\"), stages.get(\"casing\"))\n",
    "                if not sql:\n",
    "                    obs = {\"error\": reason, \"raw_sql\": raw_sql}\n",
    "                    log_decision(decision_log, step, \"guardrails\", \"clean_reject\", {\"reason\": reason, \"raw_sql\": raw_sql}, status=\"reject\")\n",
    "                    if debug:\n",
    "                        print(\"\\nGuardrails: REJECT -\", reason)\n",
    "                else:\n",
    "                    last_sql = sql\n",
    "                    last_valid = None\n",
    "                    last_constraints_ok = None\n",
    "                    pending_repair_error = None\n",
    "                    obs = {\"sql\": sql}\n",
    "                    log_decision(decision_log, step, \"guardrails\", \"cleaned\", {\"cleaned_sql\": sql})\n",
    "                    if debug:\n",
    "                        print(\"\\nSQL after guardrails:\")\n",
    "                        print(sql)\n",
    "        elif action == \"validate_sql\":\n",
    "            # Rationale: catch schema/format errors before hitting the database.\n",
    "            if not last_sql:\n",
    "                obs = {\"error\": \"No SQL to validate. Call generate_sql first.\"}\n",
    "                blocked = True\n",
    "                executed_action = None\n",
    "            else:\n",
    "                res = validate_sql(last_sql, schema_text_full)\n",
    "                if debug:\n",
    "                    _debug_event(step, \"validate_sql\", {\"sql\": _summarize_sql(last_sql), \"valid\": res.get(\"valid\"), \"reason\": res.get(\"reason\")})\n",
    "                if res.get(\"reason\") == \"no_schema\":\n",
    "                    res = {\"valid\": False, \"reason\": \"schema_missing\"}\n",
    "                obs = res\n",
    "                last_valid = bool(res.get(\"valid\"))\n",
    "                data = dict(res)\n",
    "                data[\"schema_text_len\"] = len(schema_text_full or \"\")\n",
    "                log_decision(decision_log, step, \"validate_sql\", res.get(\"reason\", \"\"), data, status=\"ok\" if last_valid else \"reject\")\n",
    "                if not last_valid:\n",
    "                    last_error = res.get(\"reason\")\n",
    "                    pending_repair_error = last_error\n",
    "                else:\n",
    "                    pending_repair_error = None\n",
    "            if debug:\n",
    "                if obs.get(\"error\"):\n",
    "                    print(\"\\nSQL check: blocked -\", obs.get(\"error\"))\n",
    "                elif obs.get(\"valid\"):\n",
    "                    print(\"\\nSQL check: PASS\")\n",
    "                else:\n",
    "                    print(\"\\nSQL check: FAIL -\", obs.get(\"reason\"))\n",
    "        elif action == \"validate_constraints\":\n",
    "            # Rationale: enforce NLQ-implied structure (aggregation, grouping, limits).\n",
    "            if not last_sql:\n",
    "                obs = {\"error\": \"No SQL to validate. Call generate_sql first.\"}\n",
    "                blocked = True\n",
    "                executed_action = None\n",
    "            elif not constraints:\n",
    "                obs = {\"error\": \"No constraints found. Call extract_constraints first.\"}\n",
    "                blocked = True\n",
    "                executed_action = None\n",
    "            else:\n",
    "                res = validate_constraints(last_sql, constraints)\n",
    "                if debug:\n",
    "                    _debug_event(step, \"validate_constraints\", {\"valid\": res.get(\"valid\"), \"reason\": res.get(\"reason\"), \"missing_fields\": res.get(\"missing_fields\")})\n",
    "                obs = res\n",
    "                last_constraints_ok = bool(res.get(\"valid\"))\n",
    "                log_decision(decision_log, step, \"validate_constraints\", res.get(\"reason\", \"\"), res, status=\"ok\" if last_constraints_ok else \"reject\")\n",
    "                if not last_constraints_ok:\n",
    "                    last_error = res.get(\"reason\")\n",
    "                    pending_repair_error = last_error\n",
    "                else:\n",
    "                    pending_repair_error = None\n",
    "            if debug:\n",
    "                if obs.get(\"error\"):\n",
    "                    print(\"\\nShape check: blocked -\", obs.get(\"error\"))\n",
    "                elif obs.get(\"valid\"):\n",
    "                    print(\"\\nShape check: PASS\")\n",
    "                else:\n",
    "                    print(\"\\nShape check: FAIL -\", obs.get(\"reason\"))\n",
    "        elif action == \"run_sql\":\n",
    "            # Rationale: execution is the ReAct Observation; it tells the loop what failed.\n",
    "            if not last_sql:\n",
    "                obs = {\"error\": \"No SQL to run. Call generate_sql first.\"}\n",
    "                blocked = True\n",
    "                executed_action = None\n",
    "            elif last_valid is None:\n",
    "                obs = {\"error\": \"Must call validate_sql before run_sql.\"}\n",
    "                blocked = True\n",
    "                executed_action = None\n",
    "            elif last_valid is False:\n",
    "                obs = {\"error\": \"Validation failed. Call repair_sql.\"}\n",
    "                blocked = True\n",
    "                executed_action = None\n",
    "            elif last_constraints_ok is None:\n",
    "                obs = {\"error\": \"Must call validate_constraints before run_sql.\"}\n",
    "                blocked = True\n",
    "                executed_action = None\n",
    "            elif last_constraints_ok is False:\n",
    "                obs = {\"error\": \"Constraint validation failed. Call repair_sql.\"}\n",
    "                blocked = True\n",
    "                executed_action = None\n",
    "            else:\n",
    "                res = run_sql(last_sql)\n",
    "                if debug:\n",
    "                    _debug_event(step, \"run_sql\", {\"success\": res.get(\"success\"), \"rowcount\": res.get(\"rowcount\"), \"error\": res.get(\"error\")})\n",
    "                log_decision(decision_log, step, \"run_sql\", \"execute\", {\"success\": res.get(\"success\"), \"rowcount\": res.get(\"rowcount\"), \"error\": res.get(\"error\")})\n",
    "                if res.get(\"success\"):\n",
    "                    ok, why = intent_constraints(nlq, last_sql)\n",
    "                    if not ok:\n",
    "                        res = {\"success\": False, \"error\": f\"Intent mismatch: {why}\"}\n",
    "                        log_decision(decision_log, step, \"intent_check\", why, {\"ok\": ok}, status=\"reject\")\n",
    "                    else:\n",
    "                        log_decision(decision_log, step, \"intent_check\", \"ok\", {\"ok\": ok})\n",
    "                        auto_finish = True\n",
    "                        auto_finish_payload = {\"answer\": str(res.get(\"rows\", [])), \"sql\": last_sql or \"\"}\n",
    "                obs = res\n",
    "                last_run = res\n",
    "                if not res.get(\"success\"):\n",
    "                    last_error = res.get(\"error\")\n",
    "                    pending_repair_error = last_error\n",
    "                else:\n",
    "                    pending_repair_error = None\n",
    "            if debug:\n",
    "                if obs.get(\"success\"):\n",
    "                    print(\"\\nRun: PASS (rows:\", obs.get(\"rowcount\"), \")\")\n",
    "                    rows = obs.get(\"rows\") or []\n",
    "                    if rows:\n",
    "                        preview = rows[: max(0, int(debug_rows_preview))]\n",
    "                        line = _truncate_text(json.dumps(preview, ensure_ascii=False, default=str), max_chars=1200)\n",
    "                        print(\"Rows preview:\", line)\n",
    "                else:\n",
    "                    print(\"\\nRun: FAIL -\", obs.get(\"error\"))\n",
    "        else:\n",
    "            obs = {\"error\": f\"Unhandled action: {action}\"}\n",
    "\n",
    "        history.append(f\"Observation: {json.dumps(obs, ensure_ascii=False, default=str)}\")\n",
    "        trace.append(\n",
    "            {\n",
    "                \"step\": step,\n",
    "                \"attempted_action\": attempted_action,\n",
    "                \"attempted_args\": attempted_args,\n",
    "                \"action\": executed_action,\n",
    "                \"args\": args if executed_action else {},\n",
    "                \"observation\": obs,\n",
    "                \"blocked\": blocked,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        if auto_finish and auto_finish_payload is not None:\n",
    "            result = finish(\n",
    "                answer=auto_finish_payload[\"answer\"],\n",
    "                sql=auto_finish_payload[\"sql\"],\n",
    "                provenance={\"trace\": trace},\n",
    "            )\n",
    "            trace.append(\n",
    "                {\n",
    "                    \"step\": step,\n",
    "                    \"attempted_action\": attempted_action,\n",
    "                    \"attempted_args\": attempted_args,\n",
    "                    \"action\": \"finish\",\n",
    "                    \"args\": {},\n",
    "                    \"observation\": result,\n",
    "                    \"forced_action\": \"finish\",\n",
    "                    \"reason\": \"auto_finish_after_success\",\n",
    "                }\n",
    "            )\n",
    "            log_decision(decision_log, step, \"finish\", \"auto_finish_after_success\", {\"sql\": result.get(\"sql\", \"\")})\n",
    "            if debug:\n",
    "                print(\"\\nAUTO-FINISH -> returning final SQL\")\n",
    "                print(result.get(\"sql\", \"\"))\n",
    "            return result.get(\"sql\", \"\"), trace, decision_log\n",
    "\n",
    "        if debug and float(debug_sleep_s) > 0:\n",
    "            time.sleep(float(debug_sleep_s))\n",
    "\n",
    "    # Post-loop salvage: validate/execute the last draft before any fallback.\n",
    "    if last_sql:\n",
    "        salvage_sql = last_sql\n",
    "        res = validate_sql(salvage_sql, schema_text_full)\n",
    "        trace.append({\"step\": max_steps, \"action\": \"validate_sql\", \"observation\": res, \"forced_action\": \"salvage_after_loop\"})\n",
    "        log_decision(\n",
    "            decision_log,\n",
    "            max_steps,\n",
    "            \"salvage_validate_sql\",\n",
    "            res.get(\"reason\", \"\"),\n",
    "            res,\n",
    "            status=\"ok\" if res.get(\"valid\") else \"reject\",\n",
    "        )\n",
    "        if res.get(\"valid\"):\n",
    "            constraints_ok = True\n",
    "            if constraints:\n",
    "                res2 = validate_constraints(salvage_sql, constraints)\n",
    "                trace.append({\"step\": max_steps, \"action\": \"validate_constraints\", \"observation\": res2, \"forced_action\": \"salvage_after_loop\"})\n",
    "                log_decision(\n",
    "                    decision_log,\n",
    "                    max_steps,\n",
    "                    \"salvage_validate_constraints\",\n",
    "                    res2.get(\"reason\", \"\"),\n",
    "                    res2,\n",
    "                    status=\"ok\" if res2.get(\"valid\") else \"reject\",\n",
    "                )\n",
    "                constraints_ok = bool(res2.get(\"valid\"))\n",
    "            if constraints_ok:\n",
    "                res3 = run_sql(salvage_sql)\n",
    "                trace.append({\"step\": max_steps, \"action\": \"run_sql\", \"observation\": res3, \"forced_action\": \"salvage_after_loop\"})\n",
    "                log_decision(\n",
    "                    decision_log,\n",
    "                    max_steps,\n",
    "                    \"salvage_run_sql\",\n",
    "                    \"execute\",\n",
    "                    {\"success\": res3.get(\"success\"), \"rowcount\": res3.get(\"rowcount\"), \"error\": res3.get(\"error\")},\n",
    "                )\n",
    "                if res3.get(\"success\"):\n",
    "                    ok, why = intent_constraints(nlq, salvage_sql)\n",
    "                    log_decision(\n",
    "                        decision_log,\n",
    "                        max_steps,\n",
    "                        \"salvage_intent_check\",\n",
    "                        why,\n",
    "                        {\"ok\": ok},\n",
    "                        status=\"ok\" if ok else \"reject\",\n",
    "                    )\n",
    "                    if ok:\n",
    "                        result = finish(answer=str(res3.get(\"rows\", [])), sql=salvage_sql, provenance={\"trace\": trace})\n",
    "                        trace.append(\n",
    "                            {\n",
    "                                \"step\": max_steps,\n",
    "                                \"action\": \"finish\",\n",
    "                                \"args\": {},\n",
    "                                \"observation\": result,\n",
    "                                \"forced_action\": \"salvage_after_loop\",\n",
    "                            }\n",
    "                        )\n",
    "                        log_decision(decision_log, max_steps, \"finish\", \"salvage_after_loop\", {\"sql\": result.get(\"sql\", \"\")})\n",
    "                        return result.get(\"sql\", \"\"), trace, decision_log\n",
    "\n",
    "    # Fallback if no salvage succeeded\n",
    "    fallback = None\n",
    "    if schema_summary:\n",
    "        fallback = vanilla_candidate(\n",
    "            nlq=nlq,\n",
    "            schema_summary=schema_summary,\n",
    "            tok=tok,\n",
    "            model=model,\n",
    "            exemplars=exemplars or [],\n",
    "        )\n",
    "    if fallback:\n",
    "        fb_sql, fb_reason, _stages = _apply_guardrails(fallback, nlq, schema_text_full)\n",
    "        if not fb_sql:\n",
    "            log_decision(\n",
    "                decision_log,\n",
    "                max_steps,\n",
    "                \"fallback_guardrails\",\n",
    "                \"clean_reject\",\n",
    "                {\"reason\": fb_reason, \"raw_sql\": fallback},\n",
    "                status=\"reject\",\n",
    "            )\n",
    "        else:\n",
    "            res = validate_sql(fb_sql, schema_text_full)\n",
    "            trace.append({\"step\": max_steps, \"action\": \"validate_sql\", \"observation\": res, \"forced_action\": \"fallback\"})\n",
    "            log_decision(\n",
    "                decision_log,\n",
    "                max_steps,\n",
    "                \"fallback_validate_sql\",\n",
    "                res.get(\"reason\", \"\"),\n",
    "                res,\n",
    "                status=\"ok\" if res.get(\"valid\") else \"reject\",\n",
    "            )\n",
    "            if res.get(\"valid\"):\n",
    "                constraints_ok = True\n",
    "                if constraints:\n",
    "                    res2 = validate_constraints(fb_sql, constraints)\n",
    "                    trace.append({\"step\": max_steps, \"action\": \"validate_constraints\", \"observation\": res2, \"forced_action\": \"fallback\"})\n",
    "                    log_decision(\n",
    "                        decision_log,\n",
    "                        max_steps,\n",
    "                        \"fallback_validate_constraints\",\n",
    "                        res2.get(\"reason\", \"\"),\n",
    "                        res2,\n",
    "                        status=\"ok\" if res2.get(\"valid\") else \"reject\",\n",
    "                    )\n",
    "                    constraints_ok = bool(res2.get(\"valid\"))\n",
    "                if constraints_ok:\n",
    "                    res3 = run_sql(fb_sql)\n",
    "                    trace.append({\"step\": max_steps, \"action\": \"run_sql\", \"observation\": res3, \"forced_action\": \"fallback\"})\n",
    "                    log_decision(\n",
    "                        decision_log,\n",
    "                        max_steps,\n",
    "                        \"fallback_run_sql\",\n",
    "                        \"execute\",\n",
    "                        {\"success\": res3.get(\"success\"), \"rowcount\": res3.get(\"rowcount\"), \"error\": res3.get(\"error\")},\n",
    "                    )\n",
    "                    if res3.get(\"success\"):\n",
    "                        ok, why = intent_constraints(nlq, fb_sql)\n",
    "                        log_decision(\n",
    "                            decision_log,\n",
    "                            max_steps,\n",
    "                            \"fallback_intent_check\",\n",
    "                            why,\n",
    "                            {\"ok\": ok},\n",
    "                            status=\"ok\" if ok else \"reject\",\n",
    "                        )\n",
    "                        if ok:\n",
    "                            trace.append({\"step\": max_steps, \"action\": \"fallback\", \"sql\": fb_sql})\n",
    "                            log_decision(decision_log, max_steps, \"fallback\", \"validated candidate\", {\"sql\": fb_sql})\n",
    "                            return fb_sql, trace, decision_log\n",
    "    return last_sql or \"\", trace, decision_log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0cb3f3",
   "metadata": {},
   "source": [
    "### Quick sanity check\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "b8b3c4fd",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 6a) Interactive walkthrough: type an NLQ and watch the loop step-by-step\n",
    "DEMO_INTERACTIVE = True\n",
    "DEMO_DEFAULT_NLQ = \"Which customers are in France?\"\n",
    "DEMO_AUTO_ORDER = True  # keep the walkthrough linear (forces the next required step)\n",
    "DEMO_SLEEP_S = 0.8  # set 0 for fast\n",
    "DEMO_PROMPT_TAIL = 0  # set >0 to show the transcript tail the model sees\n",
    "SHOW_DECISIONS = False\n",
    "\n",
    "nlq = \"\"\n",
    "if DEMO_INTERACTIVE:\n",
    "    try:\n",
    "        nlq = input(\"Type a ClassicModels question (blank uses default): \").strip()\n",
    "    except Exception:\n",
    "        nlq = \"\"\n",
    "if not nlq:\n",
    "    nlq = DEMO_DEFAULT_NLQ\n",
    "\n",
    "pred, trace, decisions = react_sql(\n",
    "    nlq=nlq,\n",
    "    schema_summary=SCHEMA_SUMMARY,\n",
    "    exemplars=REACT_EXEMPLARS,\n",
    "    debug=True,\n",
    "    auto_order=DEMO_AUTO_ORDER,\n",
    "    debug_sleep_s=DEMO_SLEEP_S,\n",
    "    debug_prompt_tail_lines=DEMO_PROMPT_TAIL,\n",
    ")\n",
    "\n",
    "print(\"\\nFINAL SQL:\")\n",
    "print(pred)\n",
    "print(\"\\nTRACE SUMMARY:\", summarize_trace(trace))\n",
    "if SHOW_DECISIONS:\n",
    "    print(\"\\nDECISIONS:\\n\" + format_decision_log(decisions, max_items=40))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41c91f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Quick sanity check on a few items\n",
    "DEBUG_EX = False  # set True for a quick EX check (slower)\n",
    "DEBUG_TRACE = True\n",
    "for sample in test_set[:5]:\n",
    "    nlq = sample[\"nlq\"]\n",
    "    gold = sample[\"sql\"]\n",
    "    pred, trace, decisions = react_sql(\n",
    "        nlq=nlq,\n",
    "        schema_summary=SCHEMA_SUMMARY,\n",
    "        exemplars=REACT_EXEMPLARS,\n",
    "        auto_order=True,  # ensure ordered tool steps in sanity check\n",
    "    )\n",
    "    print(\"NLQ:\", nlq)\n",
    "    print(\"PRED:\", pred)\n",
    "    print(\"GOLD:\", gold)\n",
    "    if pred:\n",
    "        meta = runner.run(pred, capture_df=False)\n",
    "        print(\"VA:\", int(meta.success), \"ERR:\", meta.error)\n",
    "        ok, why = intent_constraints(nlq, pred)\n",
    "        print(\"INTENT:\", ok, why)\n",
    "    else:\n",
    "        print(\"VA:\", 0, \"ERR:\", \"no prediction\")\n",
    "        print(\"INTENT:\", False, \"no prediction\")\n",
    "    if DEBUG_EX and pred:\n",
    "        ex_ok, pred_err, gold_err = execution_accuracy(engine=engine, pred_sql=pred, gold_sql=gold)\n",
    "        print(\"EX:\", int(ex_ok), \"PRED_ERR:\", pred_err, \"GOLD_ERR:\", gold_err)\n",
    "    if DEBUG_TRACE and trace:\n",
    "        summary = summarize_trace(trace)\n",
    "        print(\"TRACE LEN:\", len(trace))\n",
    "        print(\"EXECUTED ACTIONS:\", summary.get(\"actions\"))\n",
    "        attempted = summary.get(\"attempted_actions\") or []\n",
    "        if attempted:\n",
    "            print(\"ATTEMPTED ACTIONS:\", attempted[-10:])\n",
    "        print(\"BLOCKED STEPS:\", summary.get(\"blocked_steps\"))\n",
    "        print(\"COMPLIANCE:\", summary.get(\"compliance_ok\"), summary.get(\"compliance_errors\"))\n",
    "        print(\"TRACE SUMMARY:\", summary)\n",
    "        print(\"DECISIONS:\\n\" + format_decision_log(decisions, max_items=12))\n",
    "        print(\"TRACE LAST:\", trace[-1])\n",
    "    else:\n",
    "        print(\"TRACE LEN:\", len(trace))\n",
    "    print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89984dc7",
   "metadata": {},
   "source": [
    "### TS evaluator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c7a7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Test Suite Accuracy (TS) evaluation ===\n",
    "# Harness now lives in nl2sql.eval for reuse in scripts.\n",
    "from nl2sql.eval import test_suite_accuracy_for_item\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c61e8a",
   "metadata": {},
   "source": [
    "### Quick toggles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1ae08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Quick test toggles (set before full eval) ===\n",
    "# Use small values to sanityâ€‘check TS/EX before full runs.\n",
    "QUICK_LIMIT = 20   # number of NLQs to evaluate (set None for full set)\n",
    "TS_N = 3           # number of TS DBs (set 10 for full TS)\n",
    "MAX_ROWS_TS = 500  # row cap per query in TS (raise for full)\n",
    "USE_LINK_SCHEMA = True  # set False to ablate schema linking\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11f9403",
   "metadata": {},
   "source": [
    "### Full evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b771d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) Full agentic evaluation (VA/EX/EM/TS) over test_set\n",
    "from functools import lru_cache\n",
    "from nl2sql.eval import execution_accuracy, test_suite_accuracy_for_item\n",
    "from nl2sql.postprocess import normalize_sql\n",
    "\n",
    "def strip_trace_cycles(trace):\n",
    "    if not trace:\n",
    "        return trace\n",
    "    cleaned = []\n",
    "    for t in trace:\n",
    "        t2 = dict(t)\n",
    "        obs = t2.get(\"observation\")\n",
    "        if isinstance(obs, dict) and \"provenance\" in obs:\n",
    "            prov = dict(obs[\"provenance\"])\n",
    "            # remove recursive trace inside provenance to avoid JSON cycles\n",
    "            prov.pop(\"trace\", None)\n",
    "            obs2 = dict(obs)\n",
    "            obs2[\"provenance\"] = prov\n",
    "            t2[\"observation\"] = obs2\n",
    "        cleaned.append(t2)\n",
    "    return cleaned\n",
    "\n",
    "results = []\n",
    "TS_PREFIX = \"classicmodels_ts\"\n",
    "SUITE_DBS = [f\"{TS_PREFIX}_{i:02d}\" for i in range(1, TS_N + 1)]\n",
    "\n",
    "@lru_cache(maxsize=32)\n",
    "def make_engine_cached(db_name: str) -> Engine:\n",
    "    return make_engine(db_name)\n",
    "\n",
    "def make_engine_fn(db_name: str) -> Engine:\n",
    "    return make_engine_cached(db_name)\n",
    "\n",
    "LIMIT = QUICK_LIMIT  # override from quick toggles\n",
    "items = test_set[:LIMIT] if LIMIT else test_set\n",
    "\n",
    "# Per-item evaluation: generate SQL and compute VA/EM/EX/TS.\n",
    "for i, sample in enumerate(items, start=1):\n",
    "    nlq = sample[\"nlq\"]\n",
    "    gold_sql = sample[\"sql\"]\n",
    "    pred_sql, trace, decisions = react_sql(\n",
    "        nlq=nlq,\n",
    "        schema_summary=SCHEMA_SUMMARY,\n",
    "        exemplars=REACT_EXEMPLARS,\n",
    "    )\n",
    "\n",
    "    trace_clean = strip_trace_cycles(trace)\n",
    "    trace_summary = summarize_trace(trace_clean)\n",
    "    decision_log = decisions\n",
    "\n",
    "    # EM is strict (normalized) string match; kept as a diagnostic signal.\n",
    "    em = int(normalize_sql(pred_sql) == normalize_sql(gold_sql))\n",
    "\n",
    "    # VA = executability of predicted SQL\n",
    "    va_meta = runner.run(pred_sql, capture_df=False) if pred_sql else None\n",
    "    va = int(bool(va_meta and va_meta.success))\n",
    "\n",
    "    # EX = execution accuracy on base DB (row equivalence)\n",
    "    ex = 0\n",
    "    pred_err = None\n",
    "    gold_err = None\n",
    "    if va:\n",
    "        ex_ok, pred_err, gold_err = execution_accuracy(engine=engine, pred_sql=pred_sql, gold_sql=gold_sql)\n",
    "        ex = int(ex_ok)\n",
    "\n",
    "    # TS = test-suite accuracy across replica DBs\n",
    "    # Note: test_suite_accuracy_for_item returns (ts_pass, debug_info).\n",
    "    ts = None\n",
    "    ts_debug = None\n",
    "    if va:\n",
    "        ts, ts_debug = test_suite_accuracy_for_item(\n",
    "            pred_sql=pred_sql,\n",
    "            gold_sql=gold_sql,\n",
    "            suite_db_names=SUITE_DBS,\n",
    "            make_engine_fn=make_engine_fn,\n",
    "            max_rows=MAX_ROWS_TS,\n",
    "        )\n",
    "\n",
    "    results.append(\n",
    "        {\n",
    "            \"nlq\": nlq,\n",
    "            \"gold_sql\": gold_sql,\n",
    "            \"pred_sql\": pred_sql,\n",
    "            \"va\": va,\n",
    "            \"em\": em,\n",
    "            \"ex\": ex,\n",
    "            \"ts\": ts,\n",
    "            \"ts_debug\": ts_debug,\n",
    "            \"pred_err\": pred_err,\n",
    "            \"gold_err\": gold_err,\n",
    "            \"trace\": trace_clean,\n",
    "            \"trace_summary\": trace_summary,\n",
    "            \"decision_log\": decision_log,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    if i % 20 == 0 or i == len(items):\n",
    "        print(f\"Processed {i}/{len(items)}\")\n",
    "\n",
    "# Aggregate rates\n",
    "va_rate = sum(r[\"va\"] for r in results) / len(results)\n",
    "em_rate = sum(r[\"em\"] for r in results) / len(results)\n",
    "ex_rate = sum(r[\"ex\"] for r in results) / len(results)\n",
    "ts_values = [r[\"ts\"] for r in results if r.get(\"ts\") is not None]\n",
    "ts_rate = (sum(ts_values) / max(1, len(ts_values))) if ts_values else 0.0\n",
    "\n",
    "print(\"ReAct VA:\", round(va_rate, 3), \"EX:\", round(ex_rate, 3), \"EM:\", round(em_rate, 3), \"TS:\", round(ts_rate, 3))\n",
    "\n",
    "out = {\n",
    "    \"va_rate\": va_rate,\n",
    "    \"ex_rate\": ex_rate,\n",
    "    \"em_rate\": em_rate,\n",
    "    \"ts_rate\": ts_rate,\n",
    "    \"items\": results,\n",
    "}\n",
    "out_path = Path(\"results/agent/results_react_200.json\")\n",
    "out_path.write_text(json.dumps(out, indent=2, default=str))\n",
    "print(\"Saved to\", out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 7b) EX failure profiling (quick categories)\n",
    "from collections import Counter\n",
    "\n",
    "def _ex_reasons(decision_log):\n",
    "    reasons = []\n",
    "    for d in decision_log or []:\n",
    "        r = d.get('reason')\n",
    "        if r and r not in ('ok', 'success'):\n",
    "            reasons.append(r)\n",
    "    return reasons\n",
    "\n",
    "def categorize_ex_failure(item):\n",
    "    if not item.get('pred_sql'):\n",
    "        return 'no_pred'\n",
    "    if item.get('va') == 0:\n",
    "        return 'invalid_sql'\n",
    "    if item.get('ex') == 1:\n",
    "        return 'correct'\n",
    "    reasons = _ex_reasons(item.get('decision_log'))\n",
    "    if any('missing_value_hint' in r for r in reasons):\n",
    "        return 'missing_value_hint'\n",
    "    if any('missing_location_table' in r for r in reasons):\n",
    "        return 'missing_location_table'\n",
    "    if any('missing_location_column' in r for r in reasons):\n",
    "        return 'missing_location_column'\n",
    "    if any(r.startswith('missing_agg') for r in reasons):\n",
    "        return 'missing_agg'\n",
    "    if any('missing_group_by' in r for r in reasons):\n",
    "        return 'missing_group_by'\n",
    "    if any('missing_order_by' in r for r in reasons):\n",
    "        return 'missing_order_by'\n",
    "    if any('missing_limit' in r for r in reasons):\n",
    "        return 'missing_limit'\n",
    "    return 'other'\n",
    "\n",
    "counts = Counter(categorize_ex_failure(r) for r in results)\n",
    "print('EX failure categories:')\n",
    "for k, v in counts.most_common():\n",
    "    print(f'  {k}: {v}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
