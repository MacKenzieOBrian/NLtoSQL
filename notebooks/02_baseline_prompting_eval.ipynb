{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "962754b6",
   "metadata": {},
   "source": [
    "# Baseline NL→SQL Evaluation (Zero-shot vs Few-shot)\n",
    "\n",
    "This notebook is the baseline replication block for Ojuri et al. (2025): it measures prompting effects (`k=0` vs `k=3`) on the same 200-item ClassicModels test set using an open-source local stack.\n",
    "\n",
    "Primary role in dissertation:\n",
    "- establish non-fine-tuned reference metrics,\n",
    "- isolate prompting gains before QLoRA,\n",
    "- provide controlled inputs for later paired comparisons.\n",
    "\n",
    "This notebook runs the VA/EX baseline over `data/classicmodels_test_200.json` and saves outputs under `results/baseline/`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d66939",
   "metadata": {},
   "source": [
    "Run this setup in a fresh GPU runtime, then restart before continuing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f6773c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "set -e\n",
    "export PIP_DEFAULT_TIMEOUT=120\n",
    "\n",
    "# Clean conflicting preinstalls\n",
    "pip uninstall -y torch torchvision torchaudio bitsandbytes triton transformers accelerate peft trl datasets numpy pandas fsspec requests google-auth scipy scikit-learn || true\n",
    "\n",
    "# Base deps\n",
    "pip install -q --no-cache-dir --force-reinstall \\\n",
    "  numpy==1.26.4 pandas==2.2.1 scipy scikit-learn \\\n",
    "  fsspec==2024.5.0 requests==2.31.0 google-auth==2.43.0\n",
    "\n",
    "# Torch + CUDA 12.1\n",
    "pip install -q --no-cache-dir --force-reinstall \\\n",
    "  torch==2.3.1+cu121 torchvision==0.18.1+cu121 torchaudio==2.3.1+cu121 \\\n",
    "  --index-url https://download.pytorch.org/whl/cu121\n",
    "\n",
    "# bitsandbytes + triton + HF stack\n",
    "pip install -q --no-cache-dir --force-reinstall \\\n",
    "  bitsandbytes==0.43.3 triton==2.3.1 \\\n",
    "  transformers==4.44.2 accelerate==0.33.0 peft==0.17.0 trl==0.9.6 datasets==2.20.0\n",
    "\n",
    "echo \"Setup complete. Restart runtime once, then run the rest of the notebook top-to-bottom.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b335da04",
   "metadata": {},
   "source": [
    "After restart, continue with DB/auth, schema, model, and eval cells."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82818187",
   "metadata": {},
   "source": [
    "Prompt/eval: build prompts (system+schema+k exemplars), generate SQL, postprocess, and compute VA/EX/EM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba5f922",
   "metadata": {},
   "source": [
    "Practical note: we keep schema context explicit so generated SQL is grounded in real tables and columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd30aacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# If this notebook is opened directly in Colab (not from a cloned repo), clone the repo first.\n",
    "if Path(\"data/classicmodels_test_200.json\").exists() is False and Path(\"/content\").exists():\n",
    "    repo_dir = Path(\"/content/NLtoSQL\")\n",
    "    if repo_dir.exists():\n",
    "        shutil.rmtree(repo_dir)\n",
    "    !git clone https://github.com/MacKenzieOBrian/NLtoSQL.git \"{repo_dir}\"\n",
    "    os.chdir(repo_dir)\n",
    "\n",
    "# Ensure repo root is on sys.path for `import nl2sql`\n",
    "sys.path.insert(0, os.getcwd())\n",
    "print(\"cwd:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a65e12",
   "metadata": {},
   "source": [
    "## Install dependencies (Colab)\n",
    "\n",
    "This repo pins versions in `requirements.txt` to reduce Colab binary drift.\n",
    "After installation, restart the runtime (Runtime → Restart runtime), then run this notebook again from the top.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4a0263",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab  # noqa: F401\n",
    "    IN_COLAB = True\n",
    "except Exception:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    !pip -q install -r requirements.txt\n",
    "else:\n",
    "    print(\"Not in Colab; ensure requirements are installed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644e4296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colab-only: authenticate with GCP (safe to skip locally)\n",
    "try:\n",
    "    from google.colab import auth\n",
    "except ModuleNotFoundError:\n",
    "    auth = None\n",
    "\n",
    "if auth:\n",
    "    auth.authenticate_user()\n",
    "else:\n",
    "    print(\"Not running in Colab; ensure ADC or service account auth is configured.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a375d04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hugging Face auth (gated model)\n",
    "import os\n",
    "\n",
    "hf_token = os.getenv(\"HF_TOKEN\") or os.getenv(\"HUGGINGFACE_HUB_TOKEN\")\n",
    "if hf_token:\n",
    "    os.environ[\"HUGGINGFACE_HUB_TOKEN\"] = hf_token\n",
    "    print(\"Using HF token from env\")\n",
    "else:\n",
    "    try:\n",
    "        from huggingface_hub import notebook_login\n",
    "        notebook_login()\n",
    "    except Exception as e:\n",
    "        print(\"HF auth not configured:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8db21f",
   "metadata": {},
   "source": [
    "Environment note: DB access is via Cloud SQL connector + SQLAlchemy creator hook through `nl2sql.db`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc093bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from getpass import getpass\n",
    "\n",
    "INSTANCE_CONNECTION_NAME = os.getenv(\"INSTANCE_CONNECTION_NAME\")\n",
    "DB_USER = os.getenv(\"DB_USER\")\n",
    "DB_PASS = os.getenv(\"DB_PASS\")\n",
    "DB_NAME = os.getenv(\"DB_NAME\", \"classicmodels\")\n",
    "\n",
    "if not INSTANCE_CONNECTION_NAME:\n",
    "    INSTANCE_CONNECTION_NAME = input(\"Enter INSTANCE_CONNECTION_NAME: \").strip()\n",
    "if not DB_USER:\n",
    "    DB_USER = input(\"Enter DB_USER: \").strip()\n",
    "if not DB_PASS:\n",
    "    DB_PASS = getpass(\"Enter DB_PASS: \")\n",
    "\n",
    "print(\"Using DB:\", DB_NAME)\n",
    "\n",
    "test_set = json.loads(open(\"data/classicmodels_test_200.json\", \"r\", encoding=\"utf-8\").read())\n",
    "print(\"Loaded test items:\", len(test_set))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa43392",
   "metadata": {},
   "source": [
    "Data note: the benchmark stays fixed at 200 items so comparisons remain paired across runs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1016babb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nl2sql.db import create_engine_with_connector\n",
    "\n",
    "engine, connector = create_engine_with_connector(\n",
    "    instance_connection_name=INSTANCE_CONNECTION_NAME,\n",
    "    user=DB_USER,\n",
    "    password=DB_PASS,\n",
    "    db_name=DB_NAME,\n",
    ")\n",
    "\n",
    "print(\"Engine ready\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b951b4",
   "metadata": {},
   "source": [
    "Model note: default loading uses 4-bit quantization to fit common Colab GPU memory.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de77bc5",
   "metadata": {},
   "source": [
    "Fallback note: if 4-bit load fails, use the built-in fallback path in the next cell (fp16/bf16).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9070492",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "MODEL_ID = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "\n",
    "print(\"Loading tokenizer...\")\n",
    "tok = AutoTokenizer.from_pretrained(MODEL_ID, token=True)\n",
    "if tok.pad_token is None:\n",
    "    tok.pad_token = tok.eos_token\n",
    "\n",
    "# Try 4-bit loading (fallback to fp/bf16)\n",
    "try:\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    )\n",
    "    print(\"Attempting 4-bit quantized load...\")\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_ID,\n",
    "        quantization_config=bnb_config,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        device_map=\"auto\",\n",
    "        token=True,\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(\"4-bit load failed, falling back. Error:\")\n",
    "    print(e)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_ID,\n",
    "        torch_dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float32,\n",
    "        device_map=\"auto\" if torch.cuda.is_available() else None,\n",
    "        token=True,\n",
    "    )\n",
    "\n",
    "model.generation_config.do_sample = False\n",
    "model.generation_config.num_beams = 1\n",
    "\n",
    "print(\"Model device:\", model.device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb7e719",
   "metadata": {},
   "source": [
    "Schema note: `build_schema_summary(...)` generates prompt context from live DB metadata.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e11cb75",
   "metadata": {},
   "source": [
    "Consistency note: keep prompt and schema settings unchanged when making cross-run claims.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274de10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nl2sql.schema import build_schema_summary\n",
    "\n",
    "SCHEMA_SUMMARY = build_schema_summary(engine, db_name=DB_NAME, max_cols_per_table=50)\n",
    "print(\"Schema summary built (chars):\", len(SCHEMA_SUMMARY))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382bccdf",
   "metadata": {},
   "source": [
    "Evaluation note: use the shared `nl2sql.eval` harness so VA/EM/EX are computed identically for every run.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed10dfaa",
   "metadata": {},
   "source": [
    "### Experiment Controls and Demo Notes (Baseline)\n",
    "\n",
    "This section controls the **prompting-only baseline**. In viva/demo terms, this is the reference line before weight updates.\n",
    "\n",
    "**What each knob means:**\n",
    "- `MODEL_ID` / `MODEL_ALIAS`: model-family comparison (Llama vs Qwen, etc.).\n",
    "- `K_VALUES`: few-shot depth (`k=0` = zero-shot).\n",
    "- `SEEDS`: exemplar sampling stability check (effective only when `k > 0`).\n",
    "- `PROMPT_VARIANT`: prompt wording ablation.\n",
    "- `SCHEMA_VARIANT`: schema context budget ablation.\n",
    "- `EXEMPLAR_STRATEGY`: exemplar pool composition ablation.\n",
    "- `ENABLE_TS`: optional semantic robustness check over test-suite replicas.\n",
    "\n",
    "**Controlled-experiment rule:**\n",
    "Change one axis at a time and keep all other knobs fixed for interpretable claims.\n",
    "\n",
    "**Operational rule for multi-model work:**\n",
    "- Use `COPY_MODEL_FAMILY=True` to save model-labeled `k=0`/`k=3` files.\n",
    "- Use `COPY_CANONICAL=False` unless this run should replace the canonical baseline pair.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89802cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import subprocess\n",
    "import shutil\n",
    "from functools import lru_cache\n",
    "from datetime import datetime, timezone\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from nl2sql.eval import eval_run\n",
    "import nl2sql.prompting as prompting_mod\n",
    "\n",
    "DEFAULT_SYSTEM_INSTRUCTIONS = prompting_mod.SYSTEM_INSTRUCTIONS\n",
    "\n",
    "\n",
    "def _model_alias_from_id(model_id: str) -> str:\n",
    "    tail = (model_id or \"model\").split(\"/\")[-1]\n",
    "    alias = re.sub(r\"[^a-z0-9]+\", \"_\", tail.lower()).strip(\"_\")\n",
    "    return alias or \"model\"\n",
    "\n",
    "\n",
    "PROMPT_VARIANTS = {\n",
    "    \"default\": DEFAULT_SYSTEM_INSTRUCTIONS,\n",
    "    \"schema_only_minimal\": \"\"\"You are an expert data analyst writing MySQL queries.\n",
    "Given the database schema and a natural language question, write a single SQL SELECT query.\n",
    "\n",
    "Rules:\n",
    "- Output ONLY SQL (no explanation, no markdown).\n",
    "- Output exactly ONE statement, starting with SELECT.\n",
    "- Use only tables/columns listed in the schema.\n",
    "\"\"\",\n",
    "    \"no_routing_hints\": DEFAULT_SYSTEM_INSTRUCTIONS.split(\"- Routing hints:\")[0].rstrip(),\n",
    "}\n",
    "\n",
    "def schema_variant_text(schema_text: str, variant: str) -> str:\n",
    "    lines = schema_text.splitlines()\n",
    "    if variant == \"full\":\n",
    "        return schema_text\n",
    "    if variant == \"first_80_lines\":\n",
    "        return \"\\n\".join(lines[:80])\n",
    "    if variant == \"first_40_lines\":\n",
    "        return \"\\n\".join(lines[:40])\n",
    "    raise ValueError(f\"Unknown SCHEMA_VARIANT: {variant}\")\n",
    "\n",
    "def exemplar_pool_for_strategy(items: list[dict], strategy: str) -> list[dict]:\n",
    "    if strategy == \"all\":\n",
    "        return list(items)\n",
    "\n",
    "    def _sql(x):\n",
    "        return str(x.get(\"sql\", \"\")).strip()\n",
    "\n",
    "    def _is_join(sql: str) -> bool:\n",
    "        s = sql.lower()\n",
    "        return \" join \" in f\" {s} \"\n",
    "\n",
    "    def _is_agg(sql: str) -> bool:\n",
    "        return bool(re.search(r\"\\b(sum|avg|count|min|max)\\s*\\(\", sql.lower()))\n",
    "\n",
    "    if strategy == \"brief_sql\":\n",
    "        ranked = sorted(items, key=lambda x: len(_sql(x)))\n",
    "        keep = max(50, int(0.4 * len(ranked)))\n",
    "        pool = ranked[:keep]\n",
    "    elif strategy == \"join_heavy\":\n",
    "        pool = [x for x in items if _is_join(_sql(x))]\n",
    "    elif strategy == \"agg_heavy\":\n",
    "        pool = [x for x in items if _is_agg(_sql(x))]\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown EXEMPLAR_STRATEGY: {strategy}\")\n",
    "\n",
    "    return pool if len(pool) >= 10 else list(items)\n",
    "\n",
    "try:\n",
    "    commit = subprocess.check_output([\"git\", \"rev-parse\", \"--short\", \"HEAD\"]).decode().strip()\n",
    "except Exception:\n",
    "    commit = \"unknown\"\n",
    "\n",
    "run_metadata_base = {\n",
    "    \"commit\": commit,\n",
    "    \"model_id\": MODEL_ID,\n",
    "    \"model_alias\": _model_alias_from_id(MODEL_ID),\n",
    "    \"notebook\": \"02_baseline_prompting_eval.ipynb\",\n",
    "    \"method\": \"baseline\",\n",
    "}\n",
    "\n",
    "Path(\"results/baseline\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def run_baseline_grid(\n",
    "    *,\n",
    "    k_values: list[int],\n",
    "    seeds: list[int],\n",
    "    run_tag: str,\n",
    "    prompt_variant: str,\n",
    "    schema_variant: str,\n",
    "    exemplar_strategy: str,\n",
    "    limit: int | None = None,\n",
    "    copy_canonical: bool = True,\n",
    "    copy_model_family: bool = True,\n",
    "    model_alias: str | None = None,\n",
    "    enable_ts_for_k: set[int] | None = None,\n",
    "    ts_n: int = 10,\n",
    "    ts_prefix: str = \"classicmodels_ts\",\n",
    "    ts_max_rows: int = 500,\n",
    "):\n",
    "    if not seeds:\n",
    "        raise ValueError(\"Provide at least one seed\")\n",
    "\n",
    "    if prompt_variant not in PROMPT_VARIANTS:\n",
    "        raise ValueError(f\"Unknown PROMPT_VARIANT: {prompt_variant}\")\n",
    "\n",
    "    ts = datetime.now(timezone.utc).strftime(\"%Y%m%d_%H%M%SZ\")\n",
    "    run_dir = Path(\"results/baseline/runs\") / f\"{run_tag}_{ts}\"\n",
    "    run_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    schema_used = schema_variant_text(SCHEMA_SUMMARY, schema_variant)\n",
    "    exemplar_pool = exemplar_pool_for_strategy(test_set, exemplar_strategy)\n",
    "    resolved_model_alias = model_alias or run_metadata_base.get(\"model_alias\") or _model_alias_from_id(MODEL_ID)\n",
    "\n",
    "    ts_enabled_k = set(enable_ts_for_k or set())\n",
    "    ts_suite_db_names = (\n",
    "        [f\"{ts_prefix}_{i:02d}\" for i in range(1, ts_n + 1)]\n",
    "        if ts_enabled_k and ts_n > 0\n",
    "        else None\n",
    "    )\n",
    "\n",
    "    ts_connectors = {}\n",
    "\n",
    "    @lru_cache(maxsize=32)\n",
    "    def _make_engine_cached(db_name: str):\n",
    "        eng, conn = create_engine_with_connector(\n",
    "            instance_connection_name=INSTANCE_CONNECTION_NAME,\n",
    "            user=DB_USER,\n",
    "            password=DB_PASS,\n",
    "            db_name=db_name,\n",
    "        )\n",
    "        ts_connectors[db_name] = conn\n",
    "        return eng\n",
    "\n",
    "    def _make_engine_fn(db_name: str):\n",
    "        return _make_engine_cached(db_name)\n",
    "\n",
    "    rows = []\n",
    "    primary_seed = seeds[0]\n",
    "\n",
    "    old_prompt = prompting_mod.SYSTEM_INSTRUCTIONS\n",
    "    prompting_mod.SYSTEM_INSTRUCTIONS = PROMPT_VARIANTS[prompt_variant]\n",
    "\n",
    "    try:\n",
    "        for k in k_values:\n",
    "            seed_list = [primary_seed] if k == 0 else seeds\n",
    "            for seed in seed_list:\n",
    "                save_path = run_dir / f\"results_k{k}_seed{seed}.json\"\n",
    "\n",
    "                run_meta = dict(run_metadata_base)\n",
    "                run_meta.update({\n",
    "                    \"run_tag\": run_tag,\n",
    "                    \"k\": k,\n",
    "                    \"seed\": seed,\n",
    "                    \"prompt_variant\": prompt_variant,\n",
    "                    \"schema_variant\": schema_variant,\n",
    "                    \"exemplar_strategy\": exemplar_strategy,\n",
    "                    \"exemplar_pool_size\": len(exemplar_pool),\n",
    "                    \"model_alias\": resolved_model_alias,\n",
    "                    \"ts_enabled\": bool(k in ts_enabled_k),\n",
    "                    \"ts_for_k_values\": sorted(ts_enabled_k),\n",
    "                    \"ts_n\": ts_n if ts_suite_db_names else 0,\n",
    "                })\n",
    "\n",
    "                items = eval_run(\n",
    "                    test_set=test_set,\n",
    "                    exemplar_pool=exemplar_pool,\n",
    "                    k=k,\n",
    "                    limit=limit,\n",
    "                    seed=seed,\n",
    "                    engine=engine,\n",
    "                    model=model,\n",
    "                    tokenizer=tok,\n",
    "                    schema_summary=schema_used,\n",
    "                    save_path=str(save_path),\n",
    "                    run_metadata=run_meta,\n",
    "                    ts_suite_db_names=ts_suite_db_names if k in ts_enabled_k else None,\n",
    "                    ts_make_engine_fn=_make_engine_fn if k in ts_enabled_k else None,\n",
    "                    ts_max_rows=ts_max_rows,\n",
    "                    avoid_exemplar_leakage=True,\n",
    "                )\n",
    "\n",
    "                n = len(items)\n",
    "                va = sum(int(x.va) for x in items) / max(n, 1)\n",
    "                em = sum(int(x.em) for x in items) / max(n, 1)\n",
    "                ex = sum(int(x.ex) for x in items) / max(n, 1)\n",
    "                ts_values = [int(x.ts) for x in items if getattr(x, \"ts\", None) is not None]\n",
    "                ts_rate = (sum(ts_values) / len(ts_values)) if ts_values else None\n",
    "\n",
    "                rows.append({\n",
    "                    \"run_tag\": run_tag,\n",
    "                    \"prompt_variant\": prompt_variant,\n",
    "                    \"schema_variant\": schema_variant,\n",
    "                    \"exemplar_strategy\": exemplar_strategy,\n",
    "                    \"exemplar_pool_size\": len(exemplar_pool),\n",
    "                    \"k\": k,\n",
    "                    \"seed\": seed,\n",
    "                    \"n\": n,\n",
    "                    \"va_rate\": va,\n",
    "                    \"em_rate\": em,\n",
    "                    \"ex_rate\": ex,\n",
    "                    \"ts_rate\": ts_rate,\n",
    "                    \"ts_n\": len(ts_values),\n",
    "                    \"json_path\": str(save_path),\n",
    "                })\n",
    "\n",
    "                if seed == primary_seed and k in {0, 3}:\n",
    "                    if copy_canonical:\n",
    "                        target = (\n",
    "                            Path(\"results/baseline/results_zero_shot_200.json\")\n",
    "                            if k == 0\n",
    "                            else Path(\"results/baseline/results_few_shot_k3_200.json\")\n",
    "                        )\n",
    "                        target.parent.mkdir(parents=True, exist_ok=True)\n",
    "                        shutil.copy2(save_path, target)\n",
    "                        print(f\"Updated canonical file: {target}\")\n",
    "\n",
    "                    if copy_model_family:\n",
    "                        model_target = Path(\"results/baseline/model_family\") / f\"{resolved_model_alias}_k{k}.json\"\n",
    "                        model_target.parent.mkdir(parents=True, exist_ok=True)\n",
    "                        shutil.copy2(save_path, model_target)\n",
    "                        print(f\"Updated model-family file: {model_target}\")\n",
    "    finally:\n",
    "        for conn in ts_connectors.values():\n",
    "            try:\n",
    "                conn.close()\n",
    "            except Exception:\n",
    "                pass\n",
    "        prompting_mod.SYSTEM_INSTRUCTIONS = old_prompt\n",
    "\n",
    "    df = pd.DataFrame(rows).sort_values([\"k\", \"seed\"]).reset_index(drop=True)\n",
    "    df.to_csv(run_dir / \"grid_summary.csv\", index=False)\n",
    "\n",
    "    agg = (\n",
    "        df.groupby([\"prompt_variant\", \"schema_variant\", \"exemplar_strategy\", \"k\"], as_index=False)\n",
    "        .agg(\n",
    "            runs=(\"seed\", \"count\"),\n",
    "            va_mean=(\"va_rate\", \"mean\"),\n",
    "            va_std=(\"va_rate\", \"std\"),\n",
    "            em_mean=(\"em_rate\", \"mean\"),\n",
    "            em_std=(\"em_rate\", \"std\"),\n",
    "            ex_mean=(\"ex_rate\", \"mean\"),\n",
    "            ex_std=(\"ex_rate\", \"std\"),\n",
    "            ts_mean=(\"ts_rate\", \"mean\"),\n",
    "            ts_std=(\"ts_rate\", \"std\"),\n",
    "        )\n",
    "    )\n",
    "    agg.to_csv(run_dir / \"grid_summary_by_k.csv\", index=False)\n",
    "\n",
    "    print(\"Saved grid run to:\", run_dir)\n",
    "    return df, agg, run_dir\n",
    "\n",
    "# ============================\n",
    "# EXPERIMENT RULE OF THUMB (change one knob at a time)\n",
    "# 1) Model-family test: change MODEL_ID (+ MODEL_ALIAS), keep all other knobs fixed.\n",
    "# 2) Prompting test: change K_VALUES/SEEDS only, keep prompt/schema/exemplar fixed.\n",
    "# 3) Prompt ablation: change PROMPT_VARIANT only.\n",
    "# 4) Schema ablation: change SCHEMA_VARIANT only.\n",
    "# 5) Exemplar ablation: change EXEMPLAR_STRATEGY only (few-shot k>0).\n",
    "# 6) TS check: toggle ENABLE_TS=True with TS_FOR_K_VALUES=[3] for semantic robustness checks.\n",
    "# QUICK MODE (recommended default)\n",
    "K_VALUES = [0, 3]\n",
    "SEEDS = [7]\n",
    "RUN_TAG = \"baseline_main\"\n",
    "PROMPT_VARIANT = \"default\"\n",
    "SCHEMA_VARIANT = \"full\"\n",
    "EXEMPLAR_STRATEGY = \"all\"\n",
    "\n",
    "# Model labeling for multi-model comparisons\n",
    "MODEL_ALIAS = _model_alias_from_id(MODEL_ID)\n",
    "COPY_MODEL_FAMILY = True\n",
    "COPY_CANONICAL = True  # set False for non-canonical model-family sweeps\n",
    "\n",
    "# TS toggle (optional; usually enable only for k=3 checks)\n",
    "ENABLE_TS = False\n",
    "TS_FOR_K_VALUES = [3]\n",
    "TS_N = 10\n",
    "TS_PREFIX = \"classicmodels_ts\"\n",
    "TS_MAX_ROWS = 500\n",
    "\n",
    "# FULL K/S E1 SWEEP (uncomment for primary experiment)\n",
    "# K_VALUES = [0, 1, 3, 5, 8]\n",
    "# SEEDS = [7, 17, 27, 37, 47]\n",
    "# RUN_TAG = \"baseline_e1_k_sweep\"\n",
    "# PROMPT_VARIANT = \"default\"\n",
    "# SCHEMA_VARIANT = \"full\"\n",
    "# EXEMPLAR_STRATEGY = \"all\"\n",
    "\n",
    "# EXEMPLAR STRATEGY ABLATION EXAMPLE (few-shot only; keep k>0 values)\n",
    "# K_VALUES = [3]\n",
    "# SEEDS = [7, 17, 27, 37, 47]\n",
    "# RUN_TAG = \"baseline_exemplar_brief\"\n",
    "# EXEMPLAR_STRATEGY = \"brief_sql\"\n",
    "\n",
    "# PROMPT/SCHEMA ABLATION EXAMPLE\n",
    "# K_VALUES = [0, 3]\n",
    "# SEEDS = [7]\n",
    "# RUN_TAG = \"baseline_prompt_ablation_schema_only\"\n",
    "# PROMPT_VARIANT = \"schema_only_minimal\"\n",
    "# SCHEMA_VARIANT = \"first_80_lines\"\n",
    "\n",
    "baseline_grid, baseline_by_k, baseline_run_dir = run_baseline_grid(\n",
    "    k_values=K_VALUES,\n",
    "    seeds=SEEDS,\n",
    "    run_tag=RUN_TAG,\n",
    "    prompt_variant=PROMPT_VARIANT,\n",
    "    schema_variant=SCHEMA_VARIANT,\n",
    "    exemplar_strategy=EXEMPLAR_STRATEGY,\n",
    "    limit=None,\n",
    "    copy_canonical=COPY_CANONICAL,\n",
    "    copy_model_family=COPY_MODEL_FAMILY,\n",
    "    model_alias=MODEL_ALIAS,\n",
    "    enable_ts_for_k=set(TS_FOR_K_VALUES) if ENABLE_TS else None,\n",
    "    ts_n=TS_N,\n",
    "    ts_prefix=TS_PREFIX,\n",
    "    ts_max_rows=TS_MAX_ROWS,\n",
    ")\n",
    "\n",
    "print(\"\\nPer-run rows:\")\n",
    "display(baseline_grid)\n",
    "print(\"\\nPer-k summary (mean/std across seeds):\")\n",
    "display(baseline_by_k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e435ec69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick summary (reads the saved JSON outputs)\n",
    "import json\n",
    "\n",
    "zero = json.loads(open(\"results/baseline/results_zero_shot_200.json\", \"r\", encoding=\"utf-8\").read())\n",
    "few  = json.loads(open(\"results/baseline/results_few_shot_k3_200.json\", \"r\", encoding=\"utf-8\").read())\n",
    "\n",
    "print(\"Zero-shot:\", \"VA\", round(zero[\"va_rate\"], 3), \"EM\", round(zero.get(\"em_rate\", 0.0), 3), \"EX\", round(zero[\"ex_rate\"], 3))\n",
    "print(\"Few-shot:\",  \"VA\", round(few[\"va_rate\"], 3),  \"EM\", round(few.get(\"em_rate\", 0.0), 3),  \"EX\", round(few[\"ex_rate\"], 3))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}