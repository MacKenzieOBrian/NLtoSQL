{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7fec5ca",
   "metadata": {},
   "source": [
    "# 06 Research Comparison (Primary Contribution Focus)\n",
    "\n",
    "This notebook produces the replication comparison layer for the dissertation: open-source local results are contrasted across prompting, QLoRA fine-tuning, and execution infrastructure, following the comparison structure in Ojuri et al. (2025).\n",
    "\n",
    "Primary research comparisons:\n",
    "- Prompting effect: `k=0` vs `k=3`\n",
    "- Fine-tuning effect: Base vs QLoRA\n",
    "- Error taxonomy to explain why metrics move\n",
    "\n",
    "Infrastructure comparison (secondary):\n",
    "- ReAct as execution support for validity/traceability, not the main semantic claim.\n",
    "\n",
    "It reads existing JSON run outputs and writes plot-ready artifacts to `results/analysis/`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "if not (PROJECT_ROOT / 'results').exists():\n",
    "    PROJECT_ROOT = PROJECT_ROOT.parent\n",
    "\n",
    "sys.path.append(str(PROJECT_ROOT))\n",
    "from scripts.generate_research_comparison import generate\n",
    "\n",
    "OUT_DIR = PROJECT_ROOT / 'results' / 'analysis'\n",
    "summary = generate(out_dir=OUT_DIR, project_root=PROJECT_ROOT)\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9e0a34",
   "metadata": {},
   "source": [
    "### Step 1 - Review loaded runs and headline tables\n",
    "Use this to confirm which JSON artifacts were ingested before interpreting results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96158f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "manifest = pd.read_csv(OUT_DIR / 'run_manifest.csv')\n",
    "metrics_wide = pd.read_csv(OUT_DIR / 'overall_metrics_wide.csv')\n",
    "metrics_long = pd.read_csv(OUT_DIR / 'overall_metrics_long.csv')\n",
    "\n",
    "print('Run manifest:')\n",
    "display(manifest)\n",
    "\n",
    "print('Overall metrics (wide):')\n",
    "display(metrics_wide.sort_values('run_label').reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdb4542",
   "metadata": {},
   "source": [
    "### Step 2 - Inspect overall VA/EM/EX/TS patterns\n",
    "This chart gives the high-level performance profile per run.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956b2de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics = metrics_long[metrics_long['metric'].isin(['va', 'em', 'ex', 'ts'])].copy()\n",
    "pivot = plot_metrics.pivot(index='run_label', columns='metric', values='rate_pct')\n",
    "\n",
    "ax = pivot.plot(kind='bar', figsize=(10, 5), rot=20)\n",
    "ax.set_ylabel('Rate (%)')\n",
    "ax.set_xlabel('Run')\n",
    "ax.set_title('Overall Metrics by Run')\n",
    "ax.legend(title='Metric', loc='upper left', bbox_to_anchor=(1.01, 1.0))\n",
    "ax.grid(axis='y', alpha=0.25)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27efa28c",
   "metadata": {},
   "source": [
    "### Step 3 - Check paired deltas on identical items\n",
    "Use this for controlled claims (few-shot and fine-tune effects).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408828dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "paired_path = OUT_DIR / 'paired_deltas.csv'\n",
    "if paired_path.exists():\n",
    "    paired = pd.read_csv(paired_path)\n",
    "    display(paired)\n",
    "\n",
    "    delta = paired[\n",
    "        paired['comparison_id'].isin([\n",
    "            'few_shot_gain_base',\n",
    "            'few_shot_gain_qlora',\n",
    "            'qlora_gain_k0',\n",
    "            'qlora_gain_k3',\n",
    "        ])\n",
    "        & paired['metric'].isin(['va', 'em', 'ex'])\n",
    "    ].copy()\n",
    "\n",
    "    if not delta.empty:\n",
    "        pivot_delta = delta.pivot(index='comparison_label', columns='metric', values='delta_pct')\n",
    "        ax = pivot_delta.plot(kind='bar', figsize=(10, 4), rot=15)\n",
    "        ax.axhline(0.0, color='black', linewidth=1)\n",
    "        ax.set_ylabel('Delta (percentage points)')\n",
    "        ax.set_xlabel('Comparison')\n",
    "        ax.set_title('Controlled Delta Comparisons')\n",
    "        ax.legend(title='Metric', loc='upper left', bbox_to_anchor=(1.01, 1.0))\n",
    "        ax.grid(axis='y', alpha=0.25)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print('No paired_deltas.csv found yet.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44870cf",
   "metadata": {},
   "source": [
    "### Step 4 - Diagnose failure composition\n",
    "Use this to explain *why* metric changes occurred (join path, aggregation, value linking, etc.).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxonomy_path = OUT_DIR / 'failure_taxonomy.csv'\n",
    "if taxonomy_path.exists():\n",
    "    tax = pd.read_csv(taxonomy_path)\n",
    "    display(tax.sort_values(['run_label', 'count'], ascending=[True, False]).reset_index(drop=True))\n",
    "\n",
    "    pivot_tax = tax.pivot(index='run_label', columns='failure_type', values='share_of_failures').fillna(0.0)\n",
    "    ax = pivot_tax.plot(kind='bar', stacked=True, figsize=(10, 5), rot=20)\n",
    "    ax.set_ylabel('Share of failed examples')\n",
    "    ax.set_xlabel('Run')\n",
    "    ax.set_title('Failure Taxonomy by Run')\n",
    "    ax.legend(title='Failure type', loc='upper left', bbox_to_anchor=(1.01, 1.0))\n",
    "    ax.grid(axis='y', alpha=0.25)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print('No failure_taxonomy.csv found yet.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dissertation Use Notes\n",
    "\n",
    "- Use `overall_metrics_wide.csv` for headline VA/EM/EX/TS tables.\n",
    "- Use `paired_deltas.csv` for controlled claims (few-shot gain, fine-tune gain).\n",
    "- Use `failure_taxonomy.csv` to explain persistent semantic errors (join path, aggregation, value linking).\n",
    "- If QLoRA files are missing, run `05_qlora_train_eval.ipynb` and rerun this notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
